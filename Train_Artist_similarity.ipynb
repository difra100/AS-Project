{"cells":[{"cell_type":"markdown","metadata":{"id":"4hh42B2lZiqb"},"source":["# Artist Similarity with Graph Neural Network 1st Notebook\n","\n","In this notebook are implemented the experiments that were previously conducted in the paper  ['Artist Similarity with Graph Neural Network'](https://archives.ismir.net/ismir2021/paper/000043.pdf).  \n","In addition to the architectures described in the research there are also experiments with the famous Graph Attention layer, in order to show how this approach can sharply outperform the GraphSAGE configuration.  \n","In this notebook are shown the performances from the different embeddings of artists."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# !pip install torchmetrics\n","# !pip install torch-scatter -f https://data.pyg.org/whl/torch-1.12.0+cu113.html\n","# !pip install torch-sparse -f https://data.pyg.org/whl/torch-1.12.0+cu113.html\n","# !pip install torch-geometric"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34346,"status":"ok","timestamp":1666445857243,"user":{"displayName":"Andrea Giuseppe Di Francesco","userId":"08960477550582263763"},"user_tz":-120},"id":"5IpQhFw5ui1n","outputId":"facca6d1-d706-4c4d-a43b-46eb67f8d905"},"outputs":[{"name":"stdout","output_type":"stream","text":["1.12.1\n"]}],"source":["import os\n","import torch\n","os.environ['TORCH'] = torch.__version__\n","print(torch.__version__)\n","import numpy as np\n","import plotly.express as px\n","import plotly.graph_objects as go\n","import json\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchmetrics.functional import pairwise_euclidean_distance\n","from torch_geometric.nn import GATConv, SAGEConv\n","from torch.optim import lr_scheduler\n","import random\n","from random import choice,randrange\n","import matplotlib.pyplot as plt\n","from sklearn.neighbors import NearestNeighbors\n","import math\n","import time\n","from torch_geometric import seed_everything\n","\n","\n","random_seed=280085\n","\n","seed_everything(random_seed)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":254,"status":"ok","timestamp":1666445865903,"user":{"displayName":"Andrea Giuseppe Di Francesco","userId":"08960477550582263763"},"user_tz":-120},"id":"HOhjZ5Ti6eIi","outputId":"8794a273-14f7-4d6c-b51d-9b744f1c6926"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.1.0\n"]}],"source":["import torch_geometric\n","print(torch_geometric.__version__)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18302,"status":"ok","timestamp":1666445891917,"user":{"displayName":"Andrea Giuseppe Di Francesco","userId":"08960477550582263763"},"user_tz":-120},"id":"ALkv1jFrxiN5","outputId":"ee244daa-cdd0-4262-8a90-b8e58a1947e2"},"outputs":[{"name":"stdout","output_type":"stream","text":["1.12.1\n"]}],"source":["from utils import *  #In this files are reported the most useful functions\n","from architectures import *"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1666445892277,"user":{"displayName":"Andrea Giuseppe Di Francesco","userId":"08960477550582263763"},"user_tz":-120},"id":"Agyg6OT-x2Es","outputId":"4e46fa89-bb78-4251-96f5-6b3f5627acc4"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"QjCLttrhbBCF"},"source":["With the help of the [Torch geometric framework](https://pytorch-geometric.readthedocs.io/en/latest/) was really easy to handle the graph attributes and nodes and then the training of the GNNs."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11605,"status":"ok","timestamp":1666445906966,"user":{"displayName":"Andrea Giuseppe Di Francesco","userId":"08960477550582263763"},"user_tz":-120},"id":"EEnPYRB2ulHt","outputId":"318c70b2-b259-425c-afbd-fcdd9ea7a0c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["11261\n"]}],"source":["random = False\n","if random == True:\n","  A1 = torch.load('adjacency').to(device)      # Normal adjacency matrix format is obtained with torch.load('adjacency')\n","  X = torch.load('random_instance').to(device)\n","else:\n","  X = torch.load('instance').T.to(device)      # Instance matrix\n","  A1 = torch.load('adjacency').to(device) \n","\n","A = torch.load('adjacencyCOO').to(device)    # Adjacency matrix in the COO format, that is that supported by torch geometric\n","\n","\n","num_samples = X.shape[0]\n","print(num_samples)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1045,"status":"ok","timestamp":1666445908002,"user":{"displayName":"Andrea Giuseppe Di Francesco","userId":"08960477550582263763"},"user_tz":-120},"id":"allCyMKFulLc","outputId":"c6f124a2-4d6f-4df2-9aa8-2942a5906659"},"outputs":[],"source":["''' These variables contain the information about the artists' names, and their position in the dataset, this makes easy to look for their name and to better draw conclusions at inference time '''\n","num2artist = load_data('dizofartist.json')\n","artist2num = {num2artist[key]:key for key in num2artist}\n","\n","# print(num2artist)\n","# print(artist2num)"]},{"cell_type":"markdown","metadata":{"id":"g15I5izB4Ar9"},"source":["## Import the data with Torch geometric:\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1666445908003,"user":{"displayName":"Andrea Giuseppe Di Francesco","userId":"08960477550582263763"},"user_tz":-120},"id":"yI4Gdy0FulY8"},"outputs":[],"source":["''' In order to conduct the experiments was fundamental to split the dataset, either the nodes and also the edges.\n","    The splitting was performed according to the information in the paper, and considering the fact that a lot of date were lost in the preprocessing part.'''\n","\n","from torch_geometric.data import Data\n","from torch_geometric.utils import structured_negative_sampling\n","\n","\n","''' This variable contains the indices for the splitting, that are necessary to compute the masks, according to the torch geometric pipeline '''\n","data_summary = {'train_with_val' : {'low' : 0, 'high': 9022},\n","                'train' : {'low' : 0, 'high' : 10190},\n","                'val' : {'low' : 9022, 'high' : 10190},\n","                'test' : {'low' : 10190, 'high' : 11261}}\n","\n","total_mask = torch.zeros(X.shape[0], dtype = torch.bool)\n","\n","vtrain_mask = total_mask.clone()\n","train_mask = total_mask.clone()\n","val_mask = total_mask.clone()\n","test_mask = total_mask.clone()\n","eval_val = total_mask.clone()\n","\n","\n","vtrain_mask[data_summary['train_with_val']['low']:data_summary['train_with_val']['high']] = True\n","val_mask[data_summary['val']['low']:data_summary['val']['high']] = 1\n","train_mask[data_summary['train']['low']:data_summary['train']['high']] = 1\n","test_mask[data_summary['test']['low']:data_summary['test']['high']] = 1\n","\n","eval_val[data_summary['train_with_val']['low']:data_summary['val']['high']] = 1\n","\n","kwargs = {'vtrain_mask':vtrain_mask, 'train_mask':train_mask, 'val_mask':val_mask, 'test_mask':test_mask}\n","\n","data = Data(x=X, edge_index = A, **kwargs)\n","\n","\n","class data_split:\n","  ''' This class shows an alternative to the torch geometric masks procedure, it was necessary at inference time, where was needed the whole graph for the embedding compuutation '''\n","  def __init__(self, data, low, high):\n","    ''' Starting from the index 0 to 11260, we choose the interval of intersting samples\n","        self.data: contains the whole dataset (nodes and edges)\n","        self.rang: define the boundaries\n","        self.get_split_from_bounds perform the splitting, returning a x and edge_index attribute resembling the torch geometric Data objects.'''\n","    self.data = data\n","    self.rang = torch.arange(low, high + 1,1, device = 'cuda' if torch.cuda.is_available() else 'cpu')\n","    self.get_split_from_bounds(low, high)\n","\n","  def get_split_from_bounds(self, low, high):\n","    self.x= self.data.x[low:high]\n","    v1_0 = self.data.edge_index[0]\n","    v2_0 = self.data.edge_index[1]\n","    v1_1 = v1_0[v1_0 < high]\n","    v1_2 = v1_1[v1_1 >= low]\n","\n","    v2_1 = v2_0[v1_0 < high]\n","    v2_2 = v2_1[v1_1 >= low]\n","    v2_3 = v2_2[v2_2 < high]\n","    v2_4 = v2_3[v2_3 >= low]\n","    v1_3 = v1_2[v2_2 < high]\n","    v1_4 = v1_3[v2_3 >= low]\n","\n","    self.edge_index = torch.cat((v1_4.unsqueeze(0), v2_4.unsqueeze(0)), dim = 0)\n","    \n","    return self.x, self.edge_index\n","\n","  def split_for_inference(self, low_train, low_test, high_train, high_test):\n","    ''' At inference time we need to compute the embedding through the train and test artists, but we don want to consider the linkings between the test artist, those must be predicted.\n","        This function takes as input the boundaries of the train, and test set, computes the edge indices by removing the undesired connection.\n","        This method will be used to compute the accuracy. '''\n","    \n","    final_edge_indices = torch.tensor([[],[]], device = 'cuda' if torch.cuda.is_available() else 'cpu')\n","    for edge in range(self.edge_index.shape[1]):\n","      up = self.edge_index[0][edge].item()\n","      down = self.edge_index[1][edge].item()\n","\n","      if up in range(low_test,high_test) and down in range(low_test, high_test): # If the connection is between test artist we remove it from the edge indices.\n","        continue\n","\n","      else:\n","        final_edge_indices = torch.cat((final_edge_indices, self.edge_index[:,edge].reshape((2,1))), dim = 1)\n","\n","    if device.type == 'cuda':\n","      return self.x, final_edge_indices.type(torch.cuda.LongTensor)\n","    else:\n","      return self.x, final_edge_indices.type(torch.LongTensor)\n"]},{"cell_type":"markdown","metadata":{"id":"zPoJAU5AXo4h"},"source":["## Define the architectures\n","\n","* GraphSage-based architecture is the one defined in the original paper [Artist similarity with Graph Neural Networks](https://arxiv.org/pdf/2107.14541.pdf).  \n","  1. SAGEConv(2613,256)\n","  2. SAGEConv(256,256) *\n","  3. SAGEConv(256,256) *\n","  4. Linear(256,100)  \n","  5. TripletLoss(a,p,n)\n","  \n","The second and third layer are optionals based on the desired configuration.\n","\n","* The GAT-based architectures are the one used for our own experiments, they are defined as follows:  \n","\n","GAT1: \n","  1. GATConv(2613, 256)    *Multi-head attention mechanism\n","  2. GATConv(256 * n_heads, 256) *Multi-head attention mechanism\n","  3. Linear(256 * n_heads, 256)  \n","  4. Linear(256, 256)\n","  5. TripletLoss(a,p,n)\n","\n","GAT2:  \n","  1. Linear(2613, 256)\n","  2. Linear(256,256)\n","  3. Linear(256, 256) \n","  4. GATConv(256 , 256) *Multi-head attention mechanism\n","  5. GATConv(256* n_heads, 256)    *Multi-head attention mechanism\n","  6. TripletLoss(a,p,n)"]},{"cell_type":"markdown","metadata":{"id":"VzY3K4mSe42Z"},"source":["According to the paper's authors the training was done with the aid of mini-batches of 512 size, in order to do so the torch-geometric framework offer the NeighborLoader method, that shuffles the data and look for the neighbors of each batch in a few seconds."]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1666445908003,"user":{"displayName":"Andrea Giuseppe Di Francesco","userId":"08960477550582263763"},"user_tz":-120},"id":"1ECwkqYXzWxe"},"outputs":[],"source":["from torch_geometric.loader import NeighborLoader"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1666445908003,"user":{"displayName":"Andrea Giuseppe Di Francesco","userId":"08960477550582263763"},"user_tz":-120},"id":"-vkdbZ27fC5Y"},"outputs":[],"source":["lamb = 0.8 # This is the value used for the distance weighted sampling\n","\n","def get_triplets(embedding, edges, batch_size, get_vecs = False):\n","  ''' The loss function to minimize is  a triplet loss function, thus we need to look for positives and negatives for each sample in the batches.\n","      This function takes as input:\n","      * embedding:  the output of the GCN.\n","      * edges:      the edges for the mini-batch.\n","      * batch_size: the size for the batch.\n","      * get_vecs:   It is a boolean, if True the function returns the tensor of positives and negatives, otherwise only the indices are returned.  '''\n","\n","  n_of_neigh = 10 # How many samples to consider for the sampling\n","  edges_n = edges.clone()\n","  edges[0] = edges_n[1]\n","  edges[1] = edges_n[0]\n","  \n","  total_triplets = structured_negative_sampling(edges)\n","  total_ancor = total_triplets[0]\n","  total_pos = total_triplets[1]\n","  total_negs = total_triplets[2]\n","\n"," \n","  shape = batch_size\n","  positives = torch.zeros(shape)\n","  negatives = torch.zeros(shape)\n","  \n","  for ancor in range(shape):\n","    pos = total_pos[total_ancor == ancor] # We get the positives that are also neighbors for the anchor\n","    #pos = pos_n[pos_n < 512]  \n","    if pos.shape[0] > n_of_neigh:\n","      pos = pos[:n_of_neigh]\n","    neg = total_negs[total_ancor == ancor] # We get the negatives that are also neighbors for the anchor\n","    #neg = neg_n[neg_n < 512]  \n","\n","    if neg.shape[0] > n_of_neigh:\n","      neg = neg[:n_of_neigh]\n","    p = 1\n","    n = 1\n","\n","    if pos.shape[0] == 0:\n","      positives[ancor] == ancor\n","      p = 0\n","    \n","    if neg.shape[0] == 0:\n","      negatives[ancor] == ancor\n","      n = 0\n","    \n","    if p:\n","      pos_index = compute_idx_p(embedding, pos, ancor)\n","      positives[ancor] = pos_index\n","    if n:\n","      neg_index = compute_idx_n(embedding, neg, ancor)\n","      negatives[ancor] = neg_index\n","  \n","  \n","  if device.type == 'cuda':\n","    positives = positives.type(torch.cuda.LongTensor) \n","    negatives = negatives.type(torch.cuda.LongTensor)\n","  else:\n","    positives = positives.type(torch.LongTensor)\n","    negatives = negatives.type(torch.LongTensor)\n","\n","  \n","  if get_vecs:\n","    return embedding[positives], embedding[negatives] #Return the embedding vectors\n","\n","  else:\n","    return positives, negatives                       # Or return the list of indices\n","\n","\n","def compute_idx_p(embedding, pos, ancor):\n","# This function performs the distance weighted sampling.\n","# We look for all positives for the anchor sample and we weight their distance from it. We choose then the 'hard positive' namely one of the furthest positives for the anchor\n","  diz_pos_ = {}\n","  #print(pos)\n","  for idx in pos:\n","    diz_pos_[idx.item()] = pairwise_euclidean_distance(embedding[ancor].unsqueeze(0), embedding[idx.item()].unsqueeze(0))[0][0].item()\n","  max_dist = max(list(diz_pos_.values())) if max(list(diz_pos_.values()))!=0 else 1e-5\n","  keys = list(diz_pos_.keys())\n","\n","  for key in keys:\n","    if diz_pos_[key]/max_dist > lamb and len(diz_pos_) != 1:\n","      diz_pos_.pop(key)\n","\n","\n","  return max(diz_pos_,key=diz_pos_.get)\n","\n","def compute_idx_n(embedding, neg, ancor):\n","# This function performs the distance weighted sampling.\n","# We look for all negatives for the anchor sample and we weight their distance from it. We choose then the 'hard negative' namely one of the closest negative for the anchor \n","    diz_neg_ = {}\n","    #print(neg)\n","    for idx in neg:\n","      diz_neg_[idx.item()] = pairwise_euclidean_distance(embedding[ancor].unsqueeze(0), embedding[idx.item()].unsqueeze(0))[0][0].item()\n","\n","  \n","    max_dist = max(list(diz_neg_.values())) if max(list(diz_neg_.values()))!=0 else 1e-5\n","    keys = list(diz_neg_.keys())\n","    for key in keys:\n","      if diz_neg_[key]/max_dist < 1 - lamb and len(diz_neg_) != 1:\n","        diz_neg_.pop(key)\n","\n","\n","    return min(diz_neg_,key=diz_neg_.get)\n","\n","\n","class Trainer:\n","  ''' This class contains all the method needed to train, test, evaluate, save and load the model.''' \n","  def __init__(self, model, optimizer, scheduler, loss, num_epochs, mode, path, first):\n","\n","    self.model = model  # model class\n","    self.optimizer = optimizer # Adam optimizer\n","    self.scheduler = scheduler # Cosine learning rate scheduler\n","    self.loss = loss           # Triplet Loss function\n","    self.num_epochs = num_epochs # Num of epochs for the training\n","    self.mode = mode             # This must be specified to know what splitting to use in the model evaluation\n","    self.path = path             # This is the path where to save the model, if None the model won't be saved, otherwise it will be at the end of each epoch.\n","    self.first = first\n","    if self.first != True:\n","      self.checkpoint = load_model(self.path, self.model, device) # If exists already a checkpoint for the model we load it.\n","    else:\n","      self.checkpoint = {}\n","\n","\n","\n","  def train(self):\n","    self.model.train()\n","\n","    for epoch in range(num_epochs):\n","      print(\"Processing {}-th epoch\".format(epoch+1))\n","      print(\"Training step....\")\n","      loss_train_list = []\n","      loss_test_list = []\n","      for batch in train_loader:\n","        self.optimizer.zero_grad()\n","\n","        out = self.model(batch.x, batch.edge_index.to(device))\n","        \n","        positives, negatives = get_triplets(out.clone(), batch.edge_index.clone(), batch.batch_size, get_vecs = True)\n","        out_l = out[:batch.batch_size]\n","\n","      \n","\n","        loss_train = self.loss(out_l, positives, negatives)\n","        loss_train.backward()\n","        self.optimizer.step()\n","        loss_train_list.append(loss_train.item())\n","\n","\n","      self.loss_test_f = self.test()\n","      self.loss_train_f = sum(loss_train_list)/len(loss_train_list)\n","      self.accuracy_on_test = self.eval_accuracy(self.mode)\n","\n","      self.end_epoch()\n","      self.scheduler.step()\n","\n","      print(\"At the {}-th epoch we have obtained: train_loss {:.6f} \\t test_loss {:.6f} \\t test_accuracy {:.6f}\".format(epoch+1,self.loss_train_f, self.loss_test_f, self.accuracy_on_test))\n","    return self.accuracy_on_test\n","    \n","\n","  def test(self):\n","    self.model.eval()\n","    with torch.no_grad():\n","      print(\"Testing step....\")\n","      loss_test_list = []\n","      for batch in test_loader:\n","\n","        out = self.model(batch.x, batch.edge_index.to(device))\n","        \n","        positives, negatives = get_triplets(out.clone(), batch.edge_index.clone(), batch.batch_size, get_vecs = True)\n","\n","        out_l = out[:batch.batch_size]\n","        \n","\n","        loss_test = self.loss(out_l, positives, negatives)\n","        loss_test_list.append(loss_test.item())\n","\n","\n","    return sum(loss_test_list)/len(loss_test_list) \n","\n","  def calcG(self,ID):  #This method is used for the evaluation of accuracy, in particular it computes the denominator\n","    if ID>200:       # as described in the paper.\n","        ID=200\n","    c=1\n","    somm=0\n","    while c<=ID:\n","        somm+=1/(math.log2(1+c))\n","        c+=1\n","    return somm\n","\n","  def eval_accuracy(self, mode = 1): \n","    ''' This function computes the Normalized Discounted Cumulative Gain, that is the metric adopted in the research. '''\n","    if mode == 1:\n","      low_train = data_summary['train_with_val']['low']\n","      high_train = data_summary['train_with_val']['high']\n","      low_test = data_summary['val']['low']\n","      high_test = data_summary['val']['high']\n","\n","    else:\n","      low_train = data_summary['train']['low']\n","      high_train = data_summary['train']['high']\n","      low_test = data_summary['test']['low']\n","      high_test = data_summary['test']['high']      \n","\n","\n","    self.model.eval()\n","    with torch.no_grad():\n","      ''' It is necessary to compute the embedding by condisering the edges between train and test data, but without considering the linkings between test samples, because they ,must be predicted in the evaluation. '''\n","      inference_data = data_split(data, low = low_train, high = high_test).split_for_inference(low_train, low_test, high_train, high_test) # This function takes care of the link remotion.\n","      out = self.model(inference_data[0], inference_data[1].to(device))[torch.arange(low_test,high_test)]\n","\n","      A_acc = A1[low_test:high_test, low_test:high_test]\n","\n","      print(\"Evaluation step....\")\n","      test_embs = out.to(torch.device('cpu')).numpy()\n","      \n","      neigh=NearestNeighbors(n_neighbors=(200+1),algorithm='ball_tree').fit(test_embs) #With the K-NN we get the nearest \n","      \n","      dist,ind=neigh.kneighbors(test_embs) \n","\n","      acc=[]\n","\n","      c=0\n","      for test_artist in range(high_test-low_test):\n","          summ=0\n","          # ideal=len([i for i in range(self.test[0],self.test[0]+A_acc[k,:].shape[0]) if A_acc[k,i]!=0]) \n","          \n","          ideal = A_acc[ind[c][0]].sum().item()\n","          \n","          \n","          \n","          den = self.calcG(ideal)\n","          if den==0:\n","              c+=1\n","              continue  \n","          for j in range(len(ind[c][1:])):\n","              if A_acc[ind[c][0]][ind[c][1:][j]].item()!=0:\n","                  summ+= 1/(math.log2(1+(j+1)))\n","                  \n","              else:\n","                  continue\n","          c+=1    \n","          summ/=den\n","          acc.append(summ)\n","      return sum(acc)/len(acc)\n","\n","  def end_epoch(self):\n","\n","    ''' This method is called at the end of each epoch and its purpose is to save the model state, and metrics, in order to be loaded again when needed.'''\n","    if self.path != None:\n","      if self.first:\n","        self.checkpoint['loss_train'] = [self.loss_train_f]\n","        self.checkpoint['loss_test'] = [self.loss_test_f]\n","        self.checkpoint['accuracy'] = [self.accuracy_on_test]\n","        self.checkpoint['modelState'] = self.model.state_dict()\n","        save_model(self.checkpoint, self.path)\n","        self.first = False\n","      else:\n","        self.checkpoint['loss_train'] += [self.loss_train_f]\n","        self.checkpoint['loss_test'] += [self.loss_test_f]\n","        self.checkpoint['accuracy'] += [self.accuracy_on_test]\n","        self.checkpoint['modelState'] = self.model.state_dict()\n","        save_model(self.checkpoint, self.path)\n","\n","      load_model(self.path, self.model, device)\n","\n","\n","\n","    "]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":246,"status":"ok","timestamp":1666445917777,"user":{"displayName":"Andrea Giuseppe Di Francesco","userId":"08960477550582263763"},"user_tz":-120},"id":"sxnslKx7RrQr","outputId":"b44cad94-0a8b-447c-c7d2-27749de22287"},"outputs":[{"data":{"text/plain":["' NeighborLoader is really important when it comes to train with mini-batches, it provides easily the splittings and the training is faster. '"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["set_mode = 'test'  # 'val' or 'test', in order to set up the specific training procedure\n","\n","data = data\n","\n","if set_mode == 'val':\n","  trainmask = data.vtrain_mask\n","  testmask = data.val_mask\n","  mode = 1\n","elif set_mode == 'test':\n","  trainmask = data.train_mask\n","  testmask = data.test_mask\n","  mode = 2\n","\n","\n","#Gat2Model = GAT2(n_heads = 1) #, GraphSage(n_layers = n_layers), FCL() #\n","path =  './models/GATSY.pt'#'models/GAT2_nobatch.pt' #'models/three_layerSAGElstm.pt'   #Choose the path where to save the trained model\n","first = True\n","\n","''' NeighborLoader is really important when it comes to train with mini-batches, it provides easily the splittings and the training is faster. '''"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":467},"executionInfo":{"elapsed":34224,"status":"error","timestamp":1666447320791,"user":{"displayName":"Andrea Giuseppe Di Francesco","userId":"08960477550582263763"},"user_tz":-120},"id":"DpGwUMBdzhYD","outputId":"92bfe7f2-6841-4e0c-9d63-4e9c7a82cd87"},"outputs":[],"source":["model_name = 'GAT2'\n","\n","n_heads = 1\n","\n","lr = 6e-5\n","\n","n_layers = 2\n","weight_decay = 1e-2\n","num_epochs = 50\n","model = GAT2(n_heads) # GraphSage(), FCL()\n","\n","\n","train_loader = NeighborLoader(data, input_nodes = data.vtrain_mask, num_neighbors=[25]*n_layers, shuffle = True, batch_size = 512)\n","test_loader = NeighborLoader(data, input_nodes = data.val_mask, num_neighbors=[25]*n_layers, shuffle = False, batch_size = 512)\n","\n","    \n","\n","optimizer = torch.optim.Adam(model.parameters(), lr = lr, weight_decay = weight_decay)\n","scheduler=lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min= 0, last_epoch= -1, verbose=True)\n","loss = torch.nn.TripletMarginLoss(margin=0.2)\n","path =  './models/GATSY.pt'#'./models/best_gat_random.pt'\n","trainer = Trainer(model.to(device), optimizer, scheduler, loss, num_epochs, mode, path, first)\n","accuracy = trainer.train()  # This cell make the training start.\n","\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.6 ('my_env')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"3d541b27ed3f6b3a2668175b94af942c53fef9dc2000d6033c45f742df07c856"}}},"nbformat":4,"nbformat_minor":0}
