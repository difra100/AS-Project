{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4fmrN5VAWUrJ",
      "metadata": {
        "id": "4fmrN5VAWUrJ"
      },
      "source": [
        "# Neural Network project, 2022\n",
        "## - Artist similarity with Graph Neural Networks (re-implementation)\n",
        "- Andrea Giuseppe Di Francesco, 1836928\n",
        "- Giuliano Giampietro, 2024160\n",
        "\n",
        "* In this notebook we present a complete re-implementation of the paper ['Artist similarity with Graph Neural Network'](https://arxiv.org/abs/2107.14541). \n",
        "* Since the project's code wasn't provided by the authors, except for the [dataset](https://gitlab.com/fdlm/olga://paperswithcode.com/paper/artist-similarity-with-graph-neural-networks), we attempted to repeat the experiments described in the paper, and we have additionally tried 4 additional GNNs architectures, provided by the Phd student Indro Spinelli.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "serwR-KUl2Ym",
      "metadata": {
        "id": "serwR-KUl2Ym"
      },
      "source": [
        "## - Importing the libraries\n",
        "\n",
        "In the following cell we import the libraries that we used to carry out our experiments, and to extract the dataset. Since we worked with the Graph Neural Networks (GNN), it was very helpful to use the [pytorch geometric library](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html), that contains a lot of useful classes that implement the most famous GNNs architectures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "d8aee866",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.13.0\n"
          ]
        }
      ],
      "source": [
        "# !pip install plotly\n",
        "# !pip install musicbrainzngs\n",
        "# !pip install torchmetrics\n",
        "# !pip install spacy-sentence-bert\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "# !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "# !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "# !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "9e657a64",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e657a64",
        "outputId": "263c1dba-6510-4de0-dcae-62182872e4b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f71d8159cd0>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import json\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchmetrics.functional import pairwise_euclidean_distance\n",
        "# from torch_geometric.nn import GATConv, SAGEConv\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler\n",
        "import random\n",
        "from random import choice,randrange\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import math\n",
        "import time\n",
        "# from torch_geometric.nn import GCNConv,GraphConv,GATConv,SAGEConv\n",
        "import musicbrainzngs as mbr\n",
        "import spacy_sentence_bert\n",
        "\n",
        "random_seed=80085\n",
        "\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5bfd991",
      "metadata": {},
      "outputs": [],
      "source": [
        "sentence_selector = spacy_sentence_bert.load_model('en_stsb_roberta_base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "d5a78feb",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7326302253062094"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence_selector('classical rock').similarity(sentence_selector('classical music'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "7732b342",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "black metal 7\n",
            "blackgaze 1\n",
            "post-punk 12\n",
            "2008 universal fire victim 62\n",
            "soul 49\n",
            "00s 3\n",
            "10s 2\n",
            "80s 8\n",
            "90s 6\n",
            "country 26\n",
            "electronic 59\n",
            "english 45\n",
            "european 11\n",
            "folk 66\n",
            "french 17\n",
            "latin 29\n",
            "multiple ipi 1\n",
            "punk 29\n",
            "rap 5\n",
            "reggae 10\n",
            "rock 159\n",
            "spanish 3\n",
            "world 7\n",
            "new wave 26\n",
            "synthpop 21\n",
            "death metal 12\n",
            "metal 33\n",
            "poland 2\n",
            "technical death metal 2\n",
            "drum and bass 10\n",
            "slummin 1\n",
            "alternative rock 58\n",
            "pop punk 10\n",
            "bebop 3\n",
            "cool jazz 4\n",
            "jazz 97\n",
            "brazilian metal 1\n",
            "death-metal 1\n",
            "alternative hip-hop 1\n",
            "american 54\n",
            "hip-hop 4\n",
            "classic pop and rock 53\n",
            "ccm 1\n",
            "contemporary gospel 2\n",
            "contemporary r&b 28\n",
            "dance-pop 17\n",
            "electropop 9\n",
            "gospel 7\n",
            "blues 32\n",
            "classic country 1\n",
            "country blues 5\n",
            "country gospel 1\n",
            "hillbilly 1\n",
            "honky tonk 3\n",
            "poetry 4\n",
            "rockabilly 4\n",
            "traditional country 2\n",
            "folk punk 3\n",
            "hip hop 75\n",
            "ambient 23\n",
            "dark pop 1\n",
            "drone 7\n",
            "jam band 6\n",
            "krautrock 6\n",
            "neo psychedelia 1\n",
            "psychedelic rock 15\n",
            "space rock 5\n",
            "breakbeat hardcore 1\n",
            "jungle 3\n",
            "rave 2\n",
            "rock and indie 35\n",
            "big beat 4\n",
            "breakbeat 2\n",
            "dutch 5\n",
            "electroclash 3\n",
            "film score 3\n",
            "film soundtrack 2\n",
            "2000s 6\n",
            "jazz pop 4\n",
            "neo soul 9\n",
            "neo-soul 3\n",
            "nuno 5\n",
            "r&b 19\n",
            "doo-wop 5\n",
            "chamber folk 2\n",
            "indie folk 9\n",
            "smooth jazz 7\n",
            "blues rock 23\n",
            "melodic death metal 4\n",
            "swedish 4\n",
            "symphonic death metal 1\n",
            "thrash metal 7\n",
            "downtempo 15\n",
            "dubstep 3\n",
            "britannique 2\n",
            "british 60\n",
            "composer 10\n",
            "compositeur 2\n",
            "lyricist 3\n",
            "parolier 3\n",
            "synth-pop 20\n",
            "uk 47\n",
            "alternative country 6\n",
            "indie rock 44\n",
            "psychedelic folk 2\n",
            "death by colon cancer 1\n",
            "progressive rock 26\n",
            "server name 4\n",
            "german 22\n",
            "german pop 2\n",
            "pop 92\n",
            "alternative hip hop 6\n",
            "conscious hip hop 5\n",
            "hard bop 18\n",
            "shoegaze 4\n",
            "death doom metal 1\n",
            "death-doom metal 1\n",
            "doom metal 3\n",
            "finnish 3\n",
            "experimental 12\n",
            "hardcore punk 9\n",
            "screamo 2\n",
            "akcent 1\n",
            "celtic 4\n",
            "celtic folk 2\n",
            "irish 6\n",
            "irish folk 2\n",
            "actually an actor 1\n",
            "australian 5\n",
            "salsa 7\n",
            "industrial rock 5\n",
            "soundtrack 5\n",
            "western 1\n",
            "electric blues 7\n",
            "hard rock 37\n",
            "heavy metal 25\n",
            "garage pop 1\n",
            "atmospheric 1\n",
            "dark ambient 6\n",
            "dark wave 5\n",
            "darkwave 3\n",
            "dungeon synth 1\n",
            "industrial metal 3\n",
            "norwegian 6\n",
            "acoustic blues 1\n",
            "acoustic chicago blues 1\n",
            "acoustic texas blues 1\n",
            "punk rock 17\n",
            "burgess 1\n",
            "psytrance 1\n",
            "trance 3\n",
            "acoustic rock 8\n",
            "jangle pop 4\n",
            "pop rock 60\n",
            "hillsong 1\n",
            "praise & worship 1\n",
            "heute hier morgen dort 1\n",
            "liedermacher 1\n",
            "singer-songwriter 28\n",
            "alternative metal 15\n",
            "nu metal 5\n",
            "tango 1\n",
            "brazilian 2\n",
            "south american 2\n",
            "ranchera 2\n",
            "dub 5\n",
            "jamaican 4\n",
            "lovers rock 1\n",
            "roots 1\n",
            "italian 11\n",
            "post-rock 11\n",
            "merengue 6\n",
            "jazz fusion 11\n",
            "adult contemporary 10\n",
            "baroque pop 5\n",
            "christmas music 4\n",
            "country pop 4\n",
            "easy listening 4\n",
            "soft rock 18\n",
            "axé 1\n",
            "latin pop 8\n",
            "samba-reggae 1\n",
            "chicago blues 2\n",
            "modern classical 7\n",
            "session 4\n",
            "pop rap 9\n",
            "british rhythm & blues 2\n",
            "garage rock 12\n",
            "mod 4\n",
            "pop soul 16\n",
            "psychedelic soul 2\n",
            "rhythm & blues 10\n",
            "traditional pop 2\n",
            "vocal group 1\n",
            "canada 5\n",
            "canadian 10\n",
            "canadien 1\n",
            "britpop 4\n",
            "usa 20\n",
            "blue-eyed soul 7\n",
            "avant-garde jazz 5\n",
            "post-bop 7\n",
            "spiritual jazz 1\n",
            "dream pop 7\n",
            "leftfield 1\n",
            "shoegazing 2\n",
            "folktronica 4\n",
            "native american 1\n",
            "emo 6\n",
            "post-hardcore 6\n",
            "ambient pop 4\n",
            "art pop 13\n",
            "indietronica 6\n",
            "singer/songwriter 14\n",
            "contemporary christian 3\n",
            "piano 2\n",
            "funk 19\n",
            "minneapolis sound 1\n",
            "dance and electronica 21\n",
            "psychedelic 5\n",
            "psychedelic electronica 1\n",
            "fusion 2\n",
            "reggae rock 1\n",
            "art rock 11\n",
            "eclectic prog 2\n",
            "electroacoustic 1\n",
            "experimental rock 13\n",
            "parody 2\n",
            "dance 15\n",
            "electrónica 1\n",
            "fusión 1\n",
            "acid jazz 9\n",
            "new jack swing 3\n",
            "uk bass 1\n",
            "austrian 1\n",
            "austropop 1\n",
            "death by car crash 2\n",
            "classical 17\n",
            "violinist 3\n",
            "disco 13\n",
            "synth funk 2\n",
            "christian rock 3\n",
            "folk rock 17\n",
            "jazz and blues 9\n",
            "classic rock 5\n",
            "contemporary folk 7\n",
            "country rock 5\n",
            "favoritos 3\n",
            "power pop 5\n",
            "danish 2\n",
            "electronic rock 4\n",
            "soul jazz 10\n",
            "southern soul 3\n",
            "east coast hip hop 4\n",
            "funk rock 5\n",
            "crossover 2\n",
            "nu-metal 1\n",
            "pop and chart 5\n",
            "rap metal 2\n",
            "rap rock 1\n",
            "rapcore 2\n",
            "comedy 4\n",
            "boogie 2\n",
            "jazz-funk 8\n",
            "smooth soul 5\n",
            "welsh 1\n",
            "alternative 8\n",
            "bristol 1\n",
            "catch 1\n",
            "catch you 1\n",
            "chemical brothers 1\n",
            "club 2\n",
            "d&b 1\n",
            "damage 1\n",
            "dj fresh 1\n",
            "drum n bass 1\n",
            "drum&bass 1\n",
            "edm 6\n",
            "electronica 14\n",
            "faithless 1\n",
            "female vocalists 4\n",
            "guilty 1\n",
            "guitar 1\n",
            "hide u 1\n",
            "joni mitchell 1\n",
            "kokopelli 1\n",
            "kosheen 1\n",
            "kt tunstall 1\n",
            "louder 1\n",
            "massive attack 1\n",
            "moby 1\n",
            "moloko 1\n",
            "plastician 1\n",
            "resist 1\n",
            "roger shah 1\n",
            "royksopp 1\n",
            "sian evans 1\n",
            "trip hop 5\n",
            "trip rock 1\n",
            "_tidy 1\n",
            "ea 1\n",
            "game 2\n",
            "israeli 1\n",
            "score 3\n",
            "vgm 2\n",
            "video game 2\n",
            "video game music 1\n",
            "big dada 1\n",
            "post-grunge 10\n",
            "indie pop 19\n",
            "psychedelic pop 6\n",
            "gothic metal 2\n",
            "addme http://www.spotnicks.net/disco/first_release.htm 1\n",
            "freakbeat 2\n",
            "bitpop 1\n",
            "electropunk 1\n",
            "synth punk 1\n",
            "witch house 1\n",
            "electro 4\n",
            "jazz funk 2\n",
            "modal jazz 2\n",
            "space ambient 1\n",
            "ragtime 1\n",
            "piano pop 1\n",
            "gangsta rap 3\n",
            "christian hip hop 1\n",
            "christian pop 2\n",
            "scottish 7\n",
            "post-punk revival 2\n",
            "dance-rock 2\n",
            "england 8\n",
            "new romantic 5\n",
            "aor 6\n",
            "alternative-rock / grunge 1\n",
            "anxious 1\n",
            "complex 1\n",
            "depressive 1\n",
            "grunge 3\n",
            "male vocalists 4\n",
            "melancholic 1\n",
            "united states 5\n",
            "washington 1\n",
            "vocal house 1\n",
            "my rap world 1\n",
            "west coast hip hop 2\n",
            "film composer 4\n",
            "euro house 5\n",
            "eurodance 7\n",
            "hip house 3\n",
            "house 10\n",
            "cabaret 1\n",
            "chanson 3\n",
            "chanteuse réaliste 1\n",
            "neo-psychedelia 2\n",
            "noise rock 6\n",
            "industrial 10\n",
            "noise 3\n",
            "sound collage 1\n",
            "glam metal 9\n",
            "vallenato 1\n",
            "piano rock 2\n",
            "cumbia 1\n",
            "tropical 1\n",
            "dirty south 2\n",
            "southern hip hop 5\n",
            "breaks 1\n",
            "funky breaks 1\n",
            "unique style 1\n",
            "spanish tenor 1\n",
            "tenor 2\n",
            "sasscore 2\n",
            "idm 4\n",
            "murdered 1\n",
            "peace 1\n",
            "rock & roll 6\n",
            "grindcore 1\n",
            "mathcore 2\n",
            "jazz rock 11\n",
            "oxford 1\n",
            "bleep techno 1\n",
            "techno 6\n",
            "warp 7\n",
            "afrique du sud 1\n",
            "south africa 1\n",
            "south african 1\n",
            "sud-africain 1\n",
            "zulu 1\n",
            "hardcore hip hop 1\n",
            "hardcore hip-hop 1\n",
            "underground hip hop 1\n",
            "underground hip-hop 1\n",
            "instrumental hip hop 1\n",
            "dj 2\n",
            "france 3\n",
            "francophone 1\n",
            "français 2\n",
            "rock en espanol 1\n",
            "ska 6\n",
            "fixme label mess 1\n",
            "crunk 1\n",
            "snap 1\n",
            "iswcs pending 1\n",
            "minimal synth 3\n",
            "progressive house 1\n",
            "argentina 2\n",
            "otras canciones 1\n",
            "avant-garde 3\n",
            "kingston upon hull 1\n",
            "performance art 1\n",
            "post-industrial 2\n",
            "hip hop rnb and dance hall 3\n",
            "boy band 2\n",
            "bubblegum dance 4\n",
            "europop 6\n",
            "latin urban 1\n",
            "reggaeton 2\n",
            "pennsylvania 2\n",
            "1990s 3\n",
            "dancehall 2\n",
            "roots reggae 1\n",
            "world fusion 2\n",
            "latin rock 4\n",
            "belgian 2\n",
            "box set 1\n",
            "melodic hardcore 3\n",
            "old school hip hop 1\n",
            "1960s 3\n",
            "1970s 3\n",
            "1980s 4\n",
            "ballad 2\n",
            "bubblegum pop 3\n",
            "folk pop 8\n",
            "schlager 1\n",
            "acoustic 1\n",
            "americana 4\n",
            "hasta 1\n",
            "roots rock 1\n",
            "chamber pop 6\n",
            "power metal 7\n",
            "singer 5\n",
            "sweden 1\n",
            "vocalist 1\n",
            "glitch 2\n",
            "noise pop 3\n",
            "4ad 2\n",
            "indie 9\n",
            "alt-country 2\n",
            "cowpunk 1\n",
            "garage punk 3\n",
            "rock and roll 5\n",
            "southern rock 7\n",
            "funk metal 2\n",
            "prog related 3\n",
            "world music 1\n",
            "deep house 2\n",
            "uk garage 1\n",
            "quebec 1\n",
            "emo pop 2\n",
            "fort apache sound 1\n",
            "geek rock 1\n",
            "punk pop 1\n",
            "philly soul 1\n",
            "london 1\n",
            "synth pop 1\n",
            "2010s 4\n",
            "bass house 1\n",
            "comedy rap 1\n",
            "contemporary classical 2\n",
            "free jazz 6\n",
            "hardcore 2\n",
            "surf 1\n",
            "thrash 2\n",
            "grammy winner 2\n",
            "moombahton 1\n",
            "mangue beat 1\n",
            "soul and reggae 7\n",
            "brill building 1\n",
            "italo-disco 1\n",
            "bluegrass 4\n",
            "ich lieb' mich 1\n",
            "continental jazz 1\n",
            "gypsy jazz 1\n",
            "swing 4\n",
            "liverpool 1\n",
            "post-grunge grunge 1\n",
            "hamburg 2\n",
            "metalcore 5\n",
            "symphonic prog 3\n",
            "argentine rock 2\n",
            "crossover prog 1\n",
            "instrumental 4\n",
            "neo prog 1\n",
            "progressive metal 8\n",
            "northern irish 1\n",
            "chanson française 5\n",
            "french pop 1\n",
            "japan 2\n",
            "japanese 1\n",
            "kitaro 1\n",
            "new age 3\n",
            "lo-fi indie 3\n",
            "california 3\n",
            "simi valley 1\n",
            "british blues 1\n",
            "florida 1\n",
            "vero beach 1\n",
            "pop/rock 4\n",
            "blues-rock 1\n",
            "all-female 1\n",
            "groove metal 4\n",
            "n2 2\n",
            "new metal 1\n",
            "epic black metal 1\n",
            "symphonic black metal 1\n",
            "symphonic metal 3\n",
            "producer 5\n",
            "melodic metalcore 3\n",
            "progressive post-hardcore 1\n",
            "outsider 1\n",
            "classical crossover 3\n",
            "easy listening soundtracks and musicals 1\n",
            "album rock 1\n",
            "alternative/indie rock 1\n",
            "alternative pop 2\n",
            "hi-nrg 2\n",
            "contemporary country 2\n",
            "dark metal 1\n",
            "ebm 2\n",
            "swiss 2\n",
            "switzerland 3\n",
            "*tombouctou→gourma-rharous→rharous 1\n",
            "french singer 3\n",
            "alternative dance 5\n",
            "dvd 1\n",
            "glam rock 2\n",
            "à ranger 1\n",
            "neo rockabilly 1\n",
            "alternative/stoner-rock 1\n",
            "desert rock 1\n",
            "stoner metal 2\n",
            "stoner rock 4\n",
            "trombone 1\n",
            "awesomename 2\n",
            "grebo 1\n",
            "pianist 4\n",
            "germany 2\n",
            "no wave 3\n",
            "latin ballad 2\n",
            "history 1\n",
            "motorcycles 1\n",
            "mythology 2\n",
            "nwobhm 1\n",
            "rock/metal 1\n",
            "jewish 1\n",
            "new york 1\n",
            "reggae-pop 2\n",
            "religious 1\n",
            "rhythmic 1\n",
            "spiritual 1\n",
            "west coast rock 1\n",
            "yacht rock 4\n",
            "slowcore 2\n",
            "italo dance 1\n",
            "italo house 1\n",
            "italy 1\n",
            "heavy psych 2\n",
            "ndw 1\n",
            "neue deutsche welle 2\n",
            "sternenhimmel 1\n",
            "latin jazz 3\n",
            "acid trance 1\n",
            "sludge metal 4\n",
            "asian 1\n",
            "brit pop 1\n",
            "british asian 1\n",
            "indian 1\n",
            "vocal jazz 1\n",
            "human issues 1\n",
            "neoclassical metal 2\n",
            "religion 1\n",
            "science fiction 1\n",
            "post punk 1\n",
            "acid rock 1\n",
            "folk-rock 1\n",
            "experimental pop 2\n",
            "independent 1\n",
            "novelty 1\n",
            "finland 2\n",
            "mariachi 1\n",
            "mexico 1\n",
            "p-funk 1\n",
            "emo-pop 1\n",
            "powerpop 1\n",
            "american mezzo-soprano 1\n",
            "mezzo-soprano 2\n",
            "post rock 2\n",
            "gothic 3\n",
            "country music 1\n",
            "deutschrock 2\n",
            "splitme 1\n",
            "basque 1\n",
            "spain 1\n",
            "spoken word 3\n",
            "scotland 1\n",
            "american orchestra 1\n",
            "orchestra 2\n",
            "symphony orchestra 2\n",
            "ambient techno 1\n",
            "méxico 1\n",
            "crust punk 1\n",
            "arabic 1\n",
            "broadway composer 1\n",
            "afrobeat 1\n",
            "lounge 2\n",
            "aggressive 1\n",
            "atmospheric sludge metal 1\n",
            "crossover thrash 2\n",
            "heavy 1\n",
            "maryland 1\n",
            "metallic hardcore 1\n",
            "thrashcore 1\n",
            "big band 2\n",
            "slap bass 1\n",
            "black 'n' roll 1\n",
            "conductor 2\n",
            "french composer 1\n",
            "french conductor 1\n",
            "mahler 1\n",
            "king's x 1\n",
            "polish 3\n",
            "mpb 2\n",
            "boogie rock 2\n",
            "goa trance 1\n",
            "psy-trance 1\n",
            "hiphop 1\n",
            "rapper 1\n",
            "us 2\n",
            "60s 2\n",
            "abbey road 1\n",
            "british invasion 2\n",
            "europe 1\n",
            "merseybeat 1\n",
            "psychedelic/garage 1\n",
            "proto-punk 1\n",
            "dance-punk 1\n",
            "steve brown 1\n",
            "free improvisation 3\n",
            "black-metal / avantgarde 1\n",
            "dissonant 1\n",
            "motown 3\n",
            "contemporary jazz 5\n",
            "electro-industrial 1\n",
            "beat music 1\n",
            "sunshine pop 2\n",
            "queercore 1\n",
            "punk blues 2\n",
            "united kingdom 1\n",
            "liquid funk 1\n",
            "chanson à texte 2\n",
            "monaco 1\n",
            "c86 1\n",
            "goth 1\n",
            "goth rock 1\n",
            "gothic rock 2\n",
            "boom bap 1\n",
            "chamber jazz 1\n",
            "instrumental rock 1\n",
            "new acoustic music 1\n",
            "new-age 1\n",
            "western classical music 1\n",
            "chicago house 1\n",
            "avant-garde metal 1\n",
            "awe︎some 1\n",
            "swing metal 1\n",
            "swingmetal 1\n",
            "director 1\n",
            "dutch conductor 1\n",
            "dutch violinist 1\n",
            "mozart 1\n",
            "rhythm and blues 5\n",
            "female vocals 1\n",
            "melodic 1\n",
            "operatic metal 1\n",
            "symphonic power metal 1\n",
            "cup of tea 1\n",
            "ninja tune 2\n",
            "los angeles 1\n",
            "aln-sh 1\n",
            "bachata 3\n",
            "hauntology 1\n",
            "minimalism 1\n",
            "tape music 1\n",
            "icelandic 1\n",
            "jazz-rock 1\n",
            "hip-house 1\n",
            "apocalyptic folk 1\n",
            "avant-folk 1\n",
            "neofolk 1\n",
            "proto-prog 1\n",
            "rock opera 1\n",
            "fairlight cmi 1\n",
            "sampledelia 1\n",
            "dark 1\n",
            "lgbtqi 1\n",
            "80s thrash metal 1\n",
            "classic metal 1\n",
            "classic thrash metal 1\n",
            "teutonic thrash metal 1\n",
            "dreants 1\n",
            "low german 1\n",
            "low saxon 1\n",
            "riot grrrl 1\n",
            "cumbia mexicana 1\n",
            "norteño 1\n",
            "regional mexicano 1\n",
            "tejano 1\n",
            "hindustani classical 1\n",
            "tabla 1\n",
            "neoclassical new age 1\n",
            "persian pop 1\n",
            "netherlands 2\n",
            "nederbeat 1\n",
            "nederpop 1\n",
            "psych folk 1\n",
            "deep soul 1\n",
            "the queen of soul 1\n",
            "french rock 2\n",
            "latin alternative 1\n",
            "rock en español 1\n",
            "ska punk 2\n",
            "worldbeat 1\n",
            "german pianist 1\n",
            "electro house 2\n",
            "new orleans blues 1\n",
            "swamp blues 1\n",
            "crooner 1\n",
            "a cappella 3\n",
            "experimental folk 1\n",
            "post-core 1\n",
            "post-metal 1\n",
            "southern metal 2\n",
            "rocksteady 1\n",
            "70s 2\n",
            "nu-jazz 1\n",
            "palm desert scene 1\n",
            "retro rock 1\n",
            "sludge 1\n",
            "chillout 2\n",
            "actor 2\n",
            "minimal 1\n",
            "tech house 1\n",
            "progressive electronic 3\n",
            "space 1\n",
            "close harmony 1\n",
            "progressive metalcore 1\n",
            "progressive-metal / metalcore 1\n",
            "kabarett 1\n",
            "klamauk 1\n",
            "musical comedy 1\n",
            "chanteur 1\n",
            "guitarist 1\n",
            "guitariste 1\n",
            "ireland 1\n",
            "irlandais 1\n",
            "irlande 1\n",
            "actress 1\n",
            "progressive bluegrass 2\n",
            "the netherlands 1\n",
            "french house 1\n",
            "italian tenor 1\n",
            "opera 1\n",
            "bolero 1\n",
            "son cubano 1\n",
            "skam 1\n",
            "eurovision 1\n",
            "a capella 1\n",
            "aussie 1\n",
            "dutch trance 1\n",
            "seen live 1\n",
            "futurepop 2\n",
            "new wave synth pop 1\n",
            "synth rock 1\n",
            "new zealand 1\n",
            "garage rock revival 2\n",
            "am 1\n",
            "female singer 1\n",
            "sophisti-pop 2\n",
            "argentinian rock 1\n",
            "latin american rock 1\n",
            "latin pop/rock 1\n",
            "trap rap 3\n",
            "british violinist 1\n",
            "british violist 1\n",
            "violist 1\n",
            "dark cabaret 1\n",
            "industrial/electro 1\n",
            "atmospheric black metal 1\n",
            "depressive black metal 1\n",
            "conscious 1\n",
            "political hip hop 1\n",
            "hammond 1\n",
            "x factor 1\n",
            "instrumental jazz 1\n",
            "trumpeter 1\n",
            "technical prog metal 1\n",
            "comedy rock 2\n",
            "jam 1\n",
            "monte vallier 1\n",
            "ruminator audio 1\n",
            "florence and the machine 1\n",
            "delta blues 1\n",
            "hill country blues 1\n",
            "anti-rock 1\n",
            "michigan 1\n",
            "death by stroke 1\n",
            "jamaican singer 1\n",
            "jamaican songwriter 1\n",
            "songwriter 1\n",
            "teen pop 1\n",
            "piano pop rock 1\n",
            "producteur 1\n",
            "accordion 1\n",
            "pizza 1\n",
            "polka 1\n",
            "ponycore 1\n",
            "silly name 1\n",
            "star 1\n",
            "string quartet 1\n",
            "glamour rock 1\n",
            "epic 1\n",
            "iranian 1\n",
            "orchestral 2\n",
            "never been to spain 1\n",
            "sillyname alias 1\n",
            "modern country 1\n",
            "celtic metal 1\n",
            "folk metal 1\n",
            "film producer 1\n",
            "supergroup 1\n",
            "italian pop 1\n",
            "progressive pop 1\n",
            "soul blues 2\n",
            "soul-blues 1\n",
            "urban blues 1\n",
            "minimal wave 1\n",
            "chopped and screwed 1\n",
            "hustle 1\n",
            "hyphy 1\n",
            "trap 1\n",
            "goy 1\n",
            "goy karamelo 1\n",
            "mendoza 1\n",
            "progressive folk 1\n",
            "rock in opposition 1\n",
            "future jazz 1\n",
            "nu jazz 1\n",
            "easycore 1\n",
            "27 club 1\n",
            "speed metal 3\n",
            "southern rap 1\n",
            "blackened death metal 1\n",
            "christian 1\n",
            "christian metal 1\n",
            "glam 3\n",
            "alternative singer/songwriter 1\n",
            "winnipeg 1\n",
            "technical thrash metal 1\n",
            "new jersey 1\n",
            "technical 1\n",
            "unites states 1\n",
            "virtuoso 1\n",
            "puerto rican 1\n",
            "twee pop 1\n",
            "northern soul 1\n",
            "poggers 1\n",
            "symphonic rock 1\n",
            "pub rock 1\n",
            "danemark 1\n",
            "danois 1\n",
            "denmark 1\n",
            "scandinave 1\n",
            "scandinavia 1\n",
            "scandinavian 1\n",
            "scandinavie 1\n",
            "math rock 1\n",
            "jour d'hiver 1\n",
            "us power metal 1\n",
            "alternative hardcore 1\n",
            "brazil 1\n",
            "tropicália 1\n",
            "nashville sound 1\n",
            "dance pop 1\n",
            "crack rock steady 1\n",
            "clean up 1\n",
            "protest song 1\n",
            "classic 1\n",
            "hungarian 1\n",
            "hungarian composer 1\n",
            "hungary 1\n",
            "magyar 1\n",
            "romantic 1\n",
            "romantic classical 1\n",
            "rnb 1\n",
            "avant garde 1\n",
            "contemporary classic 1\n",
            "contemporary piano 1\n",
            "electroacustic 1\n",
            "modern classic. 1\n",
            "neoclassical 1\n",
            "postclassical 1\n",
            "hamburger schule 1\n"
          ]
        }
      ],
      "source": [
        "for k in ol.occurrencies:\n",
        "    print(k, ol.occurrencies[k])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbd20535",
      "metadata": {
        "id": "cbd20535"
      },
      "source": [
        "## Loading of the dataset Olga\n",
        "\n",
        " - In the next cell there is the raw dataset provided by the paper's authors **'Artist similarity with Graph Neural Networks'**.\n",
        " - Along the columns we have information about the [Musicbrainz_id](https://musicbrainz.org/) of an artist, its partition in the dataset (train,val,test), and the [AcousticBrainz](https://acousticbrainz.org/) low level features of the artist, taken from a sample of 25 songs. \n",
        " - Unfortunately, at the best of our efforts, it was not possible to recover all the information that were described in the [paper](https://arxiv.org/pdf/2107.14541.pdf). Indeed the artists contained in Olga are 17.673, whereas we were able to extract [Allmusic](https://www.allmusic.com/) ids only from 11.261 artists. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9c407599",
      "metadata": {
        "id": "9c407599"
      },
      "outputs": [],
      "source": [
        "olga=pd.read_csv('olga.csv')\n",
        "#train 0-14138, #val 14139-15905, #test 15906-17673 (indices)\n",
        "olga[:30]\n",
        "\n",
        "mbr.auth('ggiamp', 'fallinggiant')\n",
        "mbr.set_useragent(\n",
        "    \"python-musicbrainzngs-example\",\n",
        "    \"0.1\",\n",
        "    \"https://github.com/alastair/python-musicbrainzngs/\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96d08e8a",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "08648966",
      "metadata": {
        "id": "08648966"
      },
      "source": [
        "### How do we retrieve the Graph topology?\n",
        "\n",
        "- Thanks to the musicbrainz_id of each artist, we can get the link to its AllMusic profile, and from there we get also the information about its related artists. Each AllMusic link is related to a unique artist, indeed we can spot a 12 numbers identifier for each of these.\n",
        "- After having obtained the AllMusic link for each artist in the dataset (if exists), we want to associate to each artist its related ones. We do this just for those that can be re-mapped in the dataset's musicbrainz_ids, because we have associated tracks features for those.\n",
        "- Also this passage is probably very lossy, in fact, for each artist there could be a lot of similar artists (according to the AllMusic information), but we don't have the feature vectors for all of them.\n",
        "- The following class contains methods that extract information about all the artists in the dataset, but the price to pay is a high computational cost. \n",
        "For this reason it was run just once, and the information was stored in different files, such as 'MsbMapped.json', 'graphSimilarities.json', 'dizofartist.json'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "3712d1b8",
      "metadata": {
        "id": "3712d1b8",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "class DatasetOlga(): #In this class, we obtain through different methods the main characteristics of the graph of artists\n",
        "                    # thanks to the available information in the olga dataset\n",
        "    def __init__(self,olga):\n",
        "        self.olga=olga\n",
        "        self.mb=olga.musicbrainz_id\n",
        "        self.artists={} #Needed for obtaining the mapping from musicbrainz to the allmusic ids\n",
        "        self.l=len(self.mb)\n",
        "        self.d={}       #Needed for obtaining a dict. where keys are artists, and values are the artists similar to them, based on self.artists\n",
        "        self.NI={}      #Dict. that will contain the artist's features\n",
        "    \n",
        "    def get_mapping(self,i):                                                                                                 #This method returns the allmusic page of an artist (if exists), given his id from the dataset \n",
        "        response = requests.get(f'https://musicbrainz.org/ws/2/artist/{str(self.mb[i])}?inc=url-rels&fmt=json')\n",
        "        if response.ok:\n",
        "            data = response.json()\n",
        "            refs = [r['url']['resource'] for r in data['relations'] if r['type'] == 'allmusic']        \n",
        "            return refs[0] if len(refs) != 0 else \"Not found\"\n",
        "\n",
        "    def get_artist_name(self,i):                                                                                                 #This method returns the allmusic page of an artist (if exists), given his id from the dataset \n",
        "        response = requests.get(f'https://musicbrainz.org/ws/2/artist/{str(self.mb[i])}?inc=url-rels&fmt=json')\n",
        "        if response.ok:\n",
        "            data = response.json()\n",
        "            data = dict(data)\n",
        "            return data['name']\n",
        "\n",
        "\n",
        "\n",
        "    def get_mappingList(self,init,end,increm=500):\n",
        "        Lmusicbrainz_id=self.mb[init:end] #We can specify the range of the artists of our interest, for the purpose of this NN task\n",
        "        length=len(Lmusicbrainz_id)       #we will take all of them into consideration.\n",
        "        c=0\n",
        "        for i in range(len(Lmusicbrainz_id)):\n",
        "            mapp=self.get_mapping(i)   #get_mapping method again.\n",
        "            if mapp==None:\n",
        "                while mapp==None:\n",
        "                    mapp=self.get_mapping(i)\n",
        "                    \n",
        "            if mapp!=\"Not found\":   #Some of the ids has not a respective allmusic id, so we lose that information\n",
        "                mapp=str(mapp)      #Mapp are strings of links\n",
        "                key=mapp[-12:]\n",
        "                self.artists[key]=i\n",
        "            c+=1\n",
        "            if c%increm==0 or c==30:\n",
        "                    print(\"{}/{} artists were processed\".format(c,length)) #This is just to keep track of the processed artist\n",
        "                    \n",
        "            \n",
        "        self.save_data(self.artists,'MsbMapped1.json')  #We do save the Artists Ids map, this function, when called, takes a lot\n",
        "                                                        #of time, for this reason its result is already saved in the file:\n",
        "        return self.artists                             # 'MsbMapped1.json'\n",
        "    \n",
        "    \n",
        "    def get_GraphDict(self,name='MsbMapped.json',increm=500):\n",
        "        session=HTMLSession()\n",
        "        c=0 #Counter\n",
        "        artID=self.load_data(name) #We load the mapped artists (between MusicBrainz Ids, and AllMusic Ids)\n",
        "        # print(len(artID)\n",
        "        length=len(artID.keys())\n",
        "        for k in artID.keys(): #dict of mapped mbids, this has to be computed before from getmapping\n",
        "            if k!=None:\n",
        "                url='https://www.allmusic.com/artist/'+ k+ '/related' #k is just the code, every link for the artist is distinguished \n",
        "                r=session.get(url)                                    #by a unique code in the link.\n",
        "                sess=r.html.find('body',first=True)\n",
        "                div=sess.find('.overflow-container')                  #The information of the related artists are exctracted\n",
        "                divn=div[0]                                           #from the html of the allmusic's related web page\n",
        "                divn=divn.find('.content-container')\n",
        "                divn=divn[0]\n",
        "                divn=divn.find('.content')\n",
        "                divn=divn[0]\n",
        "                divn=divn.find('section',first=True)\n",
        "                if divn==None:\n",
        "                    self.d[artID[k]]=[] #That artist has not related artists (or we have missing information)\n",
        "                    continue\n",
        "                artists=divn.find('li')\n",
        "                artistL=[]\n",
        "\n",
        "\n",
        "                for i in range(len(artists)):\n",
        "                    art=artists[i]\n",
        "                    art=art.find('a')            #We look for all the k's related artists links\n",
        "                    link=list(art[0].absolute_links)[0] #Absolute_link returns a one-element set, that we convert into a list and\n",
        "                    link=str(link)[-12:]                #we get its code\n",
        "                    if link in artID.keys(): #g is the dict of all the mapped musicbrainz_ids\n",
        "                        artistL.append(self.artists[link]) #Some of the related artists may not be in the musicbrainz_ids list.\n",
        "                self.d[artID[k]]=artistL\n",
        "                c+=1\n",
        "                if c%increm==0 or c==30:\n",
        "                    print(\"{}/{} artists were processed\".format(c,length))\n",
        "        self.save_data(self.d,'graphSimilarities1.json') #Here we save the connection amongst the artists, obtained with this method\n",
        "        print(\"Done...\")     #Also it takes some time to process, for this reason the result of this method can be \n",
        "        return self.d        #found at the 'graphSimilarities.json' file.\n",
        "\n",
        "    def get_genres(self,name='MsbMapped.json',increm=500):\n",
        "        \n",
        "        c=0 #Counter\n",
        "        artID=self.load_data(name) #We load the mapped artists (between MusicBrainz Ids, and AllMusic Ids)\n",
        "        valid_ids = sorted(list(artID.values()))\n",
        "        self.occurrencies = {}\n",
        "        self.artist_genre = {}\n",
        "        print('Num of artist: {}', len(valid_ids))\n",
        "        self.lost = 0\n",
        "        for artist_num in range(len(valid_ids)):\n",
        "          print(len(self.occurrencies))\n",
        "          print('Artist {}/{}'.format(artist_num, len(valid_ids)))\n",
        "          art_id = self.olga.iloc[valid_ids[artist_num], 1]\n",
        "          result = mbr.get_artist_by_id(art_id,\n",
        "              includes=['tags'])\n",
        "          \n",
        "          if 'tag-list' in result['artist']:\n",
        "            genre_list = [genre['name'] for genre in result['artist']['tag-list']]\n",
        "            self.artist_genre[artist_num] = genre_list, result['artist']['name']\n",
        "            for genre in genre_list:\n",
        "              if genre not in self.occurrencies:\n",
        "                self.occurrencies[genre] = 1\n",
        "              else:\n",
        "                self.occurrencies[genre] += 1\n",
        "          else:\n",
        "            self.lost += 1\n",
        "            print('Lost artist {}'.format(self.lost))\n",
        "            self.artist_genre[artist_num] = [], result['artist']['name']\n",
        "\n",
        "\n",
        "        return \n",
        "\n",
        "    def get_artist_genres(self,name='MsbMapped.json',increm=500):\n",
        "        c=0 #Counter\n",
        "        artID=self.load_data(name) #We load the mapped artists (between MusicBrainz Ids, and AllMusic Ids)\n",
        "        valid_ids = sorted(list(artID.values()))\n",
        "        return artID\n",
        "    \n",
        "    def save_data(self,dicti,name):\n",
        "        jfile = open(name, \"w\")\n",
        "        jfile = json.dump(dicti, jfile)\n",
        "    \n",
        "    def load_data(self,name):\n",
        "        jfile = open(name, \"r\")\n",
        "        dicti = json.load(jfile)\n",
        "        return dicti\n",
        "ol = DatasetOlga(olga)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "PrIWLDo63SQ5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrIWLDo63SQ5",
        "outputId": "45c069e7-b9ca-4af1-af22-b5f96a9cf15b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num of artist: {} 11261\n",
            "0\n",
            "Artist 0/11261\n",
            "Lost artist 1\n",
            "0\n",
            "Artist 1/11261\n",
            "3\n",
            "Artist 2/11261\n",
            "5\n",
            "Artist 3/11261\n",
            "23\n",
            "Artist 4/11261\n",
            "Lost artist 2\n",
            "23\n",
            "Artist 5/11261\n",
            "Lost artist 3\n",
            "23\n",
            "Artist 6/11261\n",
            "25\n",
            "Artist 7/11261\n",
            "29\n",
            "Artist 8/11261\n",
            "30\n",
            "Artist 9/11261\n",
            "31\n",
            "Artist 10/11261\n",
            "33\n",
            "Artist 11/11261\n",
            "36\n",
            "Artist 12/11261\n",
            "38\n",
            "Artist 13/11261\n",
            "Lost artist 4\n",
            "38\n",
            "Artist 14/11261\n",
            "41\n",
            "Artist 15/11261\n",
            "42\n",
            "Artist 16/11261\n",
            "48\n",
            "Artist 17/11261\n",
            "48\n",
            "Artist 18/11261\n",
            "Lost artist 5\n",
            "48\n",
            "Artist 19/11261\n",
            "57\n",
            "Artist 20/11261\n",
            "Lost artist 6\n",
            "57\n",
            "Artist 21/11261\n",
            "58\n",
            "Artist 22/11261\n",
            "59\n",
            "Artist 23/11261\n",
            "Lost artist 7\n",
            "59\n",
            "Artist 24/11261\n",
            "67\n",
            "Artist 25/11261\n",
            "71\n",
            "Artist 26/11261\n",
            "71\n",
            "Artist 27/11261\n",
            "71\n",
            "Artist 28/11261\n",
            "77\n",
            "Artist 29/11261\n",
            "Lost artist 8\n",
            "77\n",
            "Artist 30/11261\n",
            "83\n",
            "Artist 31/11261\n",
            "83\n",
            "Artist 32/11261\n",
            "84\n",
            "Artist 33/11261\n",
            "86\n",
            "Artist 34/11261\n",
            "Lost artist 9\n",
            "86\n",
            "Artist 35/11261\n",
            "87\n",
            "Artist 36/11261\n",
            "88\n",
            "Artist 37/11261\n",
            "Lost artist 10\n",
            "88\n",
            "Artist 38/11261\n",
            "92\n",
            "Artist 39/11261\n",
            "92\n",
            "Artist 40/11261\n",
            "92\n",
            "Artist 41/11261\n",
            "93\n",
            "Artist 42/11261\n",
            "Lost artist 11\n",
            "93\n",
            "Artist 43/11261\n",
            "Lost artist 12\n",
            "93\n",
            "Artist 44/11261\n",
            "93\n",
            "Artist 45/11261\n",
            "94\n",
            "Artist 46/11261\n",
            "102\n",
            "Artist 47/11261\n",
            "102\n",
            "Artist 48/11261\n",
            "105\n",
            "Artist 49/11261\n",
            "108\n",
            "Artist 50/11261\n",
            "111\n",
            "Artist 51/11261\n",
            "113\n",
            "Artist 52/11261\n",
            "Lost artist 13\n",
            "113\n",
            "Artist 53/11261\n",
            "114\n",
            "Artist 54/11261\n",
            "Lost artist 14\n",
            "114\n",
            "Artist 55/11261\n",
            "115\n",
            "Artist 56/11261\n",
            "119\n",
            "Artist 57/11261\n",
            "122\n",
            "Artist 58/11261\n",
            "Lost artist 15\n",
            "122\n",
            "Artist 59/11261\n",
            "122\n",
            "Artist 60/11261\n",
            "127\n",
            "Artist 61/11261\n",
            "129\n",
            "Artist 62/11261\n",
            "129\n",
            "Artist 63/11261\n",
            "129\n",
            "Artist 64/11261\n",
            "130\n",
            "Artist 65/11261\n",
            "133\n",
            "Artist 66/11261\n",
            "133\n",
            "Artist 67/11261\n",
            "Lost artist 16\n",
            "133\n",
            "Artist 68/11261\n",
            "Lost artist 17\n",
            "133\n",
            "Artist 69/11261\n",
            "136\n",
            "Artist 70/11261\n",
            "Lost artist 18\n",
            "136\n",
            "Artist 71/11261\n",
            "137\n",
            "Artist 72/11261\n",
            "144\n",
            "Artist 73/11261\n",
            "147\n",
            "Artist 74/11261\n",
            "148\n",
            "Artist 75/11261\n",
            "149\n",
            "Artist 76/11261\n",
            "151\n",
            "Artist 77/11261\n",
            "154\n",
            "Artist 78/11261\n",
            "156\n",
            "Artist 79/11261\n",
            "156\n",
            "Artist 80/11261\n",
            "159\n",
            "Artist 81/11261\n",
            "161\n",
            "Artist 82/11261\n",
            "162\n",
            "Artist 83/11261\n",
            "164\n",
            "Artist 84/11261\n",
            "165\n",
            "Artist 85/11261\n",
            "169\n",
            "Artist 86/11261\n",
            "171\n",
            "Artist 87/11261\n",
            "Lost artist 19\n",
            "171\n",
            "Artist 88/11261\n",
            "171\n",
            "Artist 89/11261\n",
            "171\n",
            "Artist 90/11261\n",
            "172\n",
            "Artist 91/11261\n",
            "173\n",
            "Artist 92/11261\n",
            "179\n",
            "Artist 93/11261\n",
            "182\n",
            "Artist 94/11261\n",
            "182\n",
            "Artist 95/11261\n",
            "182\n",
            "Artist 96/11261\n",
            "183\n",
            "Artist 97/11261\n",
            "185\n",
            "Artist 98/11261\n",
            "186\n",
            "Artist 99/11261\n",
            "189\n",
            "Artist 100/11261\n",
            "191\n",
            "Artist 101/11261\n",
            "Lost artist 20\n",
            "191\n",
            "Artist 102/11261\n",
            "194\n",
            "Artist 103/11261\n",
            "197\n",
            "Artist 104/11261\n",
            "Lost artist 21\n",
            "197\n",
            "Artist 105/11261\n",
            "198\n",
            "Artist 106/11261\n",
            "199\n",
            "Artist 107/11261\n",
            "Lost artist 22\n",
            "199\n",
            "Artist 108/11261\n",
            "200\n",
            "Artist 109/11261\n",
            "Lost artist 23\n",
            "200\n",
            "Artist 110/11261\n",
            "Lost artist 24\n",
            "200\n",
            "Artist 111/11261\n",
            "Lost artist 25\n",
            "200\n",
            "Artist 112/11261\n",
            "200\n",
            "Artist 113/11261\n",
            "Lost artist 26\n",
            "200\n",
            "Artist 114/11261\n",
            "203\n",
            "Artist 115/11261\n",
            "203\n",
            "Artist 116/11261\n",
            "206\n",
            "Artist 117/11261\n",
            "207\n",
            "Artist 118/11261\n",
            "Lost artist 27\n",
            "207\n",
            "Artist 119/11261\n",
            "208\n",
            "Artist 120/11261\n",
            "210\n",
            "Artist 121/11261\n",
            "210\n",
            "Artist 122/11261\n",
            "214\n",
            "Artist 123/11261\n",
            "215\n",
            "Artist 124/11261\n",
            "215\n",
            "Artist 125/11261\n",
            "216\n",
            "Artist 126/11261\n",
            "Lost artist 28\n",
            "216\n",
            "Artist 127/11261\n",
            "218\n",
            "Artist 128/11261\n",
            "221\n",
            "Artist 129/11261\n",
            "221\n",
            "Artist 130/11261\n",
            "Lost artist 29\n",
            "221\n",
            "Artist 131/11261\n",
            "223\n",
            "Artist 132/11261\n",
            "227\n",
            "Artist 133/11261\n",
            "227\n",
            "Artist 134/11261\n",
            "228\n",
            "Artist 135/11261\n",
            "Lost artist 30\n",
            "228\n",
            "Artist 136/11261\n",
            "229\n",
            "Artist 137/11261\n",
            "Lost artist 31\n",
            "229\n",
            "Artist 138/11261\n",
            "Lost artist 32\n",
            "229\n",
            "Artist 139/11261\n",
            "231\n",
            "Artist 140/11261\n",
            "232\n",
            "Artist 141/11261\n",
            "232\n",
            "Artist 142/11261\n",
            "232\n",
            "Artist 143/11261\n",
            "232\n",
            "Artist 144/11261\n",
            "234\n",
            "Artist 145/11261\n",
            "234\n",
            "Artist 146/11261\n",
            "234\n",
            "Artist 147/11261\n",
            "Lost artist 33\n",
            "234\n",
            "Artist 148/11261\n",
            "234\n",
            "Artist 149/11261\n",
            "Lost artist 34\n",
            "234\n",
            "Artist 150/11261\n",
            "Lost artist 35\n",
            "234\n",
            "Artist 151/11261\n",
            "237\n",
            "Artist 152/11261\n",
            "237\n",
            "Artist 153/11261\n",
            "239\n",
            "Artist 154/11261\n",
            "241\n",
            "Artist 155/11261\n",
            "243\n",
            "Artist 156/11261\n",
            "Lost artist 36\n",
            "243\n",
            "Artist 157/11261\n",
            "243\n",
            "Artist 158/11261\n",
            "Lost artist 37\n",
            "243\n",
            "Artist 159/11261\n",
            "243\n",
            "Artist 160/11261\n",
            "243\n",
            "Artist 161/11261\n",
            "Lost artist 38\n",
            "243\n",
            "Artist 162/11261\n",
            "244\n",
            "Artist 163/11261\n",
            "248\n",
            "Artist 164/11261\n",
            "248\n",
            "Artist 165/11261\n",
            "248\n",
            "Artist 166/11261\n",
            "Lost artist 39\n",
            "248\n",
            "Artist 167/11261\n",
            "Lost artist 40\n",
            "248\n",
            "Artist 168/11261\n",
            "249\n",
            "Artist 169/11261\n",
            "251\n",
            "Artist 170/11261\n",
            "Lost artist 41\n",
            "251\n",
            "Artist 171/11261\n",
            "251\n",
            "Artist 172/11261\n",
            "Lost artist 42\n",
            "251\n",
            "Artist 173/11261\n",
            "253\n",
            "Artist 174/11261\n",
            "255\n",
            "Artist 175/11261\n",
            "255\n",
            "Artist 176/11261\n",
            "261\n",
            "Artist 177/11261\n",
            "261\n",
            "Artist 178/11261\n",
            "262\n",
            "Artist 179/11261\n",
            "Lost artist 43\n",
            "262\n",
            "Artist 180/11261\n",
            "262\n",
            "Artist 181/11261\n",
            "Lost artist 44\n",
            "262\n",
            "Artist 182/11261\n",
            "265\n",
            "Artist 183/11261\n",
            "265\n",
            "Artist 184/11261\n",
            "265\n",
            "Artist 185/11261\n",
            "266\n",
            "Artist 186/11261\n",
            "299\n",
            "Artist 187/11261\n",
            "Lost artist 45\n",
            "299\n",
            "Artist 188/11261\n",
            "Lost artist 46\n",
            "299\n",
            "Artist 189/11261\n",
            "Lost artist 47\n",
            "299\n",
            "Artist 190/11261\n",
            "299\n",
            "Artist 191/11261\n",
            "299\n",
            "Artist 192/11261\n",
            "307\n",
            "Artist 193/11261\n",
            "Lost artist 48\n",
            "307\n",
            "Artist 194/11261\n",
            "308\n",
            "Artist 195/11261\n",
            "Lost artist 49\n",
            "308\n",
            "Artist 196/11261\n",
            "308\n",
            "Artist 197/11261\n",
            "308\n",
            "Artist 198/11261\n",
            "308\n",
            "Artist 199/11261\n",
            "Lost artist 50\n",
            "308\n",
            "Artist 200/11261\n",
            "309\n",
            "Artist 201/11261\n",
            "311\n",
            "Artist 202/11261\n",
            "312\n",
            "Artist 203/11261\n",
            "313\n",
            "Artist 204/11261\n",
            "313\n",
            "Artist 205/11261\n",
            "313\n",
            "Artist 206/11261\n",
            "313\n",
            "Artist 207/11261\n",
            "314\n",
            "Artist 208/11261\n",
            "Lost artist 51\n",
            "314\n",
            "Artist 209/11261\n",
            "318\n",
            "Artist 210/11261\n",
            "Lost artist 52\n",
            "318\n",
            "Artist 211/11261\n",
            "Lost artist 53\n",
            "318\n",
            "Artist 212/11261\n",
            "321\n",
            "Artist 213/11261\n",
            "321\n",
            "Artist 214/11261\n",
            "322\n",
            "Artist 215/11261\n",
            "323\n",
            "Artist 216/11261\n",
            "323\n",
            "Artist 217/11261\n",
            "323\n",
            "Artist 218/11261\n",
            "Lost artist 54\n",
            "323\n",
            "Artist 219/11261\n",
            "Lost artist 55\n",
            "323\n",
            "Artist 220/11261\n",
            "Lost artist 56\n",
            "323\n",
            "Artist 221/11261\n",
            "Lost artist 57\n",
            "323\n",
            "Artist 222/11261\n",
            "323\n",
            "Artist 223/11261\n",
            "324\n",
            "Artist 224/11261\n",
            "324\n",
            "Artist 225/11261\n",
            "Lost artist 58\n",
            "324\n",
            "Artist 226/11261\n",
            "324\n",
            "Artist 227/11261\n",
            "325\n",
            "Artist 228/11261\n",
            "327\n",
            "Artist 229/11261\n",
            "327\n",
            "Artist 230/11261\n",
            "328\n",
            "Artist 231/11261\n",
            "329\n",
            "Artist 232/11261\n",
            "329\n",
            "Artist 233/11261\n",
            "332\n",
            "Artist 234/11261\n",
            "333\n",
            "Artist 235/11261\n",
            "333\n",
            "Artist 236/11261\n",
            "Lost artist 59\n",
            "333\n",
            "Artist 237/11261\n",
            "Lost artist 60\n",
            "333\n",
            "Artist 238/11261\n",
            "333\n",
            "Artist 239/11261\n",
            "342\n",
            "Artist 240/11261\n",
            "Lost artist 61\n",
            "342\n",
            "Artist 241/11261\n",
            "342\n",
            "Artist 242/11261\n",
            "342\n",
            "Artist 243/11261\n",
            "Lost artist 62\n",
            "342\n",
            "Artist 244/11261\n",
            "343\n",
            "Artist 245/11261\n",
            "Lost artist 63\n",
            "343\n",
            "Artist 246/11261\n",
            "345\n",
            "Artist 247/11261\n",
            "346\n",
            "Artist 248/11261\n",
            "350\n",
            "Artist 249/11261\n",
            "353\n",
            "Artist 250/11261\n",
            "355\n",
            "Artist 251/11261\n",
            "355\n",
            "Artist 252/11261\n",
            "Lost artist 64\n",
            "355\n",
            "Artist 253/11261\n",
            "Lost artist 65\n",
            "355\n",
            "Artist 254/11261\n",
            "Lost artist 66\n",
            "355\n",
            "Artist 255/11261\n",
            "355\n",
            "Artist 256/11261\n",
            "358\n",
            "Artist 257/11261\n",
            "Lost artist 67\n",
            "358\n",
            "Artist 258/11261\n",
            "359\n",
            "Artist 259/11261\n",
            "359\n",
            "Artist 260/11261\n",
            "359\n",
            "Artist 261/11261\n",
            "Lost artist 68\n",
            "359\n",
            "Artist 262/11261\n",
            "360\n",
            "Artist 263/11261\n",
            "360\n",
            "Artist 264/11261\n",
            "360\n",
            "Artist 265/11261\n",
            "Lost artist 69\n",
            "360\n",
            "Artist 266/11261\n",
            "Lost artist 70\n",
            "360\n",
            "Artist 267/11261\n",
            "361\n",
            "Artist 268/11261\n",
            "Lost artist 71\n",
            "361\n",
            "Artist 269/11261\n",
            "361\n",
            "Artist 270/11261\n",
            "Lost artist 72\n",
            "361\n",
            "Artist 271/11261\n",
            "363\n",
            "Artist 272/11261\n",
            "363\n",
            "Artist 273/11261\n",
            "Lost artist 73\n",
            "363\n",
            "Artist 274/11261\n",
            "365\n",
            "Artist 275/11261\n",
            "368\n",
            "Artist 276/11261\n",
            "370\n",
            "Artist 277/11261\n",
            "370\n",
            "Artist 278/11261\n",
            "371\n",
            "Artist 279/11261\n",
            "Lost artist 74\n",
            "371\n",
            "Artist 280/11261\n",
            "Lost artist 75\n",
            "371\n",
            "Artist 281/11261\n",
            "Lost artist 76\n",
            "371\n",
            "Artist 282/11261\n",
            "372\n",
            "Artist 283/11261\n",
            "372\n",
            "Artist 284/11261\n",
            "375\n",
            "Artist 285/11261\n",
            "375\n",
            "Artist 286/11261\n",
            "377\n",
            "Artist 287/11261\n",
            "377\n",
            "Artist 288/11261\n",
            "377\n",
            "Artist 289/11261\n",
            "378\n",
            "Artist 290/11261\n",
            "379\n",
            "Artist 291/11261\n",
            "382\n",
            "Artist 292/11261\n",
            "387\n",
            "Artist 293/11261\n",
            "Lost artist 77\n",
            "387\n",
            "Artist 294/11261\n",
            "Lost artist 78\n",
            "387\n",
            "Artist 295/11261\n",
            "387\n",
            "Artist 296/11261\n",
            "Lost artist 79\n",
            "387\n",
            "Artist 297/11261\n",
            "391\n",
            "Artist 298/11261\n",
            "Lost artist 80\n",
            "391\n",
            "Artist 299/11261\n",
            "392\n",
            "Artist 300/11261\n",
            "396\n",
            "Artist 301/11261\n",
            "396\n",
            "Artist 302/11261\n",
            "396\n",
            "Artist 303/11261\n",
            "398\n",
            "Artist 304/11261\n",
            "Lost artist 81\n",
            "398\n",
            "Artist 305/11261\n",
            "Lost artist 82\n",
            "398\n",
            "Artist 306/11261\n",
            "399\n",
            "Artist 307/11261\n",
            "399\n",
            "Artist 308/11261\n",
            "401\n",
            "Artist 309/11261\n",
            "Lost artist 83\n",
            "401\n",
            "Artist 310/11261\n",
            "401\n",
            "Artist 311/11261\n",
            "Lost artist 84\n",
            "401\n",
            "Artist 312/11261\n",
            "403\n",
            "Artist 313/11261\n",
            "Lost artist 85\n",
            "403\n",
            "Artist 314/11261\n",
            "403\n",
            "Artist 315/11261\n",
            "403\n",
            "Artist 316/11261\n",
            "403\n",
            "Artist 317/11261\n",
            "403\n",
            "Artist 318/11261\n",
            "404\n",
            "Artist 319/11261\n",
            "404\n",
            "Artist 320/11261\n",
            "Lost artist 86\n",
            "404\n",
            "Artist 321/11261\n",
            "406\n",
            "Artist 322/11261\n",
            "410\n",
            "Artist 323/11261\n",
            "410\n",
            "Artist 324/11261\n",
            "410\n",
            "Artist 325/11261\n",
            "Lost artist 87\n",
            "410\n",
            "Artist 326/11261\n",
            "410\n",
            "Artist 327/11261\n",
            "410\n",
            "Artist 328/11261\n",
            "411\n",
            "Artist 329/11261\n",
            "411\n",
            "Artist 330/11261\n",
            "411\n",
            "Artist 331/11261\n",
            "Lost artist 88\n",
            "411\n",
            "Artist 332/11261\n",
            "411\n",
            "Artist 333/11261\n",
            "411\n",
            "Artist 334/11261\n",
            "412\n",
            "Artist 335/11261\n",
            "412\n",
            "Artist 336/11261\n",
            "414\n",
            "Artist 337/11261\n",
            "414\n",
            "Artist 338/11261\n",
            "416\n",
            "Artist 339/11261\n",
            "416\n",
            "Artist 340/11261\n",
            "Lost artist 89\n",
            "416\n",
            "Artist 341/11261\n",
            "417\n",
            "Artist 342/11261\n",
            "421\n",
            "Artist 343/11261\n",
            "421\n",
            "Artist 344/11261\n",
            "Lost artist 90\n",
            "421\n",
            "Artist 345/11261\n",
            "Lost artist 91\n",
            "421\n",
            "Artist 346/11261\n",
            "422\n",
            "Artist 347/11261\n",
            "423\n",
            "Artist 348/11261\n",
            "424\n",
            "Artist 349/11261\n",
            "424\n",
            "Artist 350/11261\n",
            "Lost artist 92\n",
            "424\n",
            "Artist 351/11261\n",
            "Lost artist 93\n",
            "424\n",
            "Artist 352/11261\n",
            "425\n",
            "Artist 353/11261\n",
            "Lost artist 94\n",
            "425\n",
            "Artist 354/11261\n",
            "426\n",
            "Artist 355/11261\n",
            "426\n",
            "Artist 356/11261\n",
            "433\n",
            "Artist 357/11261\n",
            "433\n",
            "Artist 358/11261\n",
            "437\n",
            "Artist 359/11261\n",
            "438\n",
            "Artist 360/11261\n",
            "439\n",
            "Artist 361/11261\n",
            "442\n",
            "Artist 362/11261\n",
            "442\n",
            "Artist 363/11261\n",
            "442\n",
            "Artist 364/11261\n",
            "442\n",
            "Artist 365/11261\n",
            "442\n",
            "Artist 366/11261\n",
            "443\n",
            "Artist 367/11261\n",
            "443\n",
            "Artist 368/11261\n",
            "Lost artist 95\n",
            "443\n",
            "Artist 369/11261\n",
            "Lost artist 96\n",
            "443\n",
            "Artist 370/11261\n",
            "444\n",
            "Artist 371/11261\n",
            "446\n",
            "Artist 372/11261\n",
            "Lost artist 97\n",
            "446\n",
            "Artist 373/11261\n",
            "Lost artist 98\n",
            "446\n",
            "Artist 374/11261\n",
            "451\n",
            "Artist 375/11261\n",
            "453\n",
            "Artist 376/11261\n",
            "453\n",
            "Artist 377/11261\n",
            "454\n",
            "Artist 378/11261\n",
            "454\n",
            "Artist 379/11261\n",
            "455\n",
            "Artist 380/11261\n",
            "456\n",
            "Artist 381/11261\n",
            "457\n",
            "Artist 382/11261\n",
            "461\n",
            "Artist 383/11261\n",
            "461\n",
            "Artist 384/11261\n",
            "461\n",
            "Artist 385/11261\n",
            "462\n",
            "Artist 386/11261\n",
            "Lost artist 99\n",
            "462\n",
            "Artist 387/11261\n",
            "462\n",
            "Artist 388/11261\n",
            "Lost artist 100\n",
            "462\n",
            "Artist 389/11261\n",
            "462\n",
            "Artist 390/11261\n",
            "464\n",
            "Artist 391/11261\n",
            "464\n",
            "Artist 392/11261\n",
            "Lost artist 101\n",
            "464\n",
            "Artist 393/11261\n",
            "464\n",
            "Artist 394/11261\n",
            "466\n",
            "Artist 395/11261\n",
            "466\n",
            "Artist 396/11261\n",
            "466\n",
            "Artist 397/11261\n",
            "466\n",
            "Artist 398/11261\n",
            "Lost artist 102\n",
            "466\n",
            "Artist 399/11261\n",
            "466\n",
            "Artist 400/11261\n",
            "466\n",
            "Artist 401/11261\n",
            "467\n",
            "Artist 402/11261\n",
            "467\n",
            "Artist 403/11261\n",
            "467\n",
            "Artist 404/11261\n",
            "472\n",
            "Artist 405/11261\n",
            "474\n",
            "Artist 406/11261\n",
            "474\n",
            "Artist 407/11261\n",
            "474\n",
            "Artist 408/11261\n",
            "Lost artist 103\n",
            "474\n",
            "Artist 409/11261\n",
            "475\n",
            "Artist 410/11261\n",
            "Lost artist 104\n",
            "475\n",
            "Artist 411/11261\n",
            "476\n",
            "Artist 412/11261\n",
            "Lost artist 105\n",
            "476\n",
            "Artist 413/11261\n",
            "476\n",
            "Artist 414/11261\n",
            "477\n",
            "Artist 415/11261\n",
            "Lost artist 106\n",
            "477\n",
            "Artist 416/11261\n",
            "Lost artist 107\n",
            "477\n",
            "Artist 417/11261\n",
            "478\n",
            "Artist 418/11261\n",
            "478\n",
            "Artist 419/11261\n",
            "Lost artist 108\n",
            "478\n",
            "Artist 420/11261\n",
            "478\n",
            "Artist 421/11261\n",
            "478\n",
            "Artist 422/11261\n",
            "Lost artist 109\n",
            "478\n",
            "Artist 423/11261\n",
            "Lost artist 110\n",
            "478\n",
            "Artist 424/11261\n",
            "479\n",
            "Artist 425/11261\n",
            "479\n",
            "Artist 426/11261\n",
            "480\n",
            "Artist 427/11261\n",
            "480\n",
            "Artist 428/11261\n",
            "Lost artist 111\n",
            "480\n",
            "Artist 429/11261\n",
            "Lost artist 112\n",
            "480\n",
            "Artist 430/11261\n",
            "483\n",
            "Artist 431/11261\n",
            "484\n",
            "Artist 432/11261\n",
            "484\n",
            "Artist 433/11261\n",
            "484\n",
            "Artist 434/11261\n",
            "485\n",
            "Artist 435/11261\n",
            "485\n",
            "Artist 436/11261\n",
            "485\n",
            "Artist 437/11261\n",
            "485\n",
            "Artist 438/11261\n",
            "Lost artist 113\n",
            "485\n",
            "Artist 439/11261\n",
            "Lost artist 114\n",
            "485\n",
            "Artist 440/11261\n",
            "Lost artist 115\n",
            "485\n",
            "Artist 441/11261\n",
            "485\n",
            "Artist 442/11261\n",
            "486\n",
            "Artist 443/11261\n",
            "487\n",
            "Artist 444/11261\n",
            "488\n",
            "Artist 445/11261\n",
            "488\n",
            "Artist 446/11261\n",
            "Lost artist 116\n",
            "488\n",
            "Artist 447/11261\n",
            "489\n",
            "Artist 448/11261\n",
            "493\n",
            "Artist 449/11261\n",
            "Lost artist 117\n",
            "493\n",
            "Artist 450/11261\n",
            "Lost artist 118\n",
            "493\n",
            "Artist 451/11261\n",
            "493\n",
            "Artist 452/11261\n",
            "493\n",
            "Artist 453/11261\n",
            "493\n",
            "Artist 454/11261\n",
            "Lost artist 119\n",
            "493\n",
            "Artist 455/11261\n",
            "493\n",
            "Artist 456/11261\n",
            "493\n",
            "Artist 457/11261\n",
            "494\n",
            "Artist 458/11261\n",
            "494\n",
            "Artist 459/11261\n",
            "Lost artist 120\n",
            "494\n",
            "Artist 460/11261\n",
            "496\n",
            "Artist 461/11261\n",
            "500\n",
            "Artist 462/11261\n",
            "Lost artist 121\n",
            "500\n",
            "Artist 463/11261\n",
            "Lost artist 122\n",
            "500\n",
            "Artist 464/11261\n",
            "Lost artist 123\n",
            "500\n",
            "Artist 465/11261\n",
            "Lost artist 124\n",
            "500\n",
            "Artist 466/11261\n",
            "Lost artist 125\n",
            "500\n",
            "Artist 467/11261\n",
            "501\n",
            "Artist 468/11261\n",
            "503\n",
            "Artist 469/11261\n",
            "Lost artist 126\n",
            "503\n",
            "Artist 470/11261\n",
            "503\n",
            "Artist 471/11261\n",
            "503\n",
            "Artist 472/11261\n",
            "504\n",
            "Artist 473/11261\n",
            "506\n",
            "Artist 474/11261\n",
            "506\n",
            "Artist 475/11261\n",
            "507\n",
            "Artist 476/11261\n",
            "507\n",
            "Artist 477/11261\n",
            "508\n",
            "Artist 478/11261\n",
            "Lost artist 127\n",
            "508\n",
            "Artist 479/11261\n",
            "512\n",
            "Artist 480/11261\n",
            "512\n",
            "Artist 481/11261\n",
            "512\n",
            "Artist 482/11261\n",
            "515\n",
            "Artist 483/11261\n",
            "516\n",
            "Artist 484/11261\n",
            "Lost artist 128\n",
            "516\n",
            "Artist 485/11261\n",
            "516\n",
            "Artist 486/11261\n",
            "518\n",
            "Artist 487/11261\n",
            "518\n",
            "Artist 488/11261\n",
            "518\n",
            "Artist 489/11261\n",
            "518\n",
            "Artist 490/11261\n",
            "519\n",
            "Artist 491/11261\n",
            "519\n",
            "Artist 492/11261\n",
            "519\n",
            "Artist 493/11261\n",
            "519\n",
            "Artist 494/11261\n",
            "521\n",
            "Artist 495/11261\n",
            "521\n",
            "Artist 496/11261\n",
            "523\n",
            "Artist 497/11261\n",
            "Lost artist 129\n",
            "523\n",
            "Artist 498/11261\n",
            "523\n",
            "Artist 499/11261\n",
            "525\n",
            "Artist 500/11261\n",
            "525\n",
            "Artist 501/11261\n",
            "526\n",
            "Artist 502/11261\n",
            "Lost artist 130\n",
            "526\n",
            "Artist 503/11261\n",
            "526\n",
            "Artist 504/11261\n",
            "Lost artist 131\n",
            "526\n",
            "Artist 505/11261\n",
            "526\n",
            "Artist 506/11261\n",
            "Lost artist 132\n",
            "526\n",
            "Artist 507/11261\n",
            "Lost artist 133\n",
            "526\n",
            "Artist 508/11261\n",
            "526\n",
            "Artist 509/11261\n",
            "526\n",
            "Artist 510/11261\n",
            "Lost artist 134\n",
            "526\n",
            "Artist 511/11261\n",
            "530\n",
            "Artist 512/11261\n",
            "530\n",
            "Artist 513/11261\n",
            "530\n",
            "Artist 514/11261\n",
            "530\n",
            "Artist 515/11261\n",
            "530\n",
            "Artist 516/11261\n",
            "532\n",
            "Artist 517/11261\n",
            "536\n",
            "Artist 518/11261\n",
            "Lost artist 135\n",
            "536\n",
            "Artist 519/11261\n",
            "Lost artist 136\n",
            "536\n",
            "Artist 520/11261\n",
            "536\n",
            "Artist 521/11261\n",
            "537\n",
            "Artist 522/11261\n",
            "537\n",
            "Artist 523/11261\n",
            "537\n",
            "Artist 524/11261\n",
            "537\n",
            "Artist 525/11261\n",
            "541\n",
            "Artist 526/11261\n",
            "541\n",
            "Artist 527/11261\n",
            "541\n",
            "Artist 528/11261\n",
            "541\n",
            "Artist 529/11261\n",
            "542\n",
            "Artist 530/11261\n",
            "542\n",
            "Artist 531/11261\n",
            "Lost artist 137\n",
            "542\n",
            "Artist 532/11261\n",
            "Lost artist 138\n",
            "542\n",
            "Artist 533/11261\n",
            "542\n",
            "Artist 534/11261\n",
            "543\n",
            "Artist 535/11261\n",
            "Lost artist 139\n",
            "543\n",
            "Artist 536/11261\n",
            "543\n",
            "Artist 537/11261\n",
            "543\n",
            "Artist 538/11261\n",
            "543\n",
            "Artist 539/11261\n",
            "544\n",
            "Artist 540/11261\n",
            "Lost artist 140\n",
            "544\n",
            "Artist 541/11261\n",
            "544\n",
            "Artist 542/11261\n",
            "545\n",
            "Artist 543/11261\n",
            "Lost artist 141\n",
            "545\n",
            "Artist 544/11261\n",
            "545\n",
            "Artist 545/11261\n",
            "545\n",
            "Artist 546/11261\n",
            "546\n",
            "Artist 547/11261\n",
            "546\n",
            "Artist 548/11261\n",
            "546\n",
            "Artist 549/11261\n",
            "Lost artist 142\n",
            "546\n",
            "Artist 550/11261\n",
            "Lost artist 143\n",
            "546\n",
            "Artist 551/11261\n",
            "Lost artist 144\n",
            "546\n",
            "Artist 552/11261\n",
            "Lost artist 145\n",
            "546\n",
            "Artist 553/11261\n",
            "547\n",
            "Artist 554/11261\n",
            "548\n",
            "Artist 555/11261\n",
            "Lost artist 146\n",
            "548\n",
            "Artist 556/11261\n",
            "Lost artist 147\n",
            "548\n",
            "Artist 557/11261\n",
            "548\n",
            "Artist 558/11261\n",
            "553\n",
            "Artist 559/11261\n",
            "Lost artist 148\n",
            "553\n",
            "Artist 560/11261\n",
            "559\n",
            "Artist 561/11261\n",
            "561\n",
            "Artist 562/11261\n",
            "561\n",
            "Artist 563/11261\n",
            "562\n",
            "Artist 564/11261\n",
            "562\n",
            "Artist 565/11261\n",
            "565\n",
            "Artist 566/11261\n",
            "566\n",
            "Artist 567/11261\n",
            "566\n",
            "Artist 568/11261\n",
            "569\n",
            "Artist 569/11261\n",
            "569\n",
            "Artist 570/11261\n",
            "Lost artist 149\n",
            "569\n",
            "Artist 571/11261\n",
            "569\n",
            "Artist 572/11261\n",
            "570\n",
            "Artist 573/11261\n",
            "570\n",
            "Artist 574/11261\n",
            "Lost artist 150\n",
            "570\n",
            "Artist 575/11261\n",
            "Lost artist 151\n",
            "570\n",
            "Artist 576/11261\n",
            "Lost artist 152\n",
            "570\n",
            "Artist 577/11261\n",
            "571\n",
            "Artist 578/11261\n",
            "572\n",
            "Artist 579/11261\n",
            "572\n",
            "Artist 580/11261\n",
            "Lost artist 153\n",
            "572\n",
            "Artist 581/11261\n",
            "Lost artist 154\n",
            "572\n",
            "Artist 582/11261\n",
            "576\n",
            "Artist 583/11261\n",
            "576\n",
            "Artist 584/11261\n",
            "576\n",
            "Artist 585/11261\n",
            "577\n",
            "Artist 586/11261\n",
            "581\n",
            "Artist 587/11261\n",
            "581\n",
            "Artist 588/11261\n",
            "582\n",
            "Artist 589/11261\n",
            "583\n",
            "Artist 590/11261\n",
            "Lost artist 155\n",
            "583\n",
            "Artist 591/11261\n",
            "584\n",
            "Artist 592/11261\n",
            "584\n",
            "Artist 593/11261\n",
            "584\n",
            "Artist 594/11261\n",
            "Lost artist 156\n",
            "584\n",
            "Artist 595/11261\n",
            "Lost artist 157\n",
            "584\n",
            "Artist 596/11261\n",
            "586\n",
            "Artist 597/11261\n",
            "587\n",
            "Artist 598/11261\n",
            "Lost artist 158\n",
            "587\n",
            "Artist 599/11261\n",
            "587\n",
            "Artist 600/11261\n",
            "588\n",
            "Artist 601/11261\n",
            "588\n",
            "Artist 602/11261\n",
            "Lost artist 159\n",
            "588\n",
            "Artist 603/11261\n",
            "590\n",
            "Artist 604/11261\n",
            "591\n",
            "Artist 605/11261\n",
            "593\n",
            "Artist 606/11261\n",
            "593\n",
            "Artist 607/11261\n",
            "593\n",
            "Artist 608/11261\n",
            "593\n",
            "Artist 609/11261\n",
            "593\n",
            "Artist 610/11261\n",
            "593\n",
            "Artist 611/11261\n",
            "595\n",
            "Artist 612/11261\n",
            "596\n",
            "Artist 613/11261\n",
            "Lost artist 160\n",
            "596\n",
            "Artist 614/11261\n",
            "596\n",
            "Artist 615/11261\n",
            "596\n",
            "Artist 616/11261\n",
            "Lost artist 161\n",
            "596\n",
            "Artist 617/11261\n",
            "Lost artist 162\n",
            "596\n",
            "Artist 618/11261\n",
            "596\n",
            "Artist 619/11261\n",
            "596\n",
            "Artist 620/11261\n",
            "596\n",
            "Artist 621/11261\n",
            "596\n",
            "Artist 622/11261\n",
            "Lost artist 163\n",
            "596\n",
            "Artist 623/11261\n",
            "Lost artist 164\n",
            "596\n",
            "Artist 624/11261\n",
            "Lost artist 165\n",
            "596\n",
            "Artist 625/11261\n",
            "Lost artist 166\n",
            "596\n",
            "Artist 626/11261\n",
            "596\n",
            "Artist 627/11261\n",
            "597\n",
            "Artist 628/11261\n",
            "598\n",
            "Artist 629/11261\n",
            "600\n",
            "Artist 630/11261\n",
            "Lost artist 167\n",
            "600\n",
            "Artist 631/11261\n",
            "602\n",
            "Artist 632/11261\n",
            "Lost artist 168\n",
            "602\n",
            "Artist 633/11261\n",
            "Lost artist 169\n",
            "602\n",
            "Artist 634/11261\n",
            "603\n",
            "Artist 635/11261\n",
            "604\n",
            "Artist 636/11261\n",
            "604\n",
            "Artist 637/11261\n",
            "604\n",
            "Artist 638/11261\n",
            "607\n",
            "Artist 639/11261\n",
            "607\n",
            "Artist 640/11261\n",
            "607\n",
            "Artist 641/11261\n",
            "608\n",
            "Artist 642/11261\n",
            "Lost artist 170\n",
            "608\n",
            "Artist 643/11261\n",
            "Lost artist 171\n",
            "608\n",
            "Artist 644/11261\n",
            "Lost artist 172\n",
            "608\n",
            "Artist 645/11261\n",
            "609\n",
            "Artist 646/11261\n",
            "610\n",
            "Artist 647/11261\n",
            "Lost artist 173\n",
            "610\n",
            "Artist 648/11261\n",
            "Lost artist 174\n",
            "610\n",
            "Artist 649/11261\n",
            "611\n",
            "Artist 650/11261\n",
            "611\n",
            "Artist 651/11261\n",
            "612\n",
            "Artist 652/11261\n",
            "614\n",
            "Artist 653/11261\n",
            "Lost artist 175\n",
            "614\n",
            "Artist 654/11261\n",
            "614\n",
            "Artist 655/11261\n",
            "614\n",
            "Artist 656/11261\n",
            "621\n",
            "Artist 657/11261\n",
            "622\n",
            "Artist 658/11261\n",
            "622\n",
            "Artist 659/11261\n",
            "622\n",
            "Artist 660/11261\n",
            "Lost artist 176\n",
            "622\n",
            "Artist 661/11261\n",
            "623\n",
            "Artist 662/11261\n",
            "623\n",
            "Artist 663/11261\n",
            "Lost artist 177\n",
            "623\n",
            "Artist 664/11261\n",
            "623\n",
            "Artist 665/11261\n",
            "Lost artist 178\n",
            "623\n",
            "Artist 666/11261\n",
            "Lost artist 179\n",
            "623\n",
            "Artist 667/11261\n",
            "623\n",
            "Artist 668/11261\n",
            "623\n",
            "Artist 669/11261\n",
            "623\n",
            "Artist 670/11261\n",
            "624\n",
            "Artist 671/11261\n",
            "624\n",
            "Artist 672/11261\n",
            "628\n",
            "Artist 673/11261\n",
            "628\n",
            "Artist 674/11261\n",
            "628\n",
            "Artist 675/11261\n",
            "628\n",
            "Artist 676/11261\n",
            "Lost artist 180\n",
            "628\n",
            "Artist 677/11261\n",
            "628\n",
            "Artist 678/11261\n",
            "Lost artist 181\n",
            "628\n",
            "Artist 679/11261\n",
            "628\n",
            "Artist 680/11261\n",
            "628\n",
            "Artist 681/11261\n",
            "628\n",
            "Artist 682/11261\n",
            "628\n",
            "Artist 683/11261\n",
            "628\n",
            "Artist 684/11261\n",
            "628\n",
            "Artist 685/11261\n",
            "Lost artist 182\n",
            "628\n",
            "Artist 686/11261\n",
            "628\n",
            "Artist 687/11261\n",
            "628\n",
            "Artist 688/11261\n",
            "629\n",
            "Artist 689/11261\n",
            "630\n",
            "Artist 690/11261\n",
            "Lost artist 183\n",
            "630\n",
            "Artist 691/11261\n",
            "Lost artist 184\n",
            "630\n",
            "Artist 692/11261\n",
            "631\n",
            "Artist 693/11261\n",
            "631\n",
            "Artist 694/11261\n",
            "632\n",
            "Artist 695/11261\n",
            "632\n",
            "Artist 696/11261\n",
            "634\n",
            "Artist 697/11261\n",
            "634\n",
            "Artist 698/11261\n",
            "Lost artist 185\n",
            "634\n",
            "Artist 699/11261\n",
            "Lost artist 186\n",
            "634\n",
            "Artist 700/11261\n",
            "634\n",
            "Artist 701/11261\n",
            "634\n",
            "Artist 702/11261\n",
            "Lost artist 187\n",
            "634\n",
            "Artist 703/11261\n",
            "Lost artist 188\n",
            "634\n",
            "Artist 704/11261\n",
            "634\n",
            "Artist 705/11261\n",
            "634\n",
            "Artist 706/11261\n",
            "634\n",
            "Artist 707/11261\n",
            "634\n",
            "Artist 708/11261\n",
            "634\n",
            "Artist 709/11261\n",
            "637\n",
            "Artist 710/11261\n",
            "637\n",
            "Artist 711/11261\n",
            "637\n",
            "Artist 712/11261\n",
            "643\n",
            "Artist 713/11261\n",
            "643\n",
            "Artist 714/11261\n",
            "644\n",
            "Artist 715/11261\n",
            "644\n",
            "Artist 716/11261\n",
            "645\n",
            "Artist 717/11261\n",
            "645\n",
            "Artist 718/11261\n",
            "646\n",
            "Artist 719/11261\n",
            "646\n",
            "Artist 720/11261\n",
            "Lost artist 189\n",
            "646\n",
            "Artist 721/11261\n",
            "646\n",
            "Artist 722/11261\n",
            "Lost artist 190\n",
            "646\n",
            "Artist 723/11261\n",
            "647\n",
            "Artist 724/11261\n",
            "647\n",
            "Artist 725/11261\n",
            "647\n",
            "Artist 726/11261\n",
            "647\n",
            "Artist 727/11261\n",
            "647\n",
            "Artist 728/11261\n",
            "649\n",
            "Artist 729/11261\n",
            "649\n",
            "Artist 730/11261\n",
            "649\n",
            "Artist 731/11261\n",
            "650\n",
            "Artist 732/11261\n",
            "651\n",
            "Artist 733/11261\n",
            "652\n",
            "Artist 734/11261\n",
            "652\n",
            "Artist 735/11261\n",
            "654\n",
            "Artist 736/11261\n",
            "655\n",
            "Artist 737/11261\n",
            "Lost artist 191\n",
            "655\n",
            "Artist 738/11261\n",
            "Lost artist 192\n",
            "655\n",
            "Artist 739/11261\n",
            "655\n",
            "Artist 740/11261\n",
            "655\n",
            "Artist 741/11261\n",
            "655\n",
            "Artist 742/11261\n",
            "656\n",
            "Artist 743/11261\n",
            "Lost artist 193\n",
            "656\n",
            "Artist 744/11261\n",
            "Lost artist 194\n",
            "656\n",
            "Artist 745/11261\n",
            "657\n",
            "Artist 746/11261\n",
            "Lost artist 195\n",
            "657\n",
            "Artist 747/11261\n",
            "657\n",
            "Artist 748/11261\n",
            "658\n",
            "Artist 749/11261\n",
            "Lost artist 196\n",
            "658\n",
            "Artist 750/11261\n",
            "658\n",
            "Artist 751/11261\n",
            "658\n",
            "Artist 752/11261\n",
            "658\n",
            "Artist 753/11261\n",
            "658\n",
            "Artist 754/11261\n",
            "658\n",
            "Artist 755/11261\n",
            "Lost artist 197\n",
            "658\n",
            "Artist 756/11261\n",
            "658\n",
            "Artist 757/11261\n",
            "658\n",
            "Artist 758/11261\n",
            "660\n",
            "Artist 759/11261\n",
            "660\n",
            "Artist 760/11261\n",
            "Lost artist 198\n",
            "660\n",
            "Artist 761/11261\n",
            "661\n",
            "Artist 762/11261\n",
            "Lost artist 199\n",
            "661\n",
            "Artist 763/11261\n",
            "664\n",
            "Artist 764/11261\n",
            "665\n",
            "Artist 765/11261\n",
            "670\n",
            "Artist 766/11261\n",
            "Lost artist 200\n",
            "670\n",
            "Artist 767/11261\n",
            "671\n",
            "Artist 768/11261\n",
            "Lost artist 201\n",
            "671\n",
            "Artist 769/11261\n",
            "Lost artist 202\n",
            "671\n",
            "Artist 770/11261\n",
            "671\n",
            "Artist 771/11261\n",
            "671\n",
            "Artist 772/11261\n",
            "Lost artist 203\n",
            "671\n",
            "Artist 773/11261\n",
            "Lost artist 204\n",
            "671\n",
            "Artist 774/11261\n",
            "675\n",
            "Artist 775/11261\n",
            "675\n",
            "Artist 776/11261\n",
            "Lost artist 205\n",
            "675\n",
            "Artist 777/11261\n",
            "675\n",
            "Artist 778/11261\n",
            "Lost artist 206\n",
            "675\n",
            "Artist 779/11261\n",
            "679\n",
            "Artist 780/11261\n",
            "679\n",
            "Artist 781/11261\n",
            "Lost artist 207\n",
            "679\n",
            "Artist 782/11261\n",
            "679\n",
            "Artist 783/11261\n",
            "Lost artist 208\n",
            "679\n",
            "Artist 784/11261\n",
            "680\n",
            "Artist 785/11261\n",
            "680\n",
            "Artist 786/11261\n",
            "680\n",
            "Artist 787/11261\n",
            "684\n",
            "Artist 788/11261\n",
            "686\n",
            "Artist 789/11261\n",
            "687\n",
            "Artist 790/11261\n",
            "Lost artist 209\n",
            "687\n",
            "Artist 791/11261\n",
            "688\n",
            "Artist 792/11261\n",
            "Lost artist 210\n",
            "688\n",
            "Artist 793/11261\n",
            "689\n",
            "Artist 794/11261\n",
            "689\n",
            "Artist 795/11261\n",
            "689\n",
            "Artist 796/11261\n",
            "689\n",
            "Artist 797/11261\n",
            "Lost artist 211\n",
            "689\n",
            "Artist 798/11261\n",
            "Lost artist 212\n",
            "689\n",
            "Artist 799/11261\n",
            "Lost artist 213\n",
            "689\n",
            "Artist 800/11261\n",
            "689\n",
            "Artist 801/11261\n",
            "689\n",
            "Artist 802/11261\n",
            "Lost artist 214\n",
            "689\n",
            "Artist 803/11261\n",
            "692\n",
            "Artist 804/11261\n",
            "692\n",
            "Artist 805/11261\n",
            "Lost artist 215\n",
            "692\n",
            "Artist 806/11261\n",
            "Lost artist 216\n",
            "692\n",
            "Artist 807/11261\n",
            "Lost artist 217\n",
            "692\n",
            "Artist 808/11261\n",
            "693\n",
            "Artist 809/11261\n",
            "694\n",
            "Artist 810/11261\n",
            "694\n",
            "Artist 811/11261\n",
            "694\n",
            "Artist 812/11261\n",
            "Lost artist 218\n",
            "694\n",
            "Artist 813/11261\n",
            "694\n",
            "Artist 814/11261\n",
            "695\n",
            "Artist 815/11261\n",
            "Lost artist 219\n",
            "695\n",
            "Artist 816/11261\n",
            "Lost artist 220\n",
            "695\n",
            "Artist 817/11261\n",
            "695\n",
            "Artist 818/11261\n",
            "695\n",
            "Artist 819/11261\n",
            "695\n",
            "Artist 820/11261\n",
            "695\n",
            "Artist 821/11261\n",
            "Lost artist 221\n",
            "695\n",
            "Artist 822/11261\n",
            "698\n",
            "Artist 823/11261\n",
            "700\n",
            "Artist 824/11261\n",
            "Lost artist 222\n",
            "700\n",
            "Artist 825/11261\n",
            "Lost artist 223\n",
            "700\n",
            "Artist 826/11261\n",
            "700\n",
            "Artist 827/11261\n",
            "702\n",
            "Artist 828/11261\n",
            "703\n",
            "Artist 829/11261\n",
            "703\n",
            "Artist 830/11261\n",
            "704\n",
            "Artist 831/11261\n",
            "Lost artist 224\n",
            "704\n",
            "Artist 832/11261\n",
            "704\n",
            "Artist 833/11261\n",
            "Lost artist 225\n",
            "704\n",
            "Artist 834/11261\n",
            "704\n",
            "Artist 835/11261\n",
            "704\n",
            "Artist 836/11261\n",
            "Lost artist 226\n",
            "704\n",
            "Artist 837/11261\n",
            "Lost artist 227\n",
            "704\n",
            "Artist 838/11261\n",
            "704\n",
            "Artist 839/11261\n",
            "704\n",
            "Artist 840/11261\n",
            "704\n",
            "Artist 841/11261\n",
            "708\n",
            "Artist 842/11261\n",
            "708\n",
            "Artist 843/11261\n",
            "Lost artist 228\n",
            "708\n",
            "Artist 844/11261\n",
            "708\n",
            "Artist 845/11261\n",
            "711\n",
            "Artist 846/11261\n",
            "711\n",
            "Artist 847/11261\n",
            "711\n",
            "Artist 848/11261\n",
            "712\n",
            "Artist 849/11261\n",
            "712\n",
            "Artist 850/11261\n",
            "716\n",
            "Artist 851/11261\n",
            "716\n",
            "Artist 852/11261\n",
            "Lost artist 229\n",
            "716\n",
            "Artist 853/11261\n",
            "716\n",
            "Artist 854/11261\n",
            "Lost artist 230\n",
            "716\n",
            "Artist 855/11261\n",
            "716\n",
            "Artist 856/11261\n",
            "716\n",
            "Artist 857/11261\n",
            "716\n",
            "Artist 858/11261\n",
            "718\n",
            "Artist 859/11261\n",
            "720\n",
            "Artist 860/11261\n",
            "720\n",
            "Artist 861/11261\n",
            "721\n",
            "Artist 862/11261\n",
            "723\n",
            "Artist 863/11261\n",
            "723\n",
            "Artist 864/11261\n",
            "Lost artist 231\n",
            "723\n",
            "Artist 865/11261\n",
            "723\n",
            "Artist 866/11261\n",
            "724\n",
            "Artist 867/11261\n",
            "Lost artist 232\n",
            "724\n",
            "Artist 868/11261\n",
            "726\n",
            "Artist 869/11261\n",
            "726\n",
            "Artist 870/11261\n",
            "Lost artist 233\n",
            "726\n",
            "Artist 871/11261\n",
            "726\n",
            "Artist 872/11261\n",
            "726\n",
            "Artist 873/11261\n",
            "731\n",
            "Artist 874/11261\n",
            "731\n",
            "Artist 875/11261\n",
            "732\n",
            "Artist 876/11261\n",
            "732\n",
            "Artist 877/11261\n",
            "732\n",
            "Artist 878/11261\n",
            "733\n",
            "Artist 879/11261\n",
            "733\n",
            "Artist 880/11261\n",
            "733\n",
            "Artist 881/11261\n",
            "Lost artist 234\n",
            "733\n",
            "Artist 882/11261\n",
            "733\n",
            "Artist 883/11261\n",
            "733\n",
            "Artist 884/11261\n",
            "Lost artist 235\n",
            "733\n",
            "Artist 885/11261\n",
            "Lost artist 236\n",
            "733\n",
            "Artist 886/11261\n",
            "Lost artist 237\n",
            "733\n",
            "Artist 887/11261\n",
            "735\n",
            "Artist 888/11261\n",
            "735\n",
            "Artist 889/11261\n",
            "Lost artist 238\n",
            "735\n",
            "Artist 890/11261\n",
            "735\n",
            "Artist 891/11261\n",
            "736\n",
            "Artist 892/11261\n",
            "737\n",
            "Artist 893/11261\n",
            "737\n",
            "Artist 894/11261\n",
            "Lost artist 239\n",
            "737\n",
            "Artist 895/11261\n",
            "737\n",
            "Artist 896/11261\n",
            "737\n",
            "Artist 897/11261\n",
            "738\n",
            "Artist 898/11261\n",
            "740\n",
            "Artist 899/11261\n",
            "741\n",
            "Artist 900/11261\n",
            "742\n",
            "Artist 901/11261\n",
            "743\n",
            "Artist 902/11261\n",
            "744\n",
            "Artist 903/11261\n",
            "Lost artist 240\n",
            "744\n",
            "Artist 904/11261\n",
            "744\n",
            "Artist 905/11261\n",
            "747\n",
            "Artist 906/11261\n",
            "747\n",
            "Artist 907/11261\n",
            "747\n",
            "Artist 908/11261\n",
            "748\n",
            "Artist 909/11261\n",
            "749\n",
            "Artist 910/11261\n",
            "751\n",
            "Artist 911/11261\n",
            "Lost artist 241\n",
            "751\n",
            "Artist 912/11261\n",
            "751\n",
            "Artist 913/11261\n",
            "753\n",
            "Artist 914/11261\n",
            "Lost artist 242\n",
            "753\n",
            "Artist 915/11261\n",
            "753\n",
            "Artist 916/11261\n",
            "753\n",
            "Artist 917/11261\n",
            "754\n",
            "Artist 918/11261\n",
            "754\n",
            "Artist 919/11261\n",
            "Lost artist 243\n",
            "754\n",
            "Artist 920/11261\n",
            "754\n",
            "Artist 921/11261\n",
            "754\n",
            "Artist 922/11261\n",
            "Lost artist 244\n",
            "754\n",
            "Artist 923/11261\n",
            "754\n",
            "Artist 924/11261\n",
            "754\n",
            "Artist 925/11261\n",
            "754\n",
            "Artist 926/11261\n",
            "756\n",
            "Artist 927/11261\n",
            "756\n",
            "Artist 928/11261\n",
            "756\n",
            "Artist 929/11261\n",
            "Lost artist 245\n",
            "756\n",
            "Artist 930/11261\n",
            "756\n",
            "Artist 931/11261\n",
            "756\n",
            "Artist 932/11261\n",
            "Lost artist 246\n",
            "756\n",
            "Artist 933/11261\n",
            "759\n",
            "Artist 934/11261\n",
            "Lost artist 247\n",
            "759\n",
            "Artist 935/11261\n",
            "759\n",
            "Artist 936/11261\n",
            "765\n",
            "Artist 937/11261\n",
            "765\n",
            "Artist 938/11261\n",
            "766\n",
            "Artist 939/11261\n",
            "766\n",
            "Artist 940/11261\n",
            "767\n",
            "Artist 941/11261\n",
            "768\n",
            "Artist 942/11261\n",
            "Lost artist 248\n",
            "768\n",
            "Artist 943/11261\n",
            "768\n",
            "Artist 944/11261\n",
            "Lost artist 249\n",
            "768\n",
            "Artist 945/11261\n",
            "768\n",
            "Artist 946/11261\n",
            "768\n",
            "Artist 947/11261\n",
            "768\n",
            "Artist 948/11261\n",
            "768\n",
            "Artist 949/11261\n",
            "768\n",
            "Artist 950/11261\n",
            "Lost artist 250\n",
            "768\n",
            "Artist 951/11261\n",
            "769\n",
            "Artist 952/11261\n",
            "769\n",
            "Artist 953/11261\n",
            "769\n",
            "Artist 954/11261\n",
            "769\n",
            "Artist 955/11261\n",
            "769\n",
            "Artist 956/11261\n",
            "Lost artist 251\n",
            "769\n",
            "Artist 957/11261\n",
            "771\n",
            "Artist 958/11261\n",
            "771\n",
            "Artist 959/11261\n",
            "Lost artist 252\n",
            "771\n",
            "Artist 960/11261\n",
            "773\n",
            "Artist 961/11261\n",
            "773\n",
            "Artist 962/11261\n",
            "774\n",
            "Artist 963/11261\n",
            "Lost artist 253\n",
            "774\n",
            "Artist 964/11261\n",
            "Lost artist 254\n",
            "774\n",
            "Artist 965/11261\n",
            "775\n",
            "Artist 966/11261\n",
            "775\n",
            "Artist 967/11261\n",
            "Lost artist 255\n",
            "775\n",
            "Artist 968/11261\n",
            "776\n",
            "Artist 969/11261\n",
            "776\n",
            "Artist 970/11261\n",
            "Lost artist 256\n",
            "776\n",
            "Artist 971/11261\n",
            "776\n",
            "Artist 972/11261\n",
            "776\n",
            "Artist 973/11261\n",
            "Lost artist 257\n",
            "776\n",
            "Artist 974/11261\n",
            "776\n",
            "Artist 975/11261\n",
            "776\n",
            "Artist 976/11261\n",
            "777\n",
            "Artist 977/11261\n",
            "Lost artist 258\n",
            "777\n",
            "Artist 978/11261\n",
            "777\n",
            "Artist 979/11261\n",
            "Lost artist 259\n",
            "777\n",
            "Artist 980/11261\n",
            "777\n",
            "Artist 981/11261\n",
            "Lost artist 260\n",
            "777\n",
            "Artist 982/11261\n",
            "777\n",
            "Artist 983/11261\n",
            "777\n",
            "Artist 984/11261\n",
            "777\n",
            "Artist 985/11261\n",
            "777\n",
            "Artist 986/11261\n",
            "Lost artist 261\n",
            "777\n",
            "Artist 987/11261\n",
            "779\n",
            "Artist 988/11261\n",
            "782\n",
            "Artist 989/11261\n",
            "Lost artist 262\n",
            "782\n",
            "Artist 990/11261\n",
            "782\n",
            "Artist 991/11261\n",
            "782\n",
            "Artist 992/11261\n",
            "Lost artist 263\n",
            "782\n",
            "Artist 993/11261\n",
            "782\n",
            "Artist 994/11261\n",
            "783\n",
            "Artist 995/11261\n",
            "783\n",
            "Artist 996/11261\n",
            "784\n",
            "Artist 997/11261\n",
            "787\n",
            "Artist 998/11261\n",
            "Lost artist 264\n",
            "787\n",
            "Artist 999/11261\n",
            "Lost artist 265\n",
            "787\n",
            "Artist 1000/11261\n",
            "Lost artist 266\n",
            "787\n",
            "Artist 1001/11261\n",
            "790\n",
            "Artist 1002/11261\n",
            "791\n",
            "Artist 1003/11261\n",
            "791\n",
            "Artist 1004/11261\n",
            "791\n",
            "Artist 1005/11261\n",
            "794\n",
            "Artist 1006/11261\n",
            "795\n",
            "Artist 1007/11261\n",
            "795\n",
            "Artist 1008/11261\n",
            "795\n",
            "Artist 1009/11261\n",
            "Lost artist 267\n",
            "795\n",
            "Artist 1010/11261\n",
            "Lost artist 268\n",
            "795\n",
            "Artist 1011/11261\n",
            "Lost artist 269\n",
            "795\n",
            "Artist 1012/11261\n",
            "Lost artist 270\n",
            "795\n",
            "Artist 1013/11261\n",
            "795\n",
            "Artist 1014/11261\n",
            "Lost artist 271\n",
            "795\n",
            "Artist 1015/11261\n",
            "796\n",
            "Artist 1016/11261\n",
            "798\n",
            "Artist 1017/11261\n",
            "798\n",
            "Artist 1018/11261\n",
            "798\n",
            "Artist 1019/11261\n",
            "798\n",
            "Artist 1020/11261\n",
            "800\n",
            "Artist 1021/11261\n",
            "800\n",
            "Artist 1022/11261\n",
            "801\n",
            "Artist 1023/11261\n",
            "801\n",
            "Artist 1024/11261\n",
            "801\n",
            "Artist 1025/11261\n",
            "Lost artist 272\n",
            "801\n",
            "Artist 1026/11261\n",
            "Lost artist 273\n",
            "801\n",
            "Artist 1027/11261\n",
            "801\n",
            "Artist 1028/11261\n",
            "801\n",
            "Artist 1029/11261\n",
            "801\n",
            "Artist 1030/11261\n",
            "801\n",
            "Artist 1031/11261\n",
            "801\n",
            "Artist 1032/11261\n",
            "801\n",
            "Artist 1033/11261\n",
            "Lost artist 274\n",
            "801\n",
            "Artist 1034/11261\n",
            "801\n",
            "Artist 1035/11261\n",
            "801\n",
            "Artist 1036/11261\n",
            "802\n",
            "Artist 1037/11261\n",
            "802\n",
            "Artist 1038/11261\n",
            "Lost artist 275\n",
            "802\n",
            "Artist 1039/11261\n",
            "Lost artist 276\n",
            "802\n",
            "Artist 1040/11261\n",
            "804\n",
            "Artist 1041/11261\n",
            "Lost artist 277\n",
            "804\n",
            "Artist 1042/11261\n",
            "804\n",
            "Artist 1043/11261\n",
            "805\n",
            "Artist 1044/11261\n",
            "Lost artist 278\n",
            "805\n",
            "Artist 1045/11261\n",
            "Lost artist 279\n",
            "805\n",
            "Artist 1046/11261\n",
            "805\n",
            "Artist 1047/11261\n",
            "805\n",
            "Artist 1048/11261\n",
            "806\n",
            "Artist 1049/11261\n",
            "806\n",
            "Artist 1050/11261\n",
            "806\n",
            "Artist 1051/11261\n",
            "806\n",
            "Artist 1052/11261\n",
            "807\n",
            "Artist 1053/11261\n",
            "807\n",
            "Artist 1054/11261\n",
            "807\n",
            "Artist 1055/11261\n",
            "807\n",
            "Artist 1056/11261\n",
            "807\n",
            "Artist 1057/11261\n",
            "807\n",
            "Artist 1058/11261\n",
            "Lost artist 280\n",
            "807\n",
            "Artist 1059/11261\n",
            "807\n",
            "Artist 1060/11261\n",
            "809\n",
            "Artist 1061/11261\n",
            "810\n",
            "Artist 1062/11261\n",
            "810\n",
            "Artist 1063/11261\n",
            "812\n",
            "Artist 1064/11261\n",
            "814\n",
            "Artist 1065/11261\n",
            "Lost artist 281\n",
            "814\n",
            "Artist 1066/11261\n",
            "Lost artist 282\n",
            "814\n",
            "Artist 1067/11261\n",
            "814\n",
            "Artist 1068/11261\n",
            "Lost artist 283\n",
            "814\n",
            "Artist 1069/11261\n",
            "814\n",
            "Artist 1070/11261\n",
            "814\n",
            "Artist 1071/11261\n",
            "814\n",
            "Artist 1072/11261\n",
            "Lost artist 284\n",
            "814\n",
            "Artist 1073/11261\n",
            "Lost artist 285\n",
            "814\n",
            "Artist 1074/11261\n",
            "Lost artist 286\n",
            "814\n",
            "Artist 1075/11261\n",
            "814\n",
            "Artist 1076/11261\n",
            "814\n",
            "Artist 1077/11261\n",
            "818\n",
            "Artist 1078/11261\n",
            "818\n",
            "Artist 1079/11261\n",
            "Lost artist 287\n",
            "818\n",
            "Artist 1080/11261\n",
            "Lost artist 288\n",
            "818\n",
            "Artist 1081/11261\n",
            "818\n",
            "Artist 1082/11261\n",
            "Lost artist 289\n",
            "818\n",
            "Artist 1083/11261\n",
            "Lost artist 290\n",
            "818\n",
            "Artist 1084/11261\n",
            "819\n",
            "Artist 1085/11261\n",
            "Lost artist 291\n",
            "819\n",
            "Artist 1086/11261\n",
            "819\n",
            "Artist 1087/11261\n",
            "821\n",
            "Artist 1088/11261\n",
            "821\n",
            "Artist 1089/11261\n",
            "821\n",
            "Artist 1090/11261\n",
            "821\n",
            "Artist 1091/11261\n",
            "Lost artist 292\n",
            "821\n",
            "Artist 1092/11261\n",
            "827\n",
            "Artist 1093/11261\n",
            "827\n",
            "Artist 1094/11261\n",
            "827\n",
            "Artist 1095/11261\n",
            "Lost artist 293\n",
            "827\n",
            "Artist 1096/11261\n",
            "Lost artist 294\n",
            "827\n",
            "Artist 1097/11261\n",
            "Lost artist 295\n",
            "827\n",
            "Artist 1098/11261\n",
            "828\n",
            "Artist 1099/11261\n",
            "Lost artist 296\n",
            "828\n",
            "Artist 1100/11261\n",
            "828\n",
            "Artist 1101/11261\n",
            "828\n",
            "Artist 1102/11261\n",
            "828\n",
            "Artist 1103/11261\n",
            "828\n",
            "Artist 1104/11261\n",
            "Lost artist 297\n",
            "828\n",
            "Artist 1105/11261\n",
            "828\n",
            "Artist 1106/11261\n",
            "829\n",
            "Artist 1107/11261\n",
            "Lost artist 298\n",
            "829\n",
            "Artist 1108/11261\n",
            "829\n",
            "Artist 1109/11261\n",
            "Lost artist 299\n",
            "829\n",
            "Artist 1110/11261\n",
            "829\n",
            "Artist 1111/11261\n",
            "829\n",
            "Artist 1112/11261\n",
            "829\n",
            "Artist 1113/11261\n",
            "829\n",
            "Artist 1114/11261\n",
            "Lost artist 300\n",
            "829\n",
            "Artist 1115/11261\n",
            "829\n",
            "Artist 1116/11261\n",
            "829\n",
            "Artist 1117/11261\n",
            "832\n",
            "Artist 1118/11261\n",
            "832\n",
            "Artist 1119/11261\n",
            "Lost artist 301\n",
            "832\n",
            "Artist 1120/11261\n",
            "833\n",
            "Artist 1121/11261\n",
            "834\n",
            "Artist 1122/11261\n",
            "835\n",
            "Artist 1123/11261\n",
            "837\n",
            "Artist 1124/11261\n",
            "Lost artist 302\n",
            "837\n",
            "Artist 1125/11261\n",
            "838\n",
            "Artist 1126/11261\n",
            "839\n",
            "Artist 1127/11261\n",
            "841\n",
            "Artist 1128/11261\n",
            "844\n",
            "Artist 1129/11261\n",
            "845\n",
            "Artist 1130/11261\n",
            "845\n",
            "Artist 1131/11261\n",
            "845\n",
            "Artist 1132/11261\n",
            "845\n",
            "Artist 1133/11261\n",
            "845\n",
            "Artist 1134/11261\n",
            "845\n",
            "Artist 1135/11261\n",
            "Lost artist 303\n",
            "845\n",
            "Artist 1136/11261\n",
            "845\n",
            "Artist 1137/11261\n",
            "845\n",
            "Artist 1138/11261\n",
            "845\n",
            "Artist 1139/11261\n",
            "845\n",
            "Artist 1140/11261\n",
            "845\n",
            "Artist 1141/11261\n",
            "849\n",
            "Artist 1142/11261\n",
            "Lost artist 304\n",
            "849\n",
            "Artist 1143/11261\n",
            "849\n",
            "Artist 1144/11261\n",
            "Lost artist 305\n",
            "849\n",
            "Artist 1145/11261\n",
            "849\n",
            "Artist 1146/11261\n",
            "849\n",
            "Artist 1147/11261\n",
            "852\n",
            "Artist 1148/11261\n",
            "852\n",
            "Artist 1149/11261\n",
            "853\n",
            "Artist 1150/11261\n",
            "854\n",
            "Artist 1151/11261\n",
            "856\n",
            "Artist 1152/11261\n",
            "856\n",
            "Artist 1153/11261\n",
            "856\n",
            "Artist 1154/11261\n",
            "856\n",
            "Artist 1155/11261\n",
            "Lost artist 306\n",
            "856\n",
            "Artist 1156/11261\n",
            "857\n",
            "Artist 1157/11261\n",
            "Lost artist 307\n",
            "857\n",
            "Artist 1158/11261\n",
            "Lost artist 308\n",
            "857\n",
            "Artist 1159/11261\n",
            "857\n",
            "Artist 1160/11261\n",
            "857\n",
            "Artist 1161/11261\n",
            "857\n",
            "Artist 1162/11261\n",
            "Lost artist 309\n",
            "857\n",
            "Artist 1163/11261\n",
            "Lost artist 310\n",
            "857\n",
            "Artist 1164/11261\n",
            "Lost artist 311\n",
            "857\n",
            "Artist 1165/11261\n",
            "858\n",
            "Artist 1166/11261\n",
            "858\n",
            "Artist 1167/11261\n",
            "858\n",
            "Artist 1168/11261\n",
            "858\n",
            "Artist 1169/11261\n",
            "858\n",
            "Artist 1170/11261\n",
            "Lost artist 312\n",
            "858\n",
            "Artist 1171/11261\n",
            "858\n",
            "Artist 1172/11261\n",
            "Lost artist 313\n",
            "858\n",
            "Artist 1173/11261\n",
            "858\n",
            "Artist 1174/11261\n",
            "859\n",
            "Artist 1175/11261\n",
            "859\n",
            "Artist 1176/11261\n",
            "859\n",
            "Artist 1177/11261\n",
            "859\n",
            "Artist 1178/11261\n",
            "859\n",
            "Artist 1179/11261\n",
            "Lost artist 314\n",
            "859\n",
            "Artist 1180/11261\n",
            "860\n",
            "Artist 1181/11261\n",
            "860\n",
            "Artist 1182/11261\n",
            "Lost artist 315\n",
            "860\n",
            "Artist 1183/11261\n",
            "860\n",
            "Artist 1184/11261\n",
            "860\n",
            "Artist 1185/11261\n",
            "860\n",
            "Artist 1186/11261\n",
            "Lost artist 316\n",
            "860\n",
            "Artist 1187/11261\n",
            "Lost artist 317\n",
            "860\n",
            "Artist 1188/11261\n",
            "Lost artist 318\n",
            "860\n",
            "Artist 1189/11261\n",
            "861\n",
            "Artist 1190/11261\n",
            "861\n",
            "Artist 1191/11261\n",
            "861\n",
            "Artist 1192/11261\n",
            "Lost artist 319\n",
            "861\n",
            "Artist 1193/11261\n",
            "861\n",
            "Artist 1194/11261\n",
            "Lost artist 320\n",
            "861\n",
            "Artist 1195/11261\n",
            "861\n",
            "Artist 1196/11261\n",
            "861\n",
            "Artist 1197/11261\n",
            "861\n",
            "Artist 1198/11261\n",
            "861\n",
            "Artist 1199/11261\n",
            "Lost artist 321\n",
            "861\n",
            "Artist 1200/11261\n",
            "Lost artist 322\n",
            "861\n",
            "Artist 1201/11261\n",
            "861\n",
            "Artist 1202/11261\n",
            "Lost artist 323\n",
            "861\n",
            "Artist 1203/11261\n",
            "861\n",
            "Artist 1204/11261\n",
            "Lost artist 324\n",
            "861\n",
            "Artist 1205/11261\n",
            "864\n",
            "Artist 1206/11261\n",
            "Lost artist 325\n",
            "864\n",
            "Artist 1207/11261\n",
            "865\n",
            "Artist 1208/11261\n",
            "865\n",
            "Artist 1209/11261\n",
            "865\n",
            "Artist 1210/11261\n",
            "865\n",
            "Artist 1211/11261\n",
            "865\n",
            "Artist 1212/11261\n",
            "866\n",
            "Artist 1213/11261\n",
            "866\n",
            "Artist 1214/11261\n",
            "866\n",
            "Artist 1215/11261\n",
            "866\n",
            "Artist 1216/11261\n",
            "Lost artist 326\n",
            "866\n",
            "Artist 1217/11261\n",
            "Lost artist 327\n",
            "866\n",
            "Artist 1218/11261\n",
            "867\n",
            "Artist 1219/11261\n",
            "867\n",
            "Artist 1220/11261\n",
            "867\n",
            "Artist 1221/11261\n",
            "867\n",
            "Artist 1222/11261\n",
            "867\n",
            "Artist 1223/11261\n",
            "867\n",
            "Artist 1224/11261\n",
            "Lost artist 328\n",
            "867\n",
            "Artist 1225/11261\n",
            "Lost artist 329\n",
            "867\n",
            "Artist 1226/11261\n",
            "867\n",
            "Artist 1227/11261\n",
            "867\n",
            "Artist 1228/11261\n",
            "867\n",
            "Artist 1229/11261\n",
            "867\n",
            "Artist 1230/11261\n",
            "Lost artist 330\n",
            "867\n",
            "Artist 1231/11261\n",
            "871\n",
            "Artist 1232/11261\n",
            "871\n",
            "Artist 1233/11261\n",
            "872\n",
            "Artist 1234/11261\n",
            "872\n",
            "Artist 1235/11261\n",
            "872\n",
            "Artist 1236/11261\n",
            "872\n",
            "Artist 1237/11261\n",
            "872\n",
            "Artist 1238/11261\n",
            "873\n",
            "Artist 1239/11261\n",
            "Lost artist 331\n",
            "873\n",
            "Artist 1240/11261\n",
            "873\n",
            "Artist 1241/11261\n",
            "873\n",
            "Artist 1242/11261\n",
            "873\n",
            "Artist 1243/11261\n",
            "Lost artist 332\n",
            "873\n",
            "Artist 1244/11261\n",
            "873\n",
            "Artist 1245/11261\n",
            "Lost artist 333\n",
            "873\n",
            "Artist 1246/11261\n",
            "873\n",
            "Artist 1247/11261\n",
            "Lost artist 334\n",
            "873\n",
            "Artist 1248/11261\n",
            "874\n",
            "Artist 1249/11261\n",
            "874\n",
            "Artist 1250/11261\n",
            "875\n",
            "Artist 1251/11261\n",
            "Lost artist 335\n",
            "875\n",
            "Artist 1252/11261\n",
            "Lost artist 336\n",
            "875\n",
            "Artist 1253/11261\n",
            "876\n",
            "Artist 1254/11261\n",
            "876\n",
            "Artist 1255/11261\n",
            "877\n",
            "Artist 1256/11261\n",
            "Lost artist 337\n",
            "877\n",
            "Artist 1257/11261\n",
            "877\n",
            "Artist 1258/11261\n",
            "877\n",
            "Artist 1259/11261\n",
            "884\n",
            "Artist 1260/11261\n",
            "885\n",
            "Artist 1261/11261\n",
            "885\n",
            "Artist 1262/11261\n",
            "885\n",
            "Artist 1263/11261\n",
            "886\n",
            "Artist 1264/11261\n",
            "886\n",
            "Artist 1265/11261\n",
            "887\n",
            "Artist 1266/11261\n",
            "887\n",
            "Artist 1267/11261\n",
            "887\n",
            "Artist 1268/11261\n",
            "Lost artist 338\n",
            "887\n",
            "Artist 1269/11261\n",
            "Lost artist 339\n",
            "887\n",
            "Artist 1270/11261\n",
            "888\n",
            "Artist 1271/11261\n",
            "888\n",
            "Artist 1272/11261\n",
            "Lost artist 340\n",
            "888\n",
            "Artist 1273/11261\n",
            "890\n",
            "Artist 1274/11261\n",
            "891\n",
            "Artist 1275/11261\n",
            "Lost artist 341\n",
            "891\n",
            "Artist 1276/11261\n",
            "Lost artist 342\n",
            "891\n",
            "Artist 1277/11261\n",
            "891\n",
            "Artist 1278/11261\n",
            "891\n",
            "Artist 1279/11261\n",
            "Lost artist 343\n",
            "891\n",
            "Artist 1280/11261\n",
            "Lost artist 344\n",
            "891\n",
            "Artist 1281/11261\n",
            "891\n",
            "Artist 1282/11261\n",
            "Lost artist 345\n",
            "891\n",
            "Artist 1283/11261\n",
            "Lost artist 346\n",
            "891\n",
            "Artist 1284/11261\n",
            "891\n",
            "Artist 1285/11261\n",
            "Lost artist 347\n",
            "891\n",
            "Artist 1286/11261\n",
            "891\n",
            "Artist 1287/11261\n",
            "Lost artist 348\n",
            "891\n",
            "Artist 1288/11261\n",
            "891\n",
            "Artist 1289/11261\n",
            "Lost artist 349\n",
            "891\n",
            "Artist 1290/11261\n",
            "Lost artist 350\n",
            "891\n",
            "Artist 1291/11261\n",
            "Lost artist 351\n",
            "891\n",
            "Artist 1292/11261\n",
            "Lost artist 352\n",
            "891\n",
            "Artist 1293/11261\n",
            "892\n",
            "Artist 1294/11261\n",
            "892\n",
            "Artist 1295/11261\n",
            "892\n",
            "Artist 1296/11261\n",
            "892\n",
            "Artist 1297/11261\n",
            "892\n",
            "Artist 1298/11261\n",
            "Lost artist 353\n",
            "892\n",
            "Artist 1299/11261\n",
            "892\n",
            "Artist 1300/11261\n",
            "893\n",
            "Artist 1301/11261\n",
            "894\n",
            "Artist 1302/11261\n",
            "894\n",
            "Artist 1303/11261\n",
            "894\n",
            "Artist 1304/11261\n",
            "894\n",
            "Artist 1305/11261\n",
            "894\n",
            "Artist 1306/11261\n",
            "894\n",
            "Artist 1307/11261\n",
            "894\n",
            "Artist 1308/11261\n",
            "894\n",
            "Artist 1309/11261\n",
            "894\n",
            "Artist 1310/11261\n",
            "895\n",
            "Artist 1311/11261\n",
            "902\n",
            "Artist 1312/11261\n",
            "903\n",
            "Artist 1313/11261\n",
            "910\n",
            "Artist 1314/11261\n",
            "910\n",
            "Artist 1315/11261\n",
            "911\n",
            "Artist 1316/11261\n",
            "911\n",
            "Artist 1317/11261\n",
            "911\n",
            "Artist 1318/11261\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/peppe/Desktop/Università/magistrale/AS-Project/Olga.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/peppe/Desktop/Universit%C3%A0/magistrale/AS-Project/Olga.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ol\u001b[39m.\u001b[39;49mget_genres()\n",
            "\u001b[1;32m/home/peppe/Desktop/Università/magistrale/AS-Project/Olga.ipynb Cell 10\u001b[0m in \u001b[0;36mDatasetOlga.get_genres\u001b[0;34m(self, name, increm)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/peppe/Desktop/Universit%C3%A0/magistrale/AS-Project/Olga.ipynb#X20sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mArtist \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(artist_num, \u001b[39mlen\u001b[39m(valid_ids)))\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/peppe/Desktop/Universit%C3%A0/magistrale/AS-Project/Olga.ipynb#X20sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m art_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39molga\u001b[39m.\u001b[39miloc[valid_ids[artist_num], \u001b[39m1\u001b[39m]\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/peppe/Desktop/Universit%C3%A0/magistrale/AS-Project/Olga.ipynb#X20sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m result \u001b[39m=\u001b[39m mbr\u001b[39m.\u001b[39;49mget_artist_by_id(art_id,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/peppe/Desktop/Universit%C3%A0/magistrale/AS-Project/Olga.ipynb#X20sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m     includes\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mtags\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/peppe/Desktop/Universit%C3%A0/magistrale/AS-Project/Olga.ipynb#X20sZmlsZQ%3D%3D?line=106'>107</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtag-list\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m result[\u001b[39m'\u001b[39m\u001b[39martist\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/peppe/Desktop/Universit%C3%A0/magistrale/AS-Project/Olga.ipynb#X20sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m   genre_list \u001b[39m=\u001b[39m [genre[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m genre \u001b[39min\u001b[39;00m result[\u001b[39m'\u001b[39m\u001b[39martist\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtag-list\u001b[39m\u001b[39m'\u001b[39m]]\n",
            "File \u001b[0;32m~/miniconda3/envs/my_env/lib/python3.9/site-packages/musicbrainzngs/musicbrainz.py:821\u001b[0m, in \u001b[0;36mget_artist_by_id\u001b[0;34m(id, includes, release_status, release_type)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39m\"\"\"Get the artist with the MusicBrainz `id` as a dict with an 'artist' key.\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \n\u001b[1;32m    818\u001b[0m \u001b[39m*Available includes*: {includes}\"\"\"\u001b[39;00m\n\u001b[1;32m    819\u001b[0m params \u001b[39m=\u001b[39m _check_filter_and_make_params(\u001b[39m\"\u001b[39m\u001b[39martist\u001b[39m\u001b[39m\"\u001b[39m, includes,\n\u001b[1;32m    820\u001b[0m                                        release_status, release_type)\n\u001b[0;32m--> 821\u001b[0m \u001b[39mreturn\u001b[39;00m _do_mb_query(\u001b[39m\"\u001b[39;49m\u001b[39martist\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mid\u001b[39;49m, includes, params)\n",
            "File \u001b[0;32m~/miniconda3/envs/my_env/lib/python3.9/site-packages/musicbrainzngs/musicbrainz.py:728\u001b[0m, in \u001b[0;36m_do_mb_query\u001b[0;34m(entity, id, includes, params)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[39m# Build the endpoint components.\u001b[39;00m\n\u001b[1;32m    727\u001b[0m path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (entity, \u001b[39mid\u001b[39m)\n\u001b[0;32m--> 728\u001b[0m \u001b[39mreturn\u001b[39;00m _mb_request(path, \u001b[39m'\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m'\u001b[39;49m, auth_required, args\u001b[39m=\u001b[39;49margs)\n",
            "File \u001b[0;32m~/miniconda3/envs/my_env/lib/python3.9/site-packages/musicbrainzngs/musicbrainz.py:417\u001b[0m, in \u001b[0;36m_rate_limit.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[39m# Call the original function, \"paying\" for this call.\u001b[39;00m\n\u001b[1;32m    416\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremaining_requests \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m\n\u001b[0;32m--> 417\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfun(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/miniconda3/envs/my_env/lib/python3.9/site-packages/musicbrainzngs/musicbrainz.py:690\u001b[0m, in \u001b[0;36m_mb_request\u001b[0;34m(path, method, auth_required, client_required, args, data, body)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m data \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m req\u001b[39m.\u001b[39mhas_header(\u001b[39m'\u001b[39m\u001b[39mContent-Length\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    687\u001b[0m     \u001b[39m# Explicitly indicate zero content length if no request data\u001b[39;00m\n\u001b[1;32m    688\u001b[0m     \u001b[39m# will be sent (avoids HTTP 411 error).\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     req\u001b[39m.\u001b[39madd_header(\u001b[39m'\u001b[39m\u001b[39mContent-Length\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m0\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 690\u001b[0m resp \u001b[39m=\u001b[39m _safe_read(opener, req, body)\n\u001b[1;32m    692\u001b[0m \u001b[39mreturn\u001b[39;00m parser_fun(resp)\n",
            "File \u001b[0;32m~/miniconda3/envs/my_env/lib/python3.9/site-packages/musicbrainzngs/musicbrainz.py:497\u001b[0m, in \u001b[0;36m_safe_read\u001b[0;34m(opener, req, body, max_retries, retry_delay_delta)\u001b[0m\n\u001b[1;32m    495\u001b[0m \t\tf \u001b[39m=\u001b[39m opener\u001b[39m.\u001b[39mopen(req, body)\n\u001b[1;32m    496\u001b[0m \t\u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m \t\tf \u001b[39m=\u001b[39m opener\u001b[39m.\u001b[39;49mopen(req)\n\u001b[1;32m    498\u001b[0m \t\u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39mread()\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m compat\u001b[39m.\u001b[39mHTTPError \u001b[39mas\u001b[39;00m exc:\n",
            "File \u001b[0;32m~/miniconda3/envs/my_env/lib/python3.9/urllib/request.py:517\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    514\u001b[0m     req \u001b[39m=\u001b[39m meth(req)\n\u001b[1;32m    516\u001b[0m sys\u001b[39m.\u001b[39maudit(\u001b[39m'\u001b[39m\u001b[39murllib.Request\u001b[39m\u001b[39m'\u001b[39m, req\u001b[39m.\u001b[39mfull_url, req\u001b[39m.\u001b[39mdata, req\u001b[39m.\u001b[39mheaders, req\u001b[39m.\u001b[39mget_method())\n\u001b[0;32m--> 517\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(req, data)\n\u001b[1;32m    519\u001b[0m \u001b[39m# post-process response\u001b[39;00m\n\u001b[1;32m    520\u001b[0m meth_name \u001b[39m=\u001b[39m protocol\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_response\u001b[39m\u001b[39m\"\u001b[39m\n",
            "File \u001b[0;32m~/miniconda3/envs/my_env/lib/python3.9/urllib/request.py:534\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m    533\u001b[0m protocol \u001b[39m=\u001b[39m req\u001b[39m.\u001b[39mtype\n\u001b[0;32m--> 534\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_open, protocol, protocol \u001b[39m+\u001b[39;49m\n\u001b[1;32m    535\u001b[0m                           \u001b[39m'\u001b[39;49m\u001b[39m_open\u001b[39;49m\u001b[39m'\u001b[39;49m, req)\n\u001b[1;32m    536\u001b[0m \u001b[39mif\u001b[39;00m result:\n\u001b[1;32m    537\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m~/miniconda3/envs/my_env/lib/python3.9/urllib/request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[1;32m    493\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 494\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    495\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m~/miniconda3/envs/my_env/lib/python3.9/urllib/request.py:1389\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1388\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttps_open\u001b[39m(\u001b[39mself\u001b[39m, req):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_open(http\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mHTTPSConnection, req,\n\u001b[1;32m   1390\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context, check_hostname\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_hostname)\n",
            "File \u001b[0;32m~/miniconda3/envs/my_env/lib/python3.9/urllib/request.py:1346\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1346\u001b[0m         h\u001b[39m.\u001b[39;49mrequest(req\u001b[39m.\u001b[39;49mget_method(), req\u001b[39m.\u001b[39;49mselector, req\u001b[39m.\u001b[39;49mdata, headers,\n\u001b[1;32m   1347\u001b[0m                   encode_chunked\u001b[39m=\u001b[39;49mreq\u001b[39m.\u001b[39;49mhas_header(\u001b[39m'\u001b[39;49m\u001b[39mTransfer-encoding\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m   1348\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err: \u001b[39m# timeout error\u001b[39;00m\n\u001b[1;32m   1349\u001b[0m         \u001b[39mraise\u001b[39;00m URLError(err)\n",
            "File \u001b[0;32m~/miniconda3/envs/my_env/lib/python3.9/http/client.py:1285\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\u001b[39mself\u001b[39m, method, url, body\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, headers\u001b[39m=\u001b[39m{}, \u001b[39m*\u001b[39m,\n\u001b[1;32m   1283\u001b[0m             encode_chunked\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   1284\u001b[0m     \u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1285\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(method, url, body, headers, encode_chunked)\n",
            "File \u001b[0;32m~/miniconda3/envs/my_env/lib/python3.9/http/client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(body, \u001b[39mstr\u001b[39m):\n\u001b[1;32m   1328\u001b[0m     \u001b[39m# RFC 2616 Section 3.7.1 says that text default has a\u001b[39;00m\n\u001b[1;32m   1329\u001b[0m     \u001b[39m# default charset of iso-8859-1.\u001b[39;00m\n\u001b[1;32m   1330\u001b[0m     body \u001b[39m=\u001b[39m _encode(body, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1331\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders(body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
            "File \u001b[0;32m~/miniconda3/envs/my_env/lib/python3.9/http/client.py:1280\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1279\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1280\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
            "File \u001b[0;32m~/miniconda3/envs/my_env/lib/python3.9/http/client.py:1040\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1038\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer)\n\u001b[1;32m   1039\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1040\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(msg)\n\u001b[1;32m   1042\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1043\u001b[0m \n\u001b[1;32m   1044\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n\u001b[1;32m   1045\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(message_body, \u001b[39m'\u001b[39m\u001b[39mread\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m   1046\u001b[0m         \u001b[39m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[1;32m   1047\u001b[0m         \u001b[39m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m         \u001b[39m# files to be taken into account.\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/my_env/lib/python3.9/http/client.py:980\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    979\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_open:\n\u001b[0;32m--> 980\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m    981\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    982\u001b[0m         \u001b[39mraise\u001b[39;00m NotConnected()\n",
            "File \u001b[0;32m~/miniconda3/envs/my_env/lib/python3.9/http/client.py:1447\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1444\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1445\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mConnect to a host on a given (SSL) port.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1447\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m   1449\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tunnel_host:\n\u001b[1;32m   1450\u001b[0m         server_hostname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tunnel_host\n",
            "File \u001b[0;32m~/miniconda3/envs/my_env/lib/python3.9/http/client.py:946\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    945\u001b[0m     \u001b[39m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 946\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_connection(\n\u001b[1;32m    947\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhost,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msource_address)\n\u001b[1;32m    948\u001b[0m     \u001b[39m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n\u001b[1;32m    949\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/miniconda3/envs/my_env/lib/python3.9/socket.py:832\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[39mif\u001b[39;00m source_address:\n\u001b[1;32m    831\u001b[0m     sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[0;32m--> 832\u001b[0m sock\u001b[39m.\u001b[39;49mconnect(sa)\n\u001b[1;32m    833\u001b[0m \u001b[39m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[1;32m    834\u001b[0m err \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "ol.get_genres()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13f2be61",
      "metadata": {
        "id": "13f2be61"
      },
      "source": [
        "## Graph construction\n",
        "\n",
        "- Once we have obtained the information necessary to construct the Graph topology, and stored them into two json files ('MsbMapped.json','graphSimilarities.json'), we still need to have the Graph data structure to feed the Graph Convolutional Network.\n",
        "\n",
        "- In the following cell are defined the graph's adjacency matrix from the 'graphSimilarities.json', which was previously obtained, and the features of each artist, namely the attributes of the graph's nodes. Those are obtained from a numpy array stored in the file 'acousticbrainz.npy', such file was provided by the paper's authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "145ae3a2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "145ae3a2",
        "outputId": "0dffc503-54a9-4770-875b-ed1951df227e",
        "scrolled": false
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-d627ef115794>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdicti\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MsbMapped.json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'graphSimilarities.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'acousticbrainz.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mA1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_adjacency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymmetry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-d627ef115794>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mapfile, gfile)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmapfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m#The expected files are the ones mentioned before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetOlga\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0molga\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-d627ef115794>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mjfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mdicti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdicti\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
          ]
        }
      ],
      "source": [
        "n_features=2613\n",
        "class Graph():  #The purpose of this class is to construct the graph of artists, in particular the Adjacency matrix A, and the  \n",
        "                # node features tensor X\n",
        "        \n",
        "    def __init__(self,mapfile,gfile):  #The expected files are the ones mentioned before.\n",
        "        self.mfile=self.load_data(mapfile)\n",
        "        self.gfile=self.load_data(gfile)\n",
        "        self.ol = DatasetOlga(olga)\n",
        "        self.A=torch.zeros((len(self.mfile),len(self.mfile)))\n",
        "        self.X=torch.zeros((n_features,len(self.mfile)))\n",
        "        self.ord=sorted(list(map(int,self.gfile.keys())))\n",
        "        self.enc1={}\n",
        "        self.enc2={}\n",
        "    \n",
        "    #With the preprocessing step at the previous cell we have lost some information\n",
        "    #and also the ordering of the artists, so i have defined a method that for each previous artist index\n",
        "    #we can encode it to a new ordered list of artists.\n",
        "    \n",
        "    \n",
        "    def encoding1(self):   #From ordered to unordered, Dict are not ordered data structures, so is better to order them before\n",
        "        for k in range(len(self.mfile)): #This encoding is used to get the Instance matrix\n",
        "            self.enc1[k]=self.ord[k]\n",
        "        return self.enc1\n",
        "    \n",
        "    def encoding2(self):   #From unordered to ordered,  From real number, to ordered one.\n",
        "        for k in range(len(self.mfile)): #This encoding is used to get the Adjacency matrix\n",
        "            self.enc2[self.ord[k]]=k\n",
        "        return self.enc2\n",
        "    \n",
        "    def get_instance(self,instances,df=False):#We take the features centroid, obtained from 25 track from artists discographies.\n",
        "        X=np.load(instances)                  #The instances file is provided by the repository mentioned in the paper.\n",
        "        X=torch.from_numpy(X).requires_grad_(True) #We take the allmusicIDs, which contain the key of the artists for which we haven't \n",
        "        c=0                                        # lost information\n",
        "        enc=self.encoding1()\n",
        "        for k in self.mfile:\n",
        "            z=enc[c]\n",
        "            self.X[:,c]=X[z] \n",
        "            c+=1\n",
        "        return self.X\n",
        "    \n",
        "    def get_adjacency(self,symmetry=False,df=False):  #The hypothesis could be either a symmetric matrix (paper), or not.\n",
        "        enc=self.encoding2()\n",
        "        for k in self.gfile:\n",
        "            c1=enc[int(k)]\n",
        "            for j in self.gfile[k]:\n",
        "                c2=enc[int(j)]\n",
        "                if self.A[c2,c1]==1 and symmetry==True:\n",
        "                    continue\n",
        "                self.A[c1,c2]=1\n",
        "                if symmetry:\n",
        "                    self.A[c2,c1]=1\n",
        "\n",
        "            \n",
        "        return self.A\n",
        "    def get_artist_dict(self):\n",
        "      self.id_to_art = {}\n",
        "      for key in self.enc1:\n",
        "        self.id_to_art[key] = self.ol.get_artist_name(self.enc1[key])\n",
        "        print(key)\n",
        "\n",
        "\n",
        "    def load_data(self,name):\n",
        "        jfile = open(name, \"r\")\n",
        "        dicti = json.load(jfile)\n",
        "        return dicti\n",
        "    \n",
        "g=Graph('MsbMapped.json','graphSimilarities.json')\n",
        "X1=g.get_instance('acousticbrainz.npy')\n",
        "A1=g.get_adjacency(symmetry=True)\n",
        "\n",
        "## diz_of_artist contains a mapping from the ids to the artists ##\n",
        "diz_of_artist = ol.load_data('dizofartist.json')\n",
        "\n",
        "## art_to_code is the opposite of diz_of_artist ##\n",
        "art_to_code = {diz_of_artist[key]:key for key in diz_of_artist}\n",
        "## The artists names are used to see how much the different artists are distant, and also to see what are their actual names, instead of their vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VBjS1fftwDay",
      "metadata": {
        "id": "VBjS1fftwDay"
      },
      "outputs": [],
      "source": [
        "torch.save(A1,'adjacency')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1AE6nBR590hF",
      "metadata": {
        "id": "1AE6nBR590hF"
      },
      "outputs": [],
      "source": [
        "samples = np.array(torch.sum(A1,dim=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "--uo5Ltu-Sud",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "--uo5Ltu-Sud",
        "outputId": "d621b7f8-9a13-4069-9cb3-37d95c80ddf2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"4f654629-e61b-4f50-b527-f2e4e8ec2bc6\" class=\"plotly-graph-div\" style=\"height:525px; width:650px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4f654629-e61b-4f50-b527-f2e4e8ec2bc6\")) {                    Plotly.newPlot(                        \"4f654629-e61b-4f50-b527-f2e4e8ec2bc6\",                        [{\"boxmean\":\"sd\",\"boxpoints\":\"all\",\"fillcolor\":\"blue\",\"jitter\":0.3,\"marker\":{\"color\":\"red\"},\"name\":\"Artist distribution\",\"whiskerwidth\":0.1,\"y\":[6.0,1.0,18.0,18.0,19.0,0.0,6.0,13.0,5.0,6.0,10.0,3.0,18.0,1.0,16.0,6.0,14.0,12.0,7.0,24.0,1.0,2.0,12.0,2.0,1.0,1.0,15.0,18.0,57.0,0.0,34.0,2.0,20.0,19.0,3.0,15.0,7.0,4.0,15.0,4.0,3.0,14.0,9.0,19.0,8.0,0.0,4.0,25.0,10.0,9.0,26.0,27.0,3.0,3.0,3.0,8.0,8.0,4.0,0.0,3.0,17.0,2.0,5.0,7.0,12.0,10.0,2.0,8.0,5.0,28.0,4.0,12.0,5.0,8.0,9.0,13.0,2.0,25.0,8.0,8.0,14.0,32.0,1.0,5.0,17.0,27.0,10.0,0.0,20.0,26.0,14.0,13.0,25.0,3.0,2.0,8.0,19.0,14.0,9.0,4.0,3.0,1.0,19.0,6.0,12.0,8.0,22.0,7.0,29.0,4.0,2.0,1.0,5.0,2.0,12.0,9.0,8.0,9.0,1.0,1.0,16.0,5.0,18.0,10.0,9.0,4.0,2.0,17.0,10.0,29.0,4.0,9.0,34.0,6.0,1.0,4.0,14.0,5.0,20.0,8.0,29.0,1.0,19.0,6.0,30.0,7.0,31.0,6.0,3.0,1.0,1.0,61.0,34.0,4.0,12.0,10.0,3.0,9.0,5.0,5.0,4.0,1.0,18.0,79.0,3.0,16.0,1.0,3.0,3.0,6.0,4.0,6.0,16.0,29.0,26.0,5.0,49.0,16.0,4.0,6.0,4.0,5.0,12.0,7.0,23.0,10.0,14.0,1.0,28.0,3.0,5.0,10.0,14.0,1.0,6.0,4.0,14.0,18.0,3.0,8.0,8.0,17.0,28.0,1.0,4.0,14.0,28.0,9.0,4.0,18.0,0.0,2.0,30.0,7.0,12.0,1.0,12.0,9.0,2.0,4.0,6.0,3.0,6.0,20.0,60.0,8.0,7.0,17.0,3.0,15.0,5.0,33.0,7.0,12.0,21.0,17.0,3.0,1.0,22.0,66.0,2.0,6.0,5.0,23.0,17.0,9.0,5.0,6.0,15.0,12.0,16.0,23.0,14.0,6.0,14.0,9.0,9.0,6.0,18.0,24.0,8.0,1.0,7.0,14.0,6.0,20.0,3.0,26.0,10.0,7.0,12.0,0.0,1.0,3.0,14.0,11.0,2.0,1.0,5.0,5.0,1.0,4.0,6.0,20.0,34.0,12.0,29.0,8.0,8.0,4.0,18.0,23.0,1.0,7.0,0.0,4.0,0.0,22.0,16.0,19.0,3.0,10.0,8.0,15.0,8.0,5.0,33.0,2.0,13.0,1.0,21.0,8.0,41.0,4.0,12.0,4.0,14.0,7.0,11.0,5.0,5.0,10.0,18.0,6.0,13.0,8.0,2.0,10.0,13.0,4.0,5.0,7.0,0.0,5.0,11.0,1.0,9.0,33.0,15.0,10.0,3.0,9.0,5.0,12.0,7.0,2.0,0.0,37.0,36.0,24.0,10.0,9.0,5.0,6.0,12.0,21.0,10.0,1.0,30.0,7.0,26.0,17.0,1.0,20.0,4.0,32.0,30.0,1.0,4.0,0.0,28.0,35.0,0.0,3.0,21.0,42.0,19.0,12.0,14.0,11.0,9.0,0.0,91.0,15.0,4.0,14.0,0.0,11.0,25.0,3.0,6.0,3.0,2.0,32.0,13.0,14.0,24.0,11.0,1.0,24.0,17.0,12.0,6.0,29.0,20.0,44.0,3.0,25.0,4.0,2.0,6.0,33.0,4.0,6.0,22.0,4.0,8.0,2.0,31.0,0.0,6.0,5.0,1.0,7.0,10.0,14.0,27.0,4.0,20.0,17.0,7.0,12.0,1.0,5.0,16.0,18.0,39.0,7.0,1.0,4.0,9.0,11.0,31.0,6.0,7.0,2.0,2.0,7.0,21.0,0.0,1.0,1.0,19.0,2.0,3.0,4.0,15.0,51.0,15.0,1.0,18.0,9.0,1.0,3.0,17.0,7.0,12.0,48.0,23.0,9.0,18.0,6.0,42.0,9.0,24.0,1.0,13.0,18.0,5.0,13.0,11.0,12.0,0.0,6.0,3.0,8.0,13.0,14.0,15.0,29.0,13.0,13.0,1.0,4.0,15.0,2.0,3.0,0.0,9.0,18.0,0.0,23.0,4.0,4.0,2.0,18.0,4.0,2.0,4.0,21.0,13.0,24.0,14.0,16.0,17.0,41.0,10.0,43.0,2.0,13.0,7.0,15.0,10.0,6.0,14.0,65.0,6.0,17.0,13.0,1.0,7.0,7.0,4.0,5.0,7.0,1.0,20.0,21.0,9.0,9.0,1.0,26.0,12.0,1.0,31.0,4.0,19.0,4.0,29.0,2.0,10.0,0.0,6.0,16.0,2.0,4.0,5.0,14.0,39.0,2.0,5.0,33.0,7.0,11.0,12.0,10.0,15.0,21.0,4.0,7.0,5.0,2.0,2.0,16.0,1.0,7.0,2.0,3.0,2.0,34.0,19.0,9.0,16.0,5.0,13.0,8.0,16.0,21.0,52.0,5.0,6.0,35.0,3.0,5.0,13.0,15.0,4.0,38.0,9.0,13.0,1.0,34.0,3.0,14.0,1.0,50.0,9.0,4.0,16.0,0.0,0.0,2.0,0.0,10.0,4.0,9.0,3.0,6.0,17.0,7.0,45.0,5.0,2.0,3.0,0.0,8.0,33.0,25.0,12.0,18.0,2.0,0.0,1.0,3.0,8.0,8.0,6.0,11.0,1.0,13.0,1.0,21.0,1.0,0.0,3.0,9.0,6.0,8.0,2.0,1.0,15.0,17.0,4.0,4.0,14.0,86.0,1.0,9.0,16.0,36.0,0.0,5.0,5.0,0.0,20.0,0.0,1.0,12.0,3.0,1.0,21.0,5.0,5.0,14.0,7.0,5.0,1.0,6.0,7.0,22.0,16.0,4.0,10.0,14.0,13.0,4.0,6.0,3.0,17.0,15.0,11.0,3.0,11.0,7.0,59.0,26.0,15.0,19.0,2.0,5.0,12.0,4.0,1.0,0.0,0.0,17.0,48.0,19.0,0.0,32.0,10.0,26.0,52.0,31.0,18.0,9.0,13.0,1.0,1.0,20.0,5.0,0.0,2.0,4.0,7.0,3.0,15.0,14.0,8.0,22.0,35.0,13.0,9.0,0.0,7.0,6.0,3.0,11.0,3.0,2.0,6.0,7.0,1.0,3.0,15.0,20.0,20.0,5.0,9.0,18.0,15.0,6.0,51.0,3.0,24.0,3.0,10.0,3.0,8.0,9.0,7.0,10.0,10.0,4.0,20.0,1.0,3.0,12.0,8.0,1.0,4.0,1.0,6.0,0.0,12.0,38.0,5.0,0.0,9.0,1.0,14.0,2.0,8.0,1.0,8.0,8.0,25.0,45.0,22.0,16.0,2.0,3.0,1.0,1.0,1.0,1.0,8.0,2.0,1.0,2.0,15.0,1.0,1.0,11.0,4.0,8.0,3.0,2.0,46.0,6.0,27.0,31.0,5.0,7.0,11.0,5.0,1.0,6.0,2.0,9.0,1.0,19.0,19.0,58.0,12.0,1.0,25.0,23.0,23.0,16.0,21.0,2.0,13.0,3.0,3.0,4.0,4.0,1.0,8.0,15.0,13.0,60.0,3.0,2.0,1.0,2.0,3.0,2.0,8.0,7.0,15.0,14.0,10.0,13.0,11.0,11.0,29.0,3.0,7.0,8.0,10.0,23.0,9.0,3.0,3.0,27.0,9.0,7.0,38.0,27.0,6.0,5.0,9.0,6.0,6.0,2.0,14.0,9.0,19.0,7.0,16.0,5.0,19.0,17.0,5.0,1.0,3.0,12.0,5.0,0.0,7.0,13.0,3.0,11.0,5.0,1.0,11.0,13.0,21.0,10.0,22.0,7.0,5.0,12.0,9.0,9.0,17.0,1.0,3.0,11.0,5.0,7.0,18.0,12.0,34.0,2.0,8.0,19.0,36.0,12.0,29.0,3.0,0.0,37.0,29.0,7.0,30.0,45.0,10.0,9.0,1.0,25.0,2.0,7.0,16.0,10.0,16.0,9.0,5.0,8.0,18.0,8.0,3.0,8.0,4.0,21.0,6.0,13.0,33.0,1.0,4.0,4.0,10.0,6.0,5.0,5.0,10.0,2.0,8.0,8.0,7.0,18.0,13.0,4.0,4.0,2.0,4.0,2.0,7.0,3.0,9.0,3.0,2.0,12.0,9.0,1.0,15.0,6.0,4.0,4.0,25.0,3.0,22.0,7.0,6.0,7.0,1.0,22.0,12.0,12.0,20.0,6.0,5.0,4.0,3.0,2.0,17.0,30.0,9.0,26.0,9.0,29.0,38.0,12.0,9.0,6.0,5.0,7.0,54.0,12.0,8.0,8.0,14.0,5.0,8.0,21.0,5.0,10.0,5.0,0.0,27.0,6.0,10.0,4.0,26.0,4.0,13.0,15.0,16.0,33.0,12.0,6.0,43.0,7.0,2.0,17.0,24.0,9.0,3.0,0.0,29.0,1.0,12.0,4.0,11.0,9.0,13.0,2.0,5.0,6.0,13.0,33.0,1.0,7.0,20.0,2.0,1.0,4.0,17.0,15.0,1.0,19.0,43.0,13.0,5.0,5.0,3.0,5.0,11.0,1.0,27.0,17.0,1.0,4.0,6.0,19.0,5.0,5.0,22.0,2.0,6.0,13.0,5.0,4.0,30.0,10.0,5.0,14.0,8.0,13.0,15.0,4.0,16.0,22.0,10.0,6.0,6.0,4.0,3.0,3.0,9.0,12.0,23.0,7.0,0.0,27.0,25.0,6.0,16.0,5.0,1.0,7.0,3.0,20.0,10.0,3.0,3.0,23.0,19.0,5.0,10.0,29.0,22.0,18.0,2.0,2.0,2.0,1.0,29.0,8.0,8.0,10.0,12.0,11.0,1.0,1.0,3.0,13.0,5.0,3.0,25.0,20.0,7.0,33.0,4.0,12.0,12.0,26.0,11.0,9.0,1.0,23.0,26.0,7.0,13.0,6.0,15.0,1.0,8.0,21.0,2.0,1.0,1.0,22.0,1.0,7.0,5.0,9.0,30.0,16.0,8.0,14.0,8.0,13.0,23.0,2.0,6.0,15.0,7.0,1.0,10.0,18.0,12.0,7.0,3.0,8.0,9.0,3.0,3.0,7.0,8.0,5.0,3.0,11.0,1.0,10.0,3.0,1.0,15.0,2.0,2.0,19.0,9.0,25.0,1.0,4.0,3.0,52.0,14.0,21.0,1.0,10.0,25.0,42.0,16.0,6.0,10.0,18.0,12.0,4.0,2.0,4.0,10.0,2.0,9.0,11.0,7.0,8.0,18.0,1.0,4.0,22.0,13.0,18.0,17.0,32.0,44.0,8.0,85.0,9.0,12.0,0.0,15.0,4.0,2.0,0.0,1.0,7.0,14.0,10.0,19.0,4.0,2.0,40.0,13.0,11.0,10.0,4.0,20.0,2.0,21.0,4.0,9.0,4.0,8.0,25.0,4.0,9.0,7.0,11.0,11.0,9.0,24.0,23.0,29.0,4.0,1.0,1.0,14.0,4.0,6.0,6.0,7.0,3.0,11.0,4.0,51.0,6.0,16.0,2.0,0.0,3.0,2.0,17.0,2.0,5.0,7.0,10.0,4.0,12.0,4.0,16.0,4.0,9.0,20.0,32.0,39.0,3.0,10.0,45.0,8.0,1.0,8.0,4.0,35.0,7.0,1.0,4.0,3.0,3.0,1.0,1.0,6.0,2.0,7.0,2.0,3.0,5.0,22.0,10.0,1.0,4.0,10.0,2.0,1.0,6.0,0.0,2.0,7.0,1.0,1.0,20.0,1.0,1.0,6.0,16.0,0.0,22.0,1.0,2.0,6.0,23.0,5.0,7.0,4.0,2.0,23.0,1.0,4.0,2.0,6.0,32.0,2.0,5.0,4.0,8.0,12.0,9.0,1.0,0.0,1.0,7.0,0.0,3.0,25.0,18.0,3.0,4.0,8.0,33.0,2.0,5.0,8.0,14.0,5.0,29.0,8.0,16.0,1.0,14.0,12.0,12.0,1.0,21.0,13.0,22.0,29.0,3.0,62.0,60.0,8.0,1.0,10.0,18.0,4.0,11.0,30.0,1.0,1.0,12.0,6.0,12.0,18.0,30.0,7.0,7.0,1.0,13.0,3.0,3.0,4.0,6.0,1.0,12.0,29.0,5.0,0.0,49.0,27.0,21.0,2.0,15.0,3.0,14.0,4.0,24.0,8.0,10.0,24.0,18.0,6.0,5.0,12.0,12.0,1.0,6.0,2.0,7.0,2.0,6.0,0.0,18.0,11.0,1.0,5.0,42.0,62.0,87.0,7.0,31.0,12.0,9.0,2.0,6.0,8.0,1.0,29.0,40.0,8.0,2.0,4.0,12.0,8.0,2.0,1.0,17.0,22.0,6.0,9.0,1.0,13.0,12.0,10.0,18.0,7.0,26.0,15.0,18.0,4.0,10.0,2.0,3.0,0.0,4.0,6.0,1.0,4.0,24.0,23.0,12.0,6.0,4.0,18.0,2.0,7.0,20.0,30.0,11.0,2.0,5.0,2.0,0.0,15.0,2.0,2.0,23.0,16.0,10.0,8.0,1.0,10.0,9.0,5.0,12.0,48.0,1.0,6.0,8.0,3.0,8.0,3.0,1.0,3.0,5.0,7.0,4.0,2.0,42.0,22.0,6.0,12.0,17.0,8.0,6.0,4.0,17.0,17.0,5.0,5.0,9.0,0.0,10.0,18.0,4.0,3.0,8.0,3.0,51.0,16.0,6.0,0.0,8.0,1.0,3.0,2.0,18.0,2.0,16.0,1.0,13.0,11.0,6.0,7.0,1.0,0.0,3.0,3.0,3.0,6.0,4.0,2.0,12.0,8.0,4.0,21.0,9.0,22.0,28.0,5.0,19.0,2.0,14.0,11.0,3.0,2.0,23.0,2.0,13.0,5.0,6.0,10.0,7.0,12.0,19.0,36.0,5.0,12.0,29.0,10.0,27.0,9.0,5.0,0.0,22.0,4.0,1.0,4.0,8.0,42.0,11.0,13.0,5.0,2.0,0.0,25.0,15.0,1.0,1.0,17.0,1.0,25.0,11.0,5.0,7.0,4.0,5.0,21.0,4.0,1.0,63.0,1.0,8.0,9.0,1.0,17.0,8.0,24.0,1.0,9.0,19.0,8.0,2.0,12.0,15.0,14.0,13.0,14.0,3.0,3.0,1.0,3.0,3.0,32.0,9.0,9.0,9.0,10.0,3.0,9.0,26.0,66.0,8.0,2.0,9.0,1.0,29.0,8.0,10.0,1.0,9.0,25.0,7.0,27.0,7.0,12.0,8.0,26.0,15.0,2.0,3.0,4.0,5.0,3.0,12.0,25.0,9.0,8.0,8.0,1.0,18.0,7.0,26.0,5.0,13.0,2.0,6.0,4.0,8.0,4.0,7.0,14.0,13.0,21.0,2.0,18.0,28.0,8.0,32.0,0.0,7.0,8.0,6.0,10.0,1.0,18.0,21.0,44.0,5.0,3.0,2.0,16.0,31.0,47.0,14.0,0.0,5.0,8.0,4.0,1.0,1.0,6.0,9.0,10.0,1.0,24.0,1.0,15.0,11.0,23.0,6.0,18.0,8.0,12.0,52.0,6.0,0.0,7.0,5.0,7.0,16.0,4.0,1.0,10.0,5.0,21.0,1.0,5.0,23.0,20.0,35.0,7.0,22.0,3.0,5.0,3.0,2.0,16.0,32.0,10.0,1.0,15.0,5.0,1.0,7.0,66.0,5.0,24.0,35.0,2.0,19.0,8.0,5.0,8.0,17.0,13.0,7.0,3.0,5.0,10.0,6.0,3.0,9.0,59.0,7.0,21.0,26.0,19.0,12.0,3.0,19.0,5.0,11.0,2.0,10.0,12.0,4.0,8.0,15.0,3.0,18.0,14.0,3.0,4.0,8.0,1.0,1.0,4.0,21.0,19.0,28.0,14.0,0.0,8.0,20.0,3.0,5.0,19.0,31.0,1.0,23.0,0.0,6.0,12.0,32.0,8.0,4.0,22.0,3.0,0.0,38.0,16.0,15.0,7.0,12.0,2.0,8.0,25.0,20.0,6.0,0.0,6.0,6.0,3.0,8.0,14.0,7.0,9.0,6.0,34.0,17.0,3.0,2.0,23.0,1.0,11.0,30.0,0.0,1.0,10.0,7.0,5.0,2.0,23.0,22.0,2.0,19.0,4.0,30.0,8.0,16.0,17.0,5.0,2.0,0.0,15.0,3.0,35.0,1.0,20.0,2.0,17.0,0.0,4.0,2.0,9.0,1.0,5.0,8.0,8.0,28.0,2.0,26.0,6.0,4.0,17.0,0.0,5.0,4.0,3.0,2.0,5.0,10.0,1.0,5.0,7.0,7.0,10.0,22.0,8.0,7.0,10.0,43.0,1.0,26.0,13.0,7.0,8.0,26.0,36.0,13.0,23.0,4.0,8.0,4.0,1.0,17.0,3.0,19.0,17.0,4.0,12.0,1.0,17.0,6.0,22.0,0.0,47.0,13.0,17.0,2.0,15.0,34.0,24.0,8.0,5.0,8.0,20.0,6.0,20.0,4.0,7.0,20.0,26.0,0.0,1.0,13.0,4.0,13.0,17.0,24.0,3.0,8.0,23.0,8.0,12.0,3.0,6.0,15.0,1.0,26.0,5.0,17.0,30.0,7.0,5.0,7.0,5.0,1.0,21.0,20.0,40.0,1.0,2.0,14.0,5.0,1.0,11.0,12.0,55.0,5.0,33.0,16.0,26.0,2.0,7.0,6.0,16.0,19.0,14.0,4.0,9.0,7.0,8.0,11.0,15.0,3.0,5.0,8.0,7.0,3.0,1.0,13.0,0.0,4.0,0.0,6.0,22.0,6.0,6.0,5.0,17.0,29.0,35.0,7.0,21.0,2.0,6.0,39.0,1.0,18.0,13.0,13.0,1.0,23.0,8.0,8.0,1.0,5.0,10.0,4.0,6.0,3.0,15.0,6.0,14.0,17.0,1.0,19.0,1.0,4.0,6.0,15.0,22.0,36.0,8.0,1.0,2.0,17.0,0.0,13.0,10.0,24.0,1.0,22.0,7.0,14.0,14.0,11.0,3.0,8.0,20.0,9.0,8.0,5.0,41.0,8.0,6.0,4.0,16.0,16.0,3.0,1.0,16.0,8.0,7.0,1.0,1.0,7.0,6.0,4.0,35.0,17.0,6.0,5.0,32.0,15.0,3.0,5.0,3.0,7.0,15.0,3.0,9.0,22.0,2.0,13.0,4.0,15.0,29.0,18.0,2.0,9.0,4.0,22.0,13.0,8.0,21.0,5.0,13.0,7.0,11.0,1.0,9.0,25.0,21.0,5.0,6.0,0.0,1.0,22.0,6.0,12.0,34.0,15.0,21.0,14.0,9.0,5.0,4.0,5.0,6.0,2.0,6.0,3.0,19.0,8.0,10.0,7.0,4.0,17.0,17.0,2.0,13.0,4.0,2.0,19.0,8.0,6.0,9.0,15.0,11.0,8.0,26.0,8.0,6.0,3.0,3.0,38.0,4.0,3.0,8.0,8.0,8.0,5.0,1.0,1.0,1.0,3.0,15.0,7.0,19.0,19.0,10.0,4.0,11.0,4.0,16.0,10.0,0.0,3.0,22.0,11.0,1.0,1.0,4.0,5.0,8.0,9.0,2.0,28.0,2.0,8.0,12.0,35.0,6.0,8.0,4.0,8.0,17.0,7.0,9.0,11.0,6.0,1.0,20.0,23.0,9.0,11.0,12.0,2.0,2.0,2.0,14.0,34.0,11.0,40.0,21.0,5.0,3.0,6.0,9.0,2.0,3.0,3.0,20.0,5.0,0.0,59.0,3.0,18.0,8.0,0.0,9.0,76.0,13.0,11.0,2.0,3.0,3.0,1.0,8.0,16.0,3.0,7.0,0.0,18.0,5.0,1.0,22.0,3.0,14.0,26.0,20.0,12.0,3.0,6.0,1.0,0.0,14.0,18.0,26.0,1.0,3.0,17.0,4.0,2.0,6.0,16.0,15.0,4.0,15.0,4.0,23.0,1.0,3.0,24.0,9.0,10.0,7.0,7.0,4.0,11.0,61.0,11.0,0.0,15.0,12.0,22.0,10.0,5.0,7.0,13.0,3.0,20.0,8.0,34.0,3.0,26.0,8.0,1.0,2.0,20.0,1.0,5.0,5.0,1.0,21.0,1.0,6.0,9.0,2.0,22.0,11.0,22.0,37.0,30.0,1.0,3.0,16.0,1.0,5.0,13.0,8.0,23.0,20.0,43.0,0.0,20.0,3.0,39.0,19.0,6.0,2.0,3.0,7.0,12.0,9.0,7.0,6.0,1.0,5.0,12.0,12.0,17.0,9.0,11.0,3.0,10.0,24.0,2.0,6.0,4.0,16.0,8.0,9.0,0.0,5.0,5.0,23.0,1.0,8.0,10.0,7.0,25.0,9.0,22.0,7.0,2.0,1.0,6.0,33.0,1.0,5.0,1.0,2.0,11.0,2.0,2.0,20.0,8.0,1.0,28.0,31.0,2.0,3.0,6.0,13.0,1.0,3.0,7.0,12.0,25.0,2.0,5.0,20.0,7.0,7.0,36.0,0.0,13.0,1.0,9.0,5.0,9.0,8.0,11.0,17.0,5.0,4.0,13.0,5.0,15.0,12.0,8.0,0.0,5.0,13.0,30.0,7.0,6.0,28.0,13.0,1.0,19.0,11.0,15.0,12.0,4.0,14.0,22.0,31.0,8.0,19.0,7.0,11.0,31.0,16.0,2.0,16.0,10.0,5.0,1.0,11.0,8.0,21.0,1.0,10.0,1.0,14.0,20.0,11.0,11.0,12.0,4.0,8.0,29.0,4.0,1.0,2.0,1.0,10.0,6.0,10.0,8.0,1.0,15.0,3.0,2.0,20.0,21.0,33.0,44.0,16.0,7.0,21.0,7.0,26.0,18.0,0.0,12.0,9.0,98.0,5.0,12.0,8.0,11.0,16.0,12.0,18.0,1.0,8.0,17.0,44.0,3.0,11.0,19.0,22.0,1.0,1.0,12.0,26.0,11.0,5.0,14.0,10.0,8.0,3.0,2.0,5.0,4.0,14.0,17.0,2.0,23.0,11.0,28.0,4.0,13.0,17.0,20.0,31.0,27.0,2.0,20.0,12.0,15.0,22.0,49.0,4.0,18.0,21.0,1.0,0.0,8.0,10.0,2.0,8.0,10.0,3.0,43.0,3.0,9.0,17.0,5.0,1.0,13.0,30.0,2.0,2.0,13.0,7.0,1.0,4.0,12.0,2.0,5.0,7.0,1.0,22.0,2.0,11.0,24.0,20.0,17.0,12.0,13.0,27.0,28.0,13.0,2.0,6.0,12.0,10.0,15.0,4.0,11.0,6.0,4.0,7.0,17.0,16.0,15.0,5.0,11.0,1.0,21.0,12.0,5.0,4.0,6.0,10.0,5.0,55.0,16.0,12.0,34.0,1.0,11.0,4.0,19.0,9.0,0.0,7.0,20.0,30.0,8.0,3.0,7.0,5.0,14.0,10.0,2.0,24.0,3.0,2.0,15.0,11.0,4.0,3.0,11.0,6.0,6.0,3.0,17.0,12.0,1.0,12.0,16.0,5.0,2.0,9.0,15.0,13.0,19.0,19.0,4.0,4.0,35.0,7.0,7.0,1.0,5.0,6.0,12.0,8.0,3.0,4.0,3.0,6.0,17.0,7.0,38.0,24.0,2.0,21.0,4.0,4.0,10.0,4.0,7.0,42.0,7.0,4.0,10.0,8.0,11.0,2.0,19.0,11.0,11.0,6.0,16.0,4.0,11.0,1.0,1.0,1.0,10.0,25.0,16.0,6.0,11.0,20.0,0.0,5.0,7.0,24.0,2.0,4.0,18.0,1.0,19.0,8.0,1.0,28.0,2.0,5.0,2.0,6.0,0.0,2.0,1.0,34.0,5.0,0.0,4.0,6.0,1.0,18.0,26.0,12.0,4.0,4.0,14.0,5.0,7.0,8.0,18.0,1.0,18.0,15.0,0.0,4.0,35.0,8.0,5.0,10.0,0.0,9.0,5.0,3.0,1.0,9.0,16.0,24.0,6.0,7.0,4.0,5.0,0.0,5.0,3.0,10.0,15.0,18.0,8.0,27.0,4.0,7.0,2.0,13.0,14.0,20.0,16.0,15.0,9.0,6.0,7.0,0.0,20.0,5.0,6.0,8.0,9.0,6.0,6.0,19.0,5.0,23.0,2.0,55.0,22.0,4.0,6.0,13.0,18.0,2.0,4.0,21.0,8.0,27.0,16.0,22.0,5.0,13.0,4.0,21.0,3.0,15.0,3.0,18.0,24.0,22.0,13.0,4.0,9.0,22.0,15.0,1.0,8.0,1.0,0.0,1.0,20.0,1.0,7.0,5.0,10.0,1.0,12.0,8.0,31.0,1.0,15.0,2.0,5.0,8.0,12.0,23.0,3.0,6.0,2.0,0.0,35.0,9.0,35.0,9.0,6.0,8.0,25.0,13.0,7.0,10.0,48.0,2.0,1.0,10.0,1.0,1.0,12.0,7.0,2.0,8.0,1.0,15.0,9.0,48.0,5.0,17.0,15.0,8.0,6.0,18.0,33.0,11.0,7.0,3.0,10.0,5.0,8.0,15.0,6.0,0.0,17.0,11.0,3.0,3.0,4.0,13.0,25.0,26.0,9.0,24.0,37.0,2.0,9.0,44.0,4.0,25.0,22.0,6.0,5.0,1.0,15.0,3.0,1.0,11.0,14.0,1.0,12.0,5.0,2.0,5.0,4.0,24.0,13.0,17.0,8.0,51.0,19.0,22.0,18.0,1.0,20.0,4.0,24.0,13.0,1.0,14.0,24.0,3.0,32.0,6.0,32.0,2.0,0.0,11.0,4.0,14.0,4.0,0.0,1.0,3.0,2.0,5.0,27.0,5.0,15.0,10.0,2.0,4.0,14.0,7.0,6.0,17.0,1.0,2.0,1.0,2.0,2.0,1.0,5.0,11.0,13.0,16.0,9.0,6.0,6.0,3.0,11.0,39.0,17.0,4.0,4.0,6.0,3.0,13.0,2.0,13.0,9.0,2.0,30.0,13.0,13.0,10.0,0.0,5.0,8.0,17.0,37.0,40.0,3.0,32.0,19.0,10.0,11.0,12.0,26.0,32.0,6.0,11.0,21.0,1.0,6.0,15.0,12.0,5.0,6.0,20.0,1.0,0.0,2.0,7.0,7.0,7.0,7.0,4.0,39.0,10.0,2.0,5.0,14.0,3.0,1.0,13.0,40.0,15.0,9.0,14.0,12.0,10.0,11.0,37.0,2.0,6.0,4.0,32.0,5.0,2.0,28.0,4.0,23.0,7.0,3.0,20.0,16.0,18.0,27.0,8.0,9.0,6.0,14.0,3.0,7.0,10.0,1.0,31.0,20.0,10.0,9.0,0.0,4.0,2.0,31.0,2.0,2.0,13.0,6.0,2.0,3.0,1.0,8.0,1.0,2.0,4.0,17.0,1.0,10.0,11.0,1.0,19.0,6.0,0.0,15.0,36.0,34.0,3.0,10.0,14.0,19.0,17.0,9.0,3.0,34.0,4.0,10.0,10.0,13.0,2.0,17.0,7.0,2.0,18.0,1.0,8.0,0.0,27.0,6.0,14.0,8.0,6.0,17.0,38.0,7.0,5.0,4.0,3.0,7.0,5.0,2.0,7.0,2.0,3.0,4.0,3.0,10.0,3.0,31.0,3.0,6.0,8.0,2.0,1.0,1.0,19.0,6.0,6.0,31.0,12.0,43.0,9.0,4.0,2.0,2.0,16.0,15.0,12.0,17.0,3.0,14.0,5.0,27.0,12.0,2.0,7.0,4.0,9.0,2.0,4.0,8.0,0.0,5.0,23.0,30.0,1.0,40.0,1.0,34.0,14.0,71.0,9.0,0.0,14.0,22.0,7.0,4.0,1.0,8.0,2.0,28.0,5.0,10.0,14.0,3.0,9.0,11.0,19.0,3.0,0.0,8.0,8.0,16.0,19.0,1.0,6.0,3.0,19.0,21.0,7.0,8.0,13.0,27.0,12.0,12.0,9.0,2.0,7.0,8.0,5.0,1.0,7.0,25.0,13.0,19.0,12.0,58.0,2.0,9.0,8.0,6.0,8.0,9.0,1.0,29.0,1.0,14.0,5.0,15.0,11.0,2.0,13.0,31.0,27.0,0.0,22.0,54.0,1.0,1.0,5.0,1.0,1.0,15.0,9.0,13.0,17.0,13.0,13.0,4.0,4.0,15.0,8.0,4.0,4.0,10.0,5.0,23.0,4.0,1.0,27.0,7.0,2.0,0.0,22.0,1.0,9.0,25.0,10.0,3.0,4.0,1.0,19.0,12.0,3.0,11.0,29.0,4.0,7.0,2.0,1.0,1.0,2.0,9.0,1.0,1.0,1.0,5.0,12.0,32.0,13.0,1.0,27.0,6.0,15.0,11.0,9.0,5.0,3.0,40.0,8.0,26.0,9.0,8.0,3.0,12.0,31.0,6.0,4.0,2.0,8.0,14.0,9.0,3.0,7.0,6.0,4.0,2.0,7.0,10.0,2.0,9.0,21.0,1.0,4.0,21.0,6.0,7.0,2.0,1.0,9.0,24.0,12.0,3.0,14.0,33.0,13.0,2.0,2.0,50.0,9.0,8.0,25.0,2.0,1.0,2.0,15.0,8.0,4.0,3.0,32.0,17.0,10.0,3.0,14.0,1.0,20.0,12.0,15.0,2.0,7.0,12.0,6.0,5.0,22.0,13.0,16.0,4.0,3.0,4.0,16.0,6.0,13.0,7.0,7.0,2.0,8.0,3.0,40.0,1.0,48.0,7.0,44.0,13.0,0.0,7.0,2.0,34.0,12.0,18.0,1.0,14.0,23.0,5.0,18.0,31.0,2.0,18.0,23.0,7.0,1.0,17.0,16.0,9.0,4.0,5.0,3.0,9.0,47.0,4.0,1.0,10.0,2.0,21.0,17.0,4.0,7.0,8.0,1.0,7.0,3.0,12.0,2.0,16.0,1.0,5.0,4.0,6.0,12.0,29.0,2.0,3.0,2.0,12.0,10.0,32.0,4.0,7.0,6.0,3.0,11.0,6.0,11.0,5.0,59.0,3.0,16.0,15.0,27.0,23.0,17.0,1.0,0.0,4.0,10.0,58.0,14.0,9.0,2.0,1.0,6.0,17.0,15.0,8.0,1.0,6.0,5.0,2.0,22.0,32.0,5.0,2.0,70.0,22.0,9.0,11.0,18.0,6.0,1.0,9.0,31.0,30.0,14.0,13.0,6.0,1.0,5.0,13.0,4.0,22.0,2.0,6.0,17.0,51.0,3.0,23.0,20.0,13.0,2.0,22.0,27.0,1.0,7.0,2.0,4.0,6.0,12.0,2.0,4.0,2.0,1.0,0.0,1.0,5.0,17.0,20.0,2.0,2.0,7.0,35.0,1.0,0.0,33.0,4.0,1.0,0.0,5.0,5.0,1.0,13.0,1.0,3.0,2.0,1.0,2.0,1.0,17.0,3.0,4.0,20.0,1.0,21.0,46.0,2.0,1.0,5.0,7.0,11.0,16.0,5.0,5.0,3.0,5.0,1.0,5.0,16.0,2.0,4.0,10.0,10.0,7.0,15.0,23.0,32.0,5.0,5.0,13.0,9.0,8.0,6.0,1.0,3.0,9.0,5.0,1.0,25.0,2.0,13.0,9.0,8.0,18.0,1.0,9.0,16.0,3.0,5.0,19.0,1.0,22.0,23.0,1.0,3.0,3.0,37.0,17.0,4.0,5.0,6.0,6.0,21.0,1.0,6.0,5.0,2.0,13.0,1.0,20.0,10.0,5.0,18.0,11.0,11.0,8.0,26.0,6.0,4.0,12.0,18.0,13.0,4.0,8.0,6.0,1.0,5.0,38.0,2.0,3.0,5.0,6.0,17.0,7.0,4.0,21.0,2.0,23.0,26.0,10.0,3.0,1.0,1.0,29.0,2.0,62.0,4.0,1.0,4.0,5.0,10.0,4.0,2.0,9.0,8.0,10.0,7.0,0.0,11.0,6.0,14.0,27.0,5.0,24.0,8.0,15.0,1.0,14.0,29.0,16.0,5.0,6.0,20.0,11.0,17.0,25.0,23.0,28.0,3.0,3.0,14.0,22.0,43.0,1.0,4.0,71.0,7.0,8.0,9.0,7.0,2.0,5.0,83.0,1.0,19.0,24.0,16.0,5.0,8.0,1.0,12.0,13.0,15.0,12.0,0.0,7.0,2.0,1.0,20.0,17.0,4.0,8.0,23.0,24.0,5.0,41.0,23.0,6.0,12.0,4.0,13.0,1.0,2.0,3.0,8.0,12.0,15.0,12.0,10.0,4.0,2.0,11.0,2.0,7.0,30.0,2.0,7.0,23.0,5.0,7.0,1.0,16.0,12.0,8.0,1.0,20.0,5.0,1.0,1.0,3.0,3.0,3.0,1.0,2.0,41.0,8.0,33.0,12.0,1.0,2.0,24.0,11.0,6.0,12.0,5.0,16.0,32.0,25.0,7.0,19.0,3.0,12.0,31.0,17.0,5.0,20.0,11.0,5.0,20.0,21.0,23.0,7.0,15.0,20.0,1.0,2.0,1.0,32.0,8.0,2.0,12.0,27.0,9.0,3.0,1.0,17.0,4.0,4.0,11.0,18.0,4.0,2.0,14.0,33.0,2.0,11.0,8.0,8.0,3.0,23.0,22.0,4.0,21.0,8.0,11.0,19.0,2.0,11.0,13.0,7.0,5.0,15.0,2.0,7.0,12.0,1.0,3.0,4.0,4.0,2.0,11.0,7.0,23.0,0.0,10.0,2.0,13.0,11.0,8.0,29.0,22.0,5.0,12.0,16.0,10.0,2.0,73.0,4.0,17.0,30.0,34.0,34.0,1.0,6.0,10.0,10.0,0.0,21.0,3.0,15.0,7.0,9.0,17.0,2.0,23.0,4.0,10.0,8.0,24.0,3.0,1.0,13.0,0.0,4.0,17.0,22.0,9.0,35.0,20.0,12.0,3.0,1.0,24.0,13.0,1.0,45.0,27.0,3.0,2.0,16.0,0.0,2.0,3.0,6.0,2.0,17.0,11.0,45.0,16.0,5.0,6.0,2.0,12.0,2.0,1.0,11.0,1.0,9.0,8.0,10.0,4.0,15.0,4.0,1.0,11.0,6.0,4.0,16.0,4.0,7.0,3.0,4.0,2.0,9.0,21.0,6.0,9.0,15.0,11.0,12.0,6.0,18.0,0.0,8.0,1.0,10.0,21.0,1.0,10.0,4.0,16.0,4.0,24.0,1.0,3.0,4.0,2.0,13.0,1.0,3.0,14.0,10.0,5.0,11.0,5.0,3.0,10.0,9.0,14.0,16.0,4.0,5.0,6.0,17.0,11.0,6.0,24.0,7.0,1.0,22.0,2.0,17.0,13.0,17.0,10.0,19.0,0.0,12.0,8.0,24.0,7.0,21.0,6.0,1.0,19.0,40.0,5.0,1.0,13.0,8.0,18.0,13.0,6.0,3.0,20.0,18.0,9.0,5.0,13.0,6.0,2.0,5.0,0.0,19.0,19.0,42.0,21.0,10.0,31.0,2.0,31.0,14.0,44.0,13.0,21.0,8.0,3.0,8.0,3.0,27.0,18.0,6.0,1.0,14.0,16.0,2.0,23.0,3.0,3.0,5.0,33.0,9.0,2.0,21.0,29.0,12.0,1.0,13.0,25.0,2.0,5.0,2.0,14.0,8.0,5.0,3.0,1.0,6.0,44.0,6.0,11.0,5.0,14.0,28.0,3.0,4.0,25.0,1.0,2.0,27.0,11.0,1.0,2.0,30.0,9.0,12.0,9.0,20.0,5.0,12.0,45.0,11.0,30.0,1.0,6.0,4.0,32.0,7.0,9.0,9.0,11.0,17.0,3.0,1.0,66.0,0.0,27.0,9.0,5.0,5.0,8.0,9.0,8.0,1.0,17.0,0.0,3.0,4.0,8.0,6.0,8.0,26.0,35.0,31.0,10.0,0.0,5.0,1.0,2.0,1.0,17.0,17.0,16.0,4.0,2.0,7.0,21.0,5.0,0.0,4.0,10.0,4.0,8.0,2.0,21.0,4.0,8.0,16.0,21.0,16.0,20.0,19.0,1.0,28.0,11.0,13.0,7.0,32.0,34.0,6.0,2.0,16.0,16.0,10.0,5.0,2.0,10.0,16.0,9.0,25.0,5.0,3.0,8.0,23.0,7.0,12.0,0.0,19.0,43.0,4.0,3.0,8.0,18.0,19.0,0.0,18.0,4.0,6.0,3.0,9.0,9.0,4.0,7.0,6.0,14.0,15.0,27.0,8.0,26.0,3.0,31.0,16.0,22.0,12.0,12.0,2.0,3.0,7.0,13.0,1.0,1.0,5.0,15.0,5.0,9.0,3.0,3.0,13.0,1.0,19.0,28.0,5.0,25.0,36.0,2.0,1.0,8.0,0.0,2.0,11.0,9.0,8.0,24.0,11.0,6.0,20.0,15.0,9.0,4.0,7.0,10.0,30.0,0.0,10.0,2.0,0.0,8.0,3.0,2.0,15.0,3.0,11.0,5.0,19.0,5.0,5.0,35.0,18.0,1.0,2.0,4.0,1.0,24.0,11.0,8.0,10.0,11.0,14.0,18.0,6.0,3.0,11.0,23.0,1.0,19.0,1.0,23.0,2.0,14.0,18.0,12.0,7.0,4.0,14.0,36.0,15.0,5.0,5.0,26.0,11.0,11.0,4.0,9.0,10.0,22.0,0.0,23.0,1.0,0.0,6.0,2.0,23.0,0.0,6.0,3.0,16.0,10.0,2.0,58.0,11.0,13.0,3.0,0.0,17.0,21.0,3.0,28.0,4.0,2.0,20.0,8.0,22.0,23.0,1.0,26.0,24.0,18.0,5.0,2.0,2.0,9.0,2.0,1.0,3.0,29.0,5.0,2.0,17.0,7.0,8.0,2.0,4.0,6.0,50.0,16.0,5.0,16.0,13.0,3.0,17.0,23.0,12.0,20.0,9.0,17.0,4.0,15.0,21.0,4.0,6.0,3.0,18.0,9.0,1.0,15.0,24.0,6.0,11.0,37.0,8.0,9.0,3.0,4.0,15.0,2.0,1.0,48.0,1.0,10.0,13.0,9.0,17.0,28.0,6.0,3.0,4.0,0.0,9.0,2.0,8.0,11.0,16.0,6.0,20.0,6.0,6.0,0.0,0.0,6.0,4.0,8.0,37.0,2.0,6.0,16.0,10.0,14.0,14.0,0.0,11.0,1.0,4.0,8.0,36.0,15.0,16.0,5.0,5.0,31.0,27.0,17.0,21.0,5.0,12.0,1.0,13.0,12.0,9.0,1.0,6.0,8.0,11.0,6.0,7.0,11.0,11.0,0.0,41.0,8.0,8.0,6.0,7.0,7.0,3.0,0.0,7.0,15.0,5.0,3.0,28.0,30.0,10.0,3.0,0.0,2.0,2.0,6.0,20.0,1.0,5.0,5.0,4.0,3.0,2.0,23.0,10.0,2.0,31.0,4.0,7.0,21.0,5.0,2.0,17.0,4.0,5.0,1.0,14.0,1.0,4.0,18.0,20.0,5.0,13.0,21.0,9.0,4.0,1.0,26.0,1.0,2.0,5.0,9.0,10.0,10.0,33.0,11.0,14.0,65.0,26.0,17.0,25.0,4.0,29.0,4.0,6.0,1.0,24.0,32.0,17.0,8.0,14.0,5.0,5.0,11.0,1.0,2.0,4.0,15.0,1.0,14.0,9.0,4.0,1.0,5.0,7.0,29.0,32.0,9.0,6.0,10.0,21.0,20.0,5.0,17.0,11.0,20.0,2.0,2.0,5.0,21.0,38.0,6.0,16.0,3.0,8.0,7.0,24.0,2.0,4.0,0.0,1.0,0.0,22.0,7.0,3.0,3.0,17.0,1.0,8.0,3.0,6.0,22.0,25.0,6.0,1.0,5.0,2.0,2.0,6.0,4.0,0.0,2.0,19.0,0.0,1.0,24.0,1.0,6.0,13.0,9.0,20.0,27.0,5.0,29.0,2.0,8.0,19.0,3.0,10.0,4.0,5.0,31.0,10.0,9.0,2.0,15.0,14.0,0.0,6.0,5.0,1.0,21.0,9.0,6.0,20.0,5.0,7.0,25.0,7.0,39.0,17.0,6.0,8.0,2.0,28.0,15.0,1.0,2.0,3.0,10.0,5.0,9.0,6.0,7.0,4.0,20.0,25.0,23.0,6.0,2.0,5.0,14.0,8.0,20.0,2.0,13.0,13.0,25.0,2.0,2.0,11.0,3.0,13.0,8.0,8.0,3.0,2.0,17.0,11.0,2.0,4.0,19.0,5.0,3.0,2.0,11.0,28.0,3.0,1.0,1.0,2.0,2.0,18.0,8.0,15.0,55.0,1.0,6.0,8.0,16.0,5.0,10.0,19.0,11.0,15.0,29.0,13.0,6.0,3.0,16.0,3.0,19.0,3.0,29.0,24.0,2.0,10.0,13.0,7.0,2.0,10.0,1.0,45.0,25.0,33.0,3.0,17.0,13.0,19.0,33.0,4.0,1.0,3.0,3.0,16.0,18.0,48.0,5.0,7.0,14.0,0.0,22.0,1.0,10.0,22.0,4.0,12.0,8.0,8.0,2.0,4.0,1.0,3.0,18.0,3.0,4.0,1.0,36.0,7.0,23.0,25.0,15.0,0.0,4.0,24.0,13.0,8.0,10.0,10.0,2.0,3.0,2.0,11.0,4.0,9.0,19.0,3.0,27.0,2.0,17.0,9.0,5.0,4.0,1.0,4.0,7.0,1.0,5.0,2.0,14.0,2.0,14.0,7.0,5.0,7.0,29.0,6.0,10.0,22.0,61.0,4.0,2.0,5.0,24.0,7.0,0.0,15.0,5.0,7.0,6.0,10.0,2.0,3.0,2.0,37.0,1.0,4.0,12.0,4.0,5.0,13.0,10.0,8.0,12.0,19.0,14.0,6.0,5.0,8.0,6.0,3.0,1.0,6.0,27.0,7.0,13.0,6.0,7.0,12.0,19.0,11.0,3.0,24.0,15.0,15.0,30.0,1.0,2.0,36.0,17.0,1.0,6.0,19.0,17.0,18.0,11.0,1.0,5.0,2.0,28.0,1.0,11.0,1.0,9.0,5.0,2.0,4.0,4.0,7.0,16.0,14.0,15.0,1.0,11.0,5.0,1.0,18.0,22.0,1.0,11.0,20.0,12.0,3.0,7.0,2.0,0.0,5.0,10.0,14.0,18.0,10.0,20.0,20.0,17.0,27.0,24.0,9.0,15.0,9.0,4.0,1.0,22.0,13.0,16.0,13.0,10.0,37.0,2.0,36.0,8.0,4.0,1.0,13.0,9.0,28.0,1.0,3.0,2.0,22.0,6.0,23.0,32.0,18.0,5.0,5.0,3.0,27.0,1.0,2.0,2.0,9.0,1.0,23.0,13.0,3.0,31.0,16.0,55.0,18.0,2.0,33.0,10.0,12.0,4.0,6.0,8.0,3.0,2.0,1.0,6.0,12.0,7.0,3.0,2.0,2.0,58.0,2.0,2.0,35.0,2.0,38.0,4.0,8.0,40.0,2.0,12.0,7.0,33.0,5.0,17.0,2.0,19.0,12.0,17.0,15.0,2.0,9.0,8.0,18.0,0.0,4.0,34.0,1.0,8.0,7.0,16.0,13.0,8.0,9.0,22.0,2.0,14.0,7.0,6.0,14.0,40.0,8.0,14.0,9.0,9.0,3.0,6.0,1.0,4.0,6.0,9.0,1.0,16.0,2.0,7.0,4.0,6.0,32.0,4.0,13.0,2.0,19.0,32.0,18.0,18.0,16.0,10.0,28.0,59.0,9.0,28.0,1.0,30.0,8.0,6.0,2.0,2.0,5.0,17.0,2.0,7.0,6.0,23.0,20.0,2.0,3.0,9.0,7.0,2.0,1.0,3.0,18.0,6.0,20.0,24.0,24.0,2.0,29.0,9.0,2.0,3.0,4.0,4.0,24.0,4.0,7.0,18.0,5.0,16.0,13.0,32.0,7.0,7.0,2.0,33.0,2.0,5.0,18.0,15.0,13.0,2.0,1.0,24.0,5.0,12.0,2.0,19.0,6.0,2.0,5.0,29.0,9.0,22.0,6.0,10.0,3.0,1.0,9.0,1.0,19.0,3.0,16.0,9.0,13.0,25.0,3.0,2.0,15.0,28.0,4.0,21.0,0.0,11.0,50.0,11.0,28.0,10.0,14.0,10.0,6.0,18.0,22.0,7.0,11.0,8.0,24.0,11.0,9.0,17.0,6.0,1.0,5.0,17.0,1.0,13.0,10.0,8.0,15.0,19.0,2.0,19.0,6.0,4.0,9.0,20.0,31.0,0.0,10.0,37.0,3.0,7.0,19.0,85.0,16.0,2.0,52.0,31.0,13.0,32.0,6.0,5.0,14.0,2.0,17.0,8.0,14.0,5.0,1.0,20.0,26.0,25.0,18.0,2.0,9.0,9.0,3.0,1.0,4.0,13.0,5.0,4.0,6.0,73.0,23.0,2.0,1.0,3.0,10.0,13.0,13.0,5.0,28.0,5.0,13.0,9.0,4.0,16.0,4.0,5.0,3.0,3.0,8.0,6.0,9.0,7.0,4.0,11.0,10.0,13.0,17.0,3.0,3.0,2.0,4.0,9.0,17.0,1.0,5.0,3.0,9.0,17.0,1.0,2.0,8.0,30.0,16.0,1.0,0.0,30.0,6.0,9.0,9.0,8.0,6.0,51.0,20.0,1.0,0.0,1.0,25.0,15.0,64.0,8.0,31.0,6.0,7.0,11.0,8.0,14.0,2.0,16.0,10.0,24.0,0.0,12.0,16.0,36.0,1.0,23.0,12.0,2.0,3.0,12.0,21.0,6.0,3.0,11.0,9.0,3.0,7.0,6.0,13.0,41.0,1.0,3.0,6.0,10.0,7.0,2.0,2.0,2.0,13.0,5.0,7.0,1.0,10.0,8.0,3.0,3.0,10.0,4.0,20.0,5.0,3.0,3.0,15.0,3.0,3.0,11.0,2.0,0.0,7.0,22.0,1.0,3.0,16.0,8.0,17.0,2.0,59.0,3.0,7.0,11.0,1.0,2.0,2.0,3.0,12.0,7.0,7.0,12.0,7.0,13.0,13.0,7.0,10.0,36.0,2.0,0.0,25.0,3.0,11.0,7.0,2.0,0.0,1.0,1.0,23.0,4.0,9.0,2.0,14.0,19.0,13.0,7.0,8.0,34.0,17.0,4.0,3.0,1.0,39.0,5.0,21.0,14.0,7.0,7.0,4.0,1.0,25.0,8.0,23.0,4.0,14.0,3.0,12.0,8.0,7.0,11.0,2.0,13.0,25.0,5.0,22.0,3.0,7.0,16.0,5.0,0.0,14.0,14.0,16.0,2.0,24.0,59.0,1.0,15.0,20.0,2.0,4.0,4.0,30.0,13.0,12.0,14.0,26.0,2.0,1.0,21.0,43.0,28.0,14.0,7.0,7.0,1.0,23.0,16.0,13.0,11.0,17.0,37.0,1.0,10.0,18.0,2.0,0.0,11.0,4.0,3.0,19.0,13.0,13.0,6.0,15.0,15.0,14.0,27.0,2.0,6.0,18.0,12.0,11.0,3.0,23.0,2.0,23.0,5.0,4.0,4.0,2.0,2.0,14.0,3.0,31.0,13.0,7.0,17.0,15.0,8.0,3.0,26.0,17.0,3.0,9.0,8.0,8.0,31.0,18.0,15.0,4.0,8.0,7.0,2.0,17.0,15.0,4.0,6.0,6.0,1.0,10.0,20.0,7.0,2.0,6.0,12.0,2.0,10.0,28.0,4.0,15.0,1.0,13.0,0.0,13.0,8.0,3.0,6.0,0.0,8.0,14.0,10.0,17.0,4.0,7.0,6.0,3.0,4.0,29.0,1.0,42.0,9.0,5.0,17.0,1.0,5.0,7.0,1.0,1.0,17.0,11.0,5.0,5.0,13.0,1.0,10.0,16.0,8.0,25.0,3.0,5.0,5.0,2.0,17.0,6.0,3.0,6.0,4.0,0.0,14.0,21.0,10.0,1.0,3.0,6.0,1.0,31.0,18.0,27.0,3.0,12.0,27.0,1.0,0.0,31.0,9.0,25.0,9.0,18.0,3.0,9.0,21.0,25.0,29.0,0.0,6.0,7.0,12.0,10.0,6.0,5.0,2.0,11.0,5.0,12.0,3.0,53.0,7.0,3.0,5.0,1.0,0.0,2.0,28.0,17.0,16.0,1.0,2.0,3.0,6.0,17.0,8.0,5.0,3.0,10.0,11.0,1.0,0.0,8.0,11.0,6.0,8.0,8.0,13.0,27.0,9.0,10.0,10.0,2.0,19.0,9.0,11.0,0.0,13.0,3.0,2.0,3.0,2.0,13.0,8.0,2.0,11.0,0.0,26.0,3.0,6.0,12.0,28.0,1.0,7.0,10.0,22.0,2.0,0.0,11.0,1.0,8.0,14.0,7.0,13.0,19.0,9.0,14.0,3.0,37.0,7.0,15.0,2.0,1.0,1.0,63.0,3.0,35.0,16.0,10.0,3.0,4.0,21.0,4.0,5.0,5.0,9.0,15.0,2.0,5.0,6.0,5.0,10.0,3.0,1.0,6.0,3.0,4.0,6.0,11.0,6.0,6.0,19.0,1.0,1.0,4.0,28.0,1.0,35.0,6.0,22.0,2.0,11.0,25.0,18.0,11.0,14.0,15.0,20.0,13.0,11.0,27.0,14.0,5.0,0.0,24.0,12.0,1.0,4.0,32.0,1.0,25.0,52.0,36.0,18.0,21.0,7.0,15.0,10.0,5.0,3.0,15.0,0.0,6.0,1.0,3.0,13.0,12.0,5.0,8.0,7.0,15.0,6.0,12.0,24.0,18.0,11.0,10.0,15.0,27.0,3.0,10.0,17.0,14.0,2.0,6.0,1.0,16.0,47.0,0.0,7.0,32.0,42.0,5.0,10.0,10.0,1.0,3.0,5.0,6.0,6.0,11.0,6.0,9.0,2.0,25.0,9.0,3.0,5.0,12.0,12.0,8.0,4.0,29.0,4.0,5.0,7.0,6.0,40.0,13.0,5.0,13.0,20.0,36.0,15.0,11.0,14.0,14.0,4.0,18.0,31.0,16.0,8.0,48.0,7.0,1.0,0.0,8.0,6.0,12.0,2.0,16.0,3.0,8.0,0.0,6.0,16.0,7.0,2.0,21.0,40.0,4.0,4.0,18.0,21.0,9.0,22.0,7.0,9.0,2.0,15.0,9.0,27.0,39.0,6.0,19.0,46.0,16.0,4.0,9.0,7.0,3.0,12.0,18.0,13.0,2.0,8.0,7.0,14.0,16.0,27.0,18.0,25.0,7.0,35.0,2.0,3.0,3.0,25.0,5.0,2.0,0.0,15.0,6.0,10.0,4.0,3.0,34.0,2.0,6.0,5.0,6.0,9.0,1.0,1.0,10.0,5.0,10.0,7.0,3.0,10.0,9.0,2.0,7.0,4.0,4.0,6.0,14.0,3.0,19.0,0.0,8.0,5.0,10.0,2.0,5.0,6.0,4.0,49.0,16.0,4.0,19.0,10.0,1.0,7.0,6.0,3.0,17.0,28.0,18.0,11.0,5.0,6.0,2.0,39.0,4.0,19.0,14.0,9.0,5.0,32.0,0.0,17.0,8.0,14.0,14.0,1.0,2.0,4.0,11.0,8.0,8.0,4.0,29.0,12.0,3.0,1.0,5.0,11.0,7.0,18.0,7.0,14.0,1.0,1.0,32.0,14.0,1.0,10.0,6.0,87.0,21.0,5.0,31.0,12.0,26.0,3.0,6.0,1.0,4.0,0.0,8.0,9.0,1.0,16.0,13.0,9.0,1.0,7.0,15.0,7.0,4.0,15.0,5.0,9.0,9.0,2.0,8.0,22.0,5.0,9.0,0.0,13.0,17.0,15.0,37.0,8.0,1.0,42.0,18.0,1.0,16.0,6.0,1.0,11.0,1.0,21.0,5.0,11.0,26.0,1.0,32.0,12.0,26.0,6.0,2.0,1.0,3.0,7.0,24.0,16.0,11.0,12.0,1.0,5.0,42.0,4.0,1.0,7.0,8.0,18.0,3.0,8.0,39.0,4.0,1.0,28.0,2.0,7.0,1.0,9.0,11.0,2.0,8.0,4.0,8.0,20.0,11.0,8.0,21.0,14.0,18.0,9.0,1.0,31.0,3.0,25.0,3.0,3.0,22.0,10.0,25.0,2.0,0.0,11.0,13.0,3.0,10.0,11.0,18.0,2.0,2.0,0.0,3.0,7.0,6.0,8.0,1.0,6.0,26.0,30.0,1.0,9.0,5.0,5.0,46.0,18.0,3.0,38.0,4.0,9.0,6.0,13.0,1.0,17.0,11.0,50.0,15.0,11.0,11.0,12.0,52.0,7.0,6.0,26.0,1.0,13.0,0.0,4.0,0.0,2.0,0.0,23.0,2.0,8.0,4.0,7.0,38.0,29.0,5.0,2.0,18.0,19.0,5.0,3.0,5.0,10.0,3.0,1.0,8.0,4.0,39.0,2.0,22.0,1.0,18.0,13.0,19.0,4.0,8.0,0.0,6.0,7.0,7.0,12.0,9.0,2.0,11.0,22.0,13.0,8.0,3.0,17.0,0.0,2.0,29.0,4.0,13.0,0.0,17.0,15.0,21.0,16.0,9.0,13.0,4.0,22.0,40.0,7.0,1.0,10.0,2.0,15.0,20.0,5.0,9.0,4.0,18.0,25.0,4.0,10.0,34.0,12.0,4.0,28.0,7.0,20.0,2.0,2.0,13.0,2.0,41.0,15.0,29.0,4.0,22.0,17.0,2.0,6.0,3.0,3.0,1.0,38.0,13.0,9.0,2.0,5.0,7.0,10.0,6.0,5.0,60.0,11.0,17.0,13.0,8.0,1.0,14.0,7.0,10.0,1.0,2.0,5.0,11.0,9.0,2.0,6.0,7.0,17.0,17.0,16.0,4.0,4.0,10.0,14.0,10.0,11.0,8.0,16.0,32.0,13.0,16.0,4.0,9.0,0.0,15.0,8.0,18.0,7.0,4.0,16.0,18.0,17.0,17.0,41.0,1.0,11.0,28.0,6.0,14.0,1.0,37.0,15.0,57.0,4.0,50.0,1.0,8.0,19.0,45.0,2.0,0.0,8.0,12.0,5.0,14.0,38.0,25.0,0.0,9.0,1.0,10.0,11.0,22.0,9.0,4.0,7.0,9.0,22.0,15.0,8.0,12.0,16.0,9.0,1.0,8.0,13.0,3.0,2.0,34.0,5.0,4.0,4.0,2.0,1.0,16.0,19.0,4.0,29.0,14.0,0.0,4.0,17.0,10.0,60.0,10.0,6.0,13.0,14.0,14.0,21.0,1.0,16.0,14.0,5.0,12.0,3.0,18.0,3.0,21.0,29.0,29.0,4.0,18.0,2.0,1.0,23.0,13.0,58.0,12.0,31.0,23.0,10.0,13.0,25.0,3.0,11.0,1.0,4.0,15.0,4.0,3.0,0.0,3.0,2.0,3.0,39.0,2.0,14.0,13.0,2.0,33.0,2.0,30.0,14.0,2.0,6.0,3.0,25.0,13.0,5.0,1.0,11.0,2.0,31.0,5.0,17.0,6.0,51.0,10.0,7.0,3.0,13.0,2.0,5.0,23.0,11.0,30.0,8.0,26.0,8.0,0.0,3.0,3.0,9.0,6.0,22.0,44.0,11.0,3.0,4.0,8.0,7.0,5.0,22.0,4.0,26.0,15.0,2.0,3.0,1.0,6.0,9.0,2.0,68.0,0.0,7.0,7.0,4.0,16.0,30.0,3.0,33.0,15.0,5.0,3.0,2.0,10.0,39.0,4.0,33.0,3.0,0.0,0.0,14.0,5.0,8.0,19.0,2.0,21.0,3.0,48.0,23.0,16.0,17.0,5.0,18.0,3.0,3.0,2.0,3.0,22.0,2.0,8.0,10.0,5.0,10.0,6.0,3.0,16.0,15.0,14.0,6.0,9.0,25.0,3.0,2.0,11.0,27.0,7.0,10.0,4.0,12.0,7.0,7.0,2.0,16.0,26.0,14.0,19.0,6.0,1.0,31.0,35.0,23.0,11.0,2.0,13.0,2.0,2.0,5.0,6.0,26.0,9.0,1.0,8.0,3.0,1.0,1.0,4.0,20.0,45.0,11.0,4.0,9.0,12.0,1.0,10.0,8.0,11.0,11.0,15.0,4.0,27.0,15.0,0.0,1.0,19.0,4.0,19.0,27.0,17.0,0.0,3.0,19.0,9.0,18.0,13.0,3.0,2.0,3.0,17.0,7.0,3.0,4.0,3.0,8.0,5.0,15.0,3.0,2.0,3.0,9.0,31.0,1.0,26.0,3.0,8.0,5.0,19.0,8.0,4.0,8.0,3.0,3.0,50.0,30.0,1.0,11.0,6.0,17.0,0.0,36.0,25.0,12.0,4.0,17.0,5.0,2.0,0.0,12.0,3.0,29.0,4.0,38.0,4.0,14.0,7.0,3.0,0.0,33.0,6.0,16.0,25.0,4.0,7.0,5.0,2.0,0.0,6.0,10.0,5.0,14.0,13.0,4.0,7.0,1.0,8.0,7.0,0.0,23.0,14.0,20.0,5.0,10.0,5.0,12.0,6.0,9.0,40.0,4.0,1.0,20.0,12.0,3.0,2.0,7.0,7.0,4.0,31.0,11.0,17.0,16.0,16.0,51.0,12.0,32.0,3.0,8.0,5.0,14.0,7.0,8.0,9.0,14.0,4.0,21.0,17.0,10.0,8.0,5.0,5.0,5.0,10.0,14.0,5.0,7.0,8.0,10.0,3.0,5.0,3.0,3.0,6.0,9.0,37.0,23.0,18.0,26.0,23.0,27.0,2.0,20.0,67.0,11.0,6.0,14.0,3.0,23.0,14.0,4.0,1.0,12.0,9.0,9.0,18.0,5.0,17.0,5.0,2.0,18.0,12.0,4.0,18.0,5.0,3.0,11.0,10.0,3.0,3.0,2.0,25.0,6.0,3.0,32.0,17.0,14.0,2.0,0.0,47.0,11.0,21.0,14.0,17.0,21.0,9.0,1.0,14.0,8.0,16.0,7.0,11.0,10.0,23.0,2.0,20.0,16.0,10.0,1.0,28.0,22.0,3.0,58.0,1.0,3.0,16.0,1.0,34.0,52.0,1.0,6.0,23.0,21.0,8.0,19.0,12.0,10.0,1.0,13.0,2.0,43.0,8.0,7.0,13.0,20.0,0.0,7.0,19.0,4.0,11.0,2.0,16.0,6.0,6.0,9.0,20.0,10.0,4.0,27.0,4.0,19.0,30.0,10.0,4.0,7.0,1.0,4.0,33.0,11.0,6.0,8.0,2.0,14.0,4.0,20.0,10.0,13.0,15.0,3.0,9.0,1.0,15.0,50.0,3.0,13.0,22.0,6.0,2.0,8.0,6.0,9.0,14.0,7.0,6.0,0.0,2.0,13.0,5.0,6.0,10.0,9.0,43.0,4.0,23.0,1.0,4.0,4.0,29.0,6.0,12.0,6.0,1.0,31.0,19.0,53.0,6.0,17.0,5.0,5.0,2.0,24.0,19.0,16.0,10.0,8.0,7.0,0.0,5.0,6.0,5.0,5.0,18.0,8.0,10.0,14.0,14.0,27.0,6.0,10.0,11.0,14.0,13.0,4.0,4.0,2.0,1.0,3.0,9.0,4.0,4.0,6.0,18.0,2.0,4.0,56.0,7.0,2.0,6.0,12.0,7.0,1.0,8.0,7.0,21.0,14.0,11.0,9.0,17.0,15.0,14.0,23.0,11.0,44.0,2.0,7.0,17.0,8.0,11.0,6.0,19.0,13.0,0.0,9.0,18.0,13.0,7.0,3.0,33.0,20.0,1.0,1.0,1.0,2.0,74.0,3.0,18.0,7.0,21.0,5.0,4.0,10.0,14.0,21.0,17.0,1.0,9.0,5.0,0.0,10.0,5.0,12.0,13.0,39.0,0.0,17.0,16.0,2.0,13.0,17.0,20.0,9.0,1.0,28.0,2.0,33.0,15.0,15.0,8.0,27.0,14.0,22.0,19.0,31.0,1.0,2.0,16.0,13.0,14.0,5.0,1.0,12.0,8.0,5.0,7.0,5.0,4.0,2.0,7.0,2.0,9.0,4.0,10.0,4.0,1.0,13.0,4.0,26.0,11.0,2.0,18.0,38.0,29.0,6.0,2.0,10.0,10.0,18.0,7.0,0.0,7.0,1.0,16.0,27.0,5.0,6.0,2.0,16.0,0.0,3.0,3.0,6.0,9.0,7.0,1.0,4.0,3.0,15.0,9.0,19.0,14.0,1.0,1.0,6.0,4.0,3.0,9.0,4.0,9.0,3.0,22.0,19.0,18.0,2.0,15.0,5.0,2.0,14.0,7.0,16.0,4.0,2.0,6.0,14.0,9.0,1.0,2.0,2.0,9.0,21.0,43.0,8.0,7.0,13.0,1.0,1.0,2.0,33.0,1.0,20.0,3.0,18.0,9.0,3.0,18.0,20.0,14.0,12.0,4.0,0.0,16.0,8.0,12.0,0.0,10.0,5.0,1.0,21.0,67.0,3.0,15.0,18.0,7.0,3.0,10.0,7.0,25.0,0.0,3.0,11.0,18.0,10.0,10.0,7.0,22.0,10.0,2.0,1.0,4.0,2.0,5.0,5.0,3.0,3.0,6.0,47.0,38.0,22.0,9.0,9.0,4.0,8.0,9.0,9.0,7.0,21.0,15.0,14.0,7.0,8.0,7.0,0.0,3.0,1.0,15.0,9.0,10.0,20.0,4.0,12.0,15.0,1.0,26.0,0.0,10.0,3.0,8.0,12.0,36.0,1.0,1.0,4.0,14.0,1.0,2.0,21.0,3.0,31.0,5.0,1.0,1.0,20.0,6.0,8.0,3.0,10.0,28.0,9.0,4.0,0.0,20.0,1.0,37.0,25.0,7.0,2.0,9.0,15.0,0.0,45.0,18.0,7.0,12.0,8.0,9.0,5.0,0.0,0.0,12.0,31.0,1.0,4.0,10.0,32.0,10.0,9.0,3.0,16.0,2.0,6.0,7.0,5.0,1.0,3.0,9.0,5.0,3.0,4.0,13.0,1.0,19.0,1.0,11.0,1.0,20.0,20.0,9.0,11.0,17.0,10.0,19.0,26.0,8.0,15.0,12.0,2.0,20.0,1.0,3.0,7.0,4.0,13.0,14.0,11.0,20.0,7.0,8.0,5.0,26.0,7.0,9.0,38.0,27.0,3.0,10.0,24.0,3.0,10.0,17.0,0.0,11.0,12.0,2.0,2.0,1.0,21.0,5.0,15.0,6.0,36.0,21.0,3.0,32.0,18.0,10.0,1.0,0.0,5.0,11.0,3.0,3.0,9.0,1.0,8.0,11.0,9.0,8.0,15.0,0.0,13.0,14.0,11.0,2.0,2.0,8.0,10.0,31.0,2.0,8.0,8.0,7.0,5.0,21.0,19.0,8.0,1.0,8.0,2.0,1.0,0.0,2.0,14.0,6.0,3.0,1.0,26.0,4.0,21.0,13.0,9.0,4.0,3.0,13.0,2.0,4.0,35.0,1.0,14.0,22.0,24.0,4.0,11.0,6.0,2.0,6.0,6.0,10.0,2.0,3.0,38.0,24.0,0.0,0.0,9.0,28.0,8.0,20.0,4.0,15.0,2.0,6.0,3.0,5.0,19.0,4.0,11.0,1.0,3.0,28.0,2.0,25.0,22.0,11.0,45.0,24.0,2.0,13.0,1.0,4.0,9.0,8.0,17.0,5.0,4.0,6.0,4.0,33.0,6.0,40.0,17.0,2.0,4.0,1.0,2.0,0.0,0.0,5.0,18.0,24.0,4.0,8.0,27.0,19.0,14.0,42.0,2.0,2.0,21.0,2.0,7.0,7.0,5.0,10.0,1.0,7.0,3.0,22.0,14.0,6.0,4.0,6.0,25.0,5.0,2.0,6.0,21.0,2.0,13.0,3.0,5.0,2.0,1.0,14.0,0.0,4.0,23.0,7.0,14.0,16.0,20.0,0.0,15.0,2.0,3.0,5.0,7.0,11.0,2.0,49.0,6.0,9.0,18.0,2.0,9.0,13.0,4.0,21.0,1.0,8.0,5.0,1.0,11.0,4.0,3.0,1.0,2.0,3.0,48.0,8.0,21.0,12.0,12.0,23.0,6.0,5.0,21.0,2.0,7.0,6.0,14.0,2.0,2.0,9.0,10.0,5.0,3.0,6.0,4.0,2.0,31.0,8.0,6.0,45.0,5.0,1.0,5.0,2.0,15.0,3.0,19.0,18.0,32.0,3.0,1.0,4.0,14.0,6.0,4.0,24.0,44.0,6.0,19.0,13.0,1.0,10.0,10.0,12.0,7.0,4.0,15.0,18.0,3.0,38.0,5.0,3.0,4.0,0.0,4.0,6.0,0.0,8.0,2.0,15.0,38.0,15.0,1.0,3.0,29.0,11.0,3.0,12.0,13.0,38.0,14.0,3.0,6.0,24.0,2.0,1.0,3.0,6.0,5.0,12.0,5.0,14.0,27.0,42.0,6.0,3.0,1.0,21.0,2.0,0.0,15.0,5.0,0.0,10.0,14.0,10.0,9.0,30.0,11.0,12.0,10.0,6.0,6.0,2.0,3.0,5.0,21.0,4.0,3.0,9.0,9.0,4.0,21.0,8.0,2.0,15.0,10.0,17.0,0.0,25.0,29.0,4.0,6.0,3.0,10.0,49.0,8.0,10.0,3.0,5.0,6.0,34.0,2.0,12.0,3.0,22.0,3.0,3.0,1.0,20.0,7.0,26.0,26.0,7.0,11.0,9.0,4.0,15.0,3.0,0.0,15.0,11.0,1.0,7.0,20.0,16.0,20.0,3.0,3.0,12.0,3.0,16.0,1.0,5.0,7.0,23.0,11.0,7.0,8.0,24.0,11.0,2.0,3.0,0.0,0.0,22.0,13.0,26.0,1.0,1.0,10.0,1.0,5.0,5.0,13.0,0.0,8.0,14.0,12.0,10.0,6.0,1.0,43.0,5.0,4.0,25.0,3.0,0.0,2.0,2.0,1.0,14.0,8.0,15.0,5.0,2.0,3.0,33.0,34.0,1.0,7.0,4.0,1.0,41.0,3.0,1.0,42.0,19.0,6.0,6.0,5.0,24.0,13.0,15.0,30.0,2.0,8.0,1.0,5.0,14.0,0.0,0.0,4.0,12.0,0.0,23.0,13.0,4.0,40.0,13.0,7.0,1.0,0.0,6.0,0.0,11.0,6.0,42.0,14.0,8.0,2.0,2.0,16.0,7.0,19.0,1.0,2.0,3.0,7.0,9.0,1.0,14.0,9.0,7.0,7.0,7.0,14.0,9.0,14.0,0.0,7.0,13.0,4.0,23.0,7.0,8.0,14.0,2.0,1.0,15.0,21.0,2.0,10.0,15.0,6.0,8.0,1.0,24.0,7.0,4.0,40.0,30.0,10.0,13.0,3.0,9.0,40.0,19.0,0.0,5.0,21.0,5.0,5.0,1.0,6.0,21.0,12.0,0.0,6.0,35.0,10.0,14.0,28.0,4.0,6.0,1.0,5.0,1.0,17.0,6.0,3.0,6.0,6.0,7.0,16.0,5.0,8.0,1.0,30.0,4.0,7.0,4.0,12.0,3.0,6.0,7.0,4.0,1.0,3.0,18.0,8.0,1.0,12.0,2.0,27.0,0.0,2.0,6.0,4.0,5.0,24.0,38.0,0.0,3.0,2.0,18.0,6.0,0.0,12.0,5.0,14.0,16.0,2.0,2.0,25.0,29.0,24.0,7.0,6.0,16.0,0.0,6.0,10.0,6.0,1.0,30.0,15.0,17.0,16.0,10.0,13.0,0.0,24.0,3.0,5.0,5.0,14.0,37.0,24.0,10.0,6.0,14.0,10.0,1.0,1.0,23.0,2.0,23.0,23.0,2.0,6.0,5.0,3.0,12.0,8.0,22.0,7.0,25.0,9.0,8.0,10.0,1.0,18.0,2.0,2.0,5.0,2.0,15.0,15.0,7.0,7.0,1.0,25.0,1.0,4.0,10.0,1.0,2.0,20.0,12.0,12.0,9.0,9.0,12.0,25.0,2.0,40.0,26.0,13.0,5.0,8.0,3.0,2.0,4.0,1.0,3.0,1.0,26.0,2.0,6.0,3.0,4.0,4.0,7.0,1.0,6.0,6.0,1.0,3.0,6.0,7.0,3.0,84.0,2.0,17.0,2.0,6.0,17.0,28.0,2.0,3.0,4.0,0.0,23.0,5.0,54.0,11.0,6.0,5.0,5.0,1.0,3.0,15.0,28.0,2.0,6.0,5.0,20.0,6.0,34.0,8.0,15.0,7.0,17.0,50.0,2.0,8.0,7.0,3.0,3.0,5.0,39.0,13.0,5.0,1.0,5.0,9.0,1.0,2.0,29.0,1.0,30.0,21.0,22.0,4.0,8.0,14.0,8.0,7.0,2.0,10.0,5.0,12.0,4.0,12.0,4.0,9.0,17.0,6.0,10.0,3.0,16.0,6.0,9.0,2.0,4.0,24.0,2.0,2.0,45.0,15.0,5.0,6.0,1.0,5.0,1.0,14.0,6.0,11.0,7.0,9.0,2.0,15.0,22.0,15.0,8.0,6.0,3.0,14.0,9.0,11.0,20.0,15.0,17.0,10.0,1.0,11.0,19.0,18.0,11.0,32.0,10.0,15.0,6.0,20.0,2.0,4.0,12.0,3.0,14.0,9.0,11.0,2.0,24.0,2.0,18.0,9.0,18.0,12.0,48.0,60.0,7.0,26.0,8.0,22.0,9.0,18.0,6.0,8.0,5.0,8.0,1.0,4.0,28.0,25.0,3.0,2.0,5.0,8.0,22.0,20.0,23.0,56.0,10.0,27.0,17.0,5.0,0.0,3.0,5.0,14.0,2.0,4.0,25.0,6.0,19.0,5.0,23.0,1.0,7.0,5.0,2.0,5.0,5.0,6.0,0.0,4.0,5.0,7.0,4.0,10.0,26.0,39.0,5.0,24.0,1.0,7.0,30.0,38.0,2.0,12.0,18.0,9.0,5.0,1.0,3.0,13.0,1.0,34.0,1.0,22.0,14.0,5.0,26.0,21.0,7.0,9.0,3.0,8.0,10.0,5.0,1.0,10.0,6.0,4.0,12.0,8.0,1.0,11.0,8.0,16.0,17.0,3.0,14.0,15.0,0.0,5.0,12.0,6.0,18.0,7.0,1.0,4.0,6.0,8.0,18.0,6.0,82.0,19.0,2.0,26.0,8.0,2.0,3.0,2.0,3.0,3.0,19.0,8.0,2.0,2.0,16.0,9.0,14.0,11.0,3.0,22.0,5.0,16.0,4.0,16.0,8.0,8.0,2.0,13.0,20.0,3.0,14.0,8.0,7.0,7.0,0.0,4.0,10.0,7.0,13.0,6.0,6.0,0.0,27.0,18.0,22.0,2.0,4.0,12.0,4.0,8.0,12.0,10.0,22.0,3.0,34.0,1.0,13.0,14.0,11.0,3.0,10.0,6.0,10.0,11.0,12.0,8.0,5.0,15.0,5.0,11.0,3.0,23.0,5.0,9.0,31.0,0.0,1.0,3.0,4.0,22.0,10.0,5.0,6.0,30.0,17.0,9.0,21.0,26.0,10.0,30.0,10.0,3.0,23.0,14.0,20.0,15.0,8.0,10.0,27.0,15.0,11.0,4.0,3.0,19.0,21.0,10.0,7.0,0.0,4.0,9.0,0.0,11.0,5.0,27.0,28.0,0.0,5.0,38.0,2.0,1.0,22.0,21.0,3.0,19.0,28.0,5.0,22.0,3.0,14.0,3.0,8.0,17.0,16.0,25.0,3.0,1.0,8.0,44.0,15.0,17.0,20.0,2.0,12.0,20.0,4.0,5.0,8.0,17.0,13.0,17.0,13.0,1.0,12.0,13.0,4.0,1.0,9.0,10.0,4.0,5.0,1.0,18.0,22.0,14.0,4.0,18.0,1.0,2.0,14.0,4.0,22.0,1.0,7.0,15.0,9.0,9.0,18.0,18.0,5.0,4.0,4.0,2.0,7.0,2.0,12.0,0.0,7.0,8.0,5.0,30.0,8.0,1.0,41.0,4.0,1.0,4.0,1.0,16.0,13.0,2.0,22.0,20.0,10.0,2.0,2.0,11.0,3.0,7.0,26.0,6.0,8.0,41.0,1.0,1.0,2.0,9.0,8.0,1.0,13.0,10.0,2.0,7.0,10.0,19.0,0.0,8.0,5.0,17.0,33.0,1.0,4.0,0.0,10.0,1.0,8.0,2.0,20.0,15.0,18.0,11.0,3.0,12.0,13.0,0.0,12.0,2.0,6.0,21.0,24.0,6.0,26.0,0.0,9.0,3.0,22.0,3.0,39.0,2.0,12.0,4.0,7.0,8.0,13.0,1.0,13.0,8.0,7.0,2.0,27.0,7.0,5.0,1.0,14.0,6.0,0.0,6.0,7.0,4.0,1.0,11.0,56.0,14.0,11.0,0.0,10.0,5.0,19.0,2.0,6.0,3.0,6.0,15.0,19.0,38.0,66.0,4.0,11.0,10.0,9.0,19.0,27.0,25.0,6.0,5.0,21.0,30.0,2.0,10.0,1.0,1.0,11.0,21.0,6.0,26.0,5.0,9.0,4.0,10.0,21.0,10.0,7.0,9.0,20.0,11.0,19.0,5.0,14.0,15.0,11.0,22.0,8.0,2.0,1.0,11.0,13.0,4.0,1.0,34.0,23.0,1.0,19.0,5.0,15.0,8.0,6.0,3.0,16.0,4.0,23.0,5.0,40.0,6.0,20.0,16.0,18.0,12.0,12.0,5.0,0.0,9.0,4.0,9.0,11.0,17.0,12.0,4.0,21.0,7.0,29.0,10.0,3.0,8.0,14.0,33.0,9.0,40.0,7.0,6.0,17.0,2.0,8.0,2.0,15.0,6.0,3.0,5.0,8.0,12.0,7.0,9.0,13.0,5.0,19.0,12.0,21.0,8.0,6.0,6.0,6.0,7.0,15.0,11.0,5.0,9.0,1.0,29.0,3.0,47.0,13.0,3.0,11.0,8.0,28.0,8.0,14.0,5.0,19.0,10.0,21.0,2.0,32.0,31.0,2.0,14.0,1.0,10.0,5.0,4.0,11.0,28.0,5.0,1.0,11.0,2.0,11.0,5.0,1.0,12.0,4.0,1.0,10.0,14.0,1.0,3.0,17.0,3.0,39.0,17.0,10.0,6.0,22.0,16.0,0.0,0.0,15.0,11.0,4.0,1.0,17.0,6.0,3.0,12.0,5.0,25.0,30.0,1.0,16.0,10.0,11.0,31.0,7.0,16.0,29.0,45.0,3.0,2.0,16.0,24.0,25.0,61.0,2.0,14.0,1.0,9.0,4.0,0.0,2.0,32.0,11.0,4.0,1.0,7.0,0.0,0.0,8.0,2.0,2.0,8.0,19.0,11.0,6.0,4.0,2.0,14.0,23.0,4.0,11.0,9.0,46.0,15.0,5.0,6.0,14.0,10.0,12.0,4.0,14.0,3.0,15.0,29.0,4.0,19.0,1.0,1.0,7.0,3.0,3.0,6.0,10.0,23.0,3.0,3.0,22.0,4.0,3.0,2.0,22.0,15.0,3.0,2.0,27.0,12.0,7.0,6.0,14.0,2.0,1.0,19.0,2.0,1.0,6.0,16.0,1.0,27.0,10.0,4.0,8.0,2.0,20.0,5.0,14.0,26.0,2.0,2.0,30.0,6.0,2.0,2.0,24.0,0.0,23.0,11.0,16.0,16.0,1.0,18.0,2.0,11.0,6.0,17.0,8.0,5.0,1.0,9.0,9.0,4.0,8.0,8.0,7.0,16.0,7.0,5.0,35.0,10.0,13.0,12.0,17.0,20.0,19.0,7.0,4.0,1.0,16.0,1.0,9.0,19.0,9.0,0.0,8.0,13.0,11.0,32.0,3.0,4.0,4.0,56.0,27.0,14.0,4.0,18.0,3.0,23.0,8.0,1.0,3.0,9.0,22.0,12.0,6.0,6.0,5.0,3.0,15.0,2.0,5.0,3.0,25.0,7.0,0.0,1.0,8.0,8.0,1.0,16.0,25.0,18.0,12.0,4.0,8.0,17.0,11.0,15.0,7.0,10.0,1.0,28.0,14.0,3.0,4.0,3.0,12.0,29.0,1.0,1.0,6.0,3.0,22.0,4.0,16.0,9.0,9.0,11.0,17.0,35.0,11.0,6.0,2.0,2.0,1.0,39.0,28.0,22.0,5.0,14.0,6.0,7.0,7.0,34.0,14.0,6.0,0.0,10.0,9.0,24.0,45.0,1.0,26.0,2.0,4.0,50.0,2.0,6.0,12.0,6.0,27.0,4.0,28.0,7.0,13.0,7.0,21.0,48.0,7.0,20.0,2.0,15.0,1.0,12.0,3.0,4.0,23.0,7.0,7.0,5.0,29.0,10.0,3.0,1.0,22.0,3.0,11.0,2.0,5.0,1.0,11.0,12.0,1.0,8.0,13.0,11.0,1.0,3.0,3.0,3.0,13.0,16.0,11.0,11.0,5.0,4.0,8.0,1.0,0.0,10.0,11.0,2.0,4.0,10.0,16.0,8.0,58.0,17.0,25.0,35.0,11.0,12.0,21.0,7.0,4.0,9.0,5.0,0.0,25.0,20.0,19.0,26.0,2.0,18.0,2.0,6.0,16.0,2.0,11.0,7.0,3.0,29.0,3.0,2.0,6.0,10.0,33.0,4.0,12.0,6.0,3.0,1.0,10.0,26.0,12.0,16.0,21.0,4.0,8.0,2.0,1.0,8.0,3.0,15.0,2.0,11.0,5.0,18.0,4.0,32.0,29.0,21.0,13.0,5.0,4.0,13.0,28.0,8.0,55.0,4.0,7.0,1.0,8.0,34.0,15.0,6.0,16.0,6.0,5.0,7.0,16.0,5.0,1.0,9.0,5.0,8.0,20.0,8.0,2.0,3.0,6.0,2.0,1.0,7.0,21.0,14.0,10.0,5.0,26.0,2.0,1.0,15.0,3.0,7.0,6.0,17.0,15.0,10.0,2.0,20.0,20.0,3.0,23.0,38.0,15.0,29.0,7.0,19.0,9.0,5.0,3.0,4.0,2.0,17.0,10.0,15.0,10.0,26.0,8.0,9.0,41.0,4.0,13.0,25.0,15.0,1.0,0.0,1.0,18.0,1.0,52.0,24.0,2.0,3.0,17.0,33.0,17.0,13.0,2.0,13.0,30.0,13.0,11.0,37.0,2.0,1.0,22.0,64.0,14.0,14.0,11.0,1.0,1.0,10.0,18.0,6.0,25.0,56.0,3.0,7.0,3.0,8.0,4.0,35.0,43.0,13.0,47.0,1.0,3.0,6.0,2.0,5.0,2.0,0.0,7.0,15.0,2.0,10.0,7.0,4.0,13.0,2.0,1.0,12.0,6.0,16.0,3.0,4.0,0.0,12.0,5.0,6.0,17.0,0.0,9.0,10.0,4.0,10.0,1.0,8.0,11.0,4.0,6.0,12.0,6.0,1.0,9.0,1.0,1.0,3.0,34.0,10.0,23.0,3.0,29.0,2.0,4.0,6.0,21.0,9.0,15.0,22.0,1.0,5.0,10.0,0.0,18.0,13.0,11.0,1.0,3.0,1.0,14.0,10.0,9.0,4.0,16.0,13.0,26.0,33.0,5.0,6.0,12.0,1.0,4.0,3.0,10.0,11.0,27.0,19.0,14.0,4.0,4.0,6.0,20.0,2.0,7.0,3.0,8.0,0.0,27.0,4.0,24.0,29.0,9.0,12.0,3.0,1.0,10.0,6.0,45.0,6.0,2.0,2.0,4.0,32.0,23.0,6.0,9.0,3.0,10.0,14.0,6.0,2.0,51.0,34.0,3.0,4.0,16.0,2.0,0.0,4.0,7.0,0.0,3.0,8.0,16.0,6.0,7.0,6.0,6.0,7.0,14.0,12.0,7.0,3.0,0.0,5.0,17.0,38.0,7.0,6.0,5.0,21.0,9.0,12.0,2.0,19.0,12.0,8.0,5.0,13.0,1.0,4.0,10.0,26.0,19.0,20.0,6.0,7.0,4.0,1.0,8.0,2.0,2.0,24.0,4.0,18.0,6.0,2.0,15.0,5.0,1.0,1.0,3.0,15.0,24.0,18.0,6.0,13.0,28.0,16.0,16.0,14.0,1.0,8.0,2.0,38.0,4.0,23.0,9.0,12.0,7.0,6.0,16.0,29.0,5.0,10.0,4.0,2.0,17.0,9.0,9.0,11.0,3.0,1.0,2.0,3.0,23.0,3.0,1.0,2.0,22.0,6.0,18.0,19.0,5.0,11.0,18.0,6.0,1.0,12.0,4.0,7.0,16.0,4.0,7.0,1.0,7.0,22.0,4.0,21.0,2.0,1.0,15.0,23.0,27.0,7.0,5.0,1.0,25.0,14.0,50.0,2.0,4.0,4.0,13.0,10.0,2.0,5.0,48.0,11.0,13.0,7.0,9.0,7.0,26.0,2.0,17.0,15.0,12.0,9.0,7.0,5.0,7.0,3.0,9.0,7.0,12.0,15.0,33.0,26.0,20.0,4.0,14.0,7.0,1.0,0.0,7.0,16.0,74.0,4.0,1.0,3.0,31.0,8.0,3.0,15.0,28.0,8.0,18.0,13.0,9.0,0.0,13.0,1.0,2.0,3.0,7.0,61.0,5.0,3.0,2.0,6.0,1.0,1.0,26.0,50.0,7.0,23.0,0.0,7.0,18.0,22.0,39.0,7.0,4.0,72.0,6.0,10.0,3.0,13.0,41.0,10.0,9.0,13.0,5.0,26.0,34.0,61.0,4.0,10.0,18.0,14.0,5.0,8.0,4.0,4.0,4.0,16.0,25.0,4.0,21.0,4.0,47.0,5.0,63.0,5.0,10.0,0.0,14.0,29.0,25.0,26.0,14.0,8.0,1.0,7.0,1.0,8.0,18.0,8.0,0.0,13.0,7.0,11.0,15.0,6.0,13.0,6.0,11.0,2.0,0.0,7.0,17.0,2.0,24.0,17.0,13.0,6.0,29.0,24.0,34.0,6.0,37.0,7.0,36.0,14.0,32.0,2.0,1.0,7.0,6.0,1.0,26.0,5.0,0.0,24.0,2.0,4.0,7.0,16.0,22.0,10.0,7.0,21.0,9.0,17.0,2.0,20.0,33.0,16.0,7.0,6.0,5.0,14.0,3.0,33.0,4.0,27.0,27.0,5.0,7.0,11.0,18.0,13.0,10.0,5.0,3.0,5.0,6.0,4.0,30.0,10.0,5.0,3.0,12.0,9.0,2.0,1.0,9.0,18.0,24.0,5.0,6.0,3.0,5.0,4.0,6.0,6.0,2.0,40.0,3.0,12.0,8.0,16.0,4.0,4.0,17.0,1.0,7.0,3.0,20.0,0.0,7.0,12.0,3.0,6.0,13.0,16.0,19.0,17.0,12.0,20.0,3.0,7.0,2.0,3.0,67.0,13.0,8.0,3.0,12.0,14.0,13.0,14.0,32.0,24.0,0.0,28.0,6.0,29.0,12.0,12.0,8.0,3.0,8.0,1.0,5.0,2.0,13.0,2.0,0.0,20.0,13.0,1.0,9.0,10.0,7.0,8.0,2.0,12.0,4.0,12.0,32.0,5.0,8.0,1.0,19.0,17.0,1.0,9.0,18.0,7.0,17.0,18.0,19.0,15.0,14.0,31.0,7.0,6.0,2.0,1.0,29.0,35.0,0.0,5.0,34.0,2.0,25.0,27.0,4.0,9.0,11.0,3.0,7.0,25.0,2.0,14.0,10.0,10.0,8.0,2.0,42.0,27.0,2.0,11.0,7.0,6.0,7.0,7.0,8.0,3.0,1.0,2.0,7.0,14.0,6.0,5.0,3.0,13.0,0.0,9.0,4.0,7.0,7.0,16.0,35.0,4.0,2.0,7.0,9.0,1.0,2.0,2.0,3.0,4.0,24.0,9.0,8.0,29.0,11.0,2.0,12.0,2.0,6.0,5.0,39.0,12.0,12.0,6.0,8.0,7.0,18.0,26.0,4.0,21.0,52.0,2.0,3.0,11.0,1.0,8.0,4.0,4.0,6.0,70.0,5.0,31.0,7.0,1.0,3.0,5.0,16.0,1.0,7.0,3.0,8.0,4.0,6.0,1.0,35.0,28.0,4.0,23.0,9.0,18.0,1.0,10.0,2.0,16.0,5.0,23.0,4.0,2.0,19.0,27.0,22.0,14.0,21.0,19.0,15.0,2.0,22.0,18.0,15.0,13.0,1.0,2.0,12.0,22.0,6.0,4.0,9.0,4.0,1.0,4.0,33.0,9.0,24.0,7.0,14.0,8.0,51.0,23.0,9.0,13.0,11.0,9.0,2.0,9.0,27.0,1.0,45.0,3.0,29.0,5.0,4.0,6.0,53.0,34.0,3.0,25.0,31.0,10.0,4.0,19.0,23.0,9.0,2.0,8.0,10.0,14.0,12.0,36.0,4.0,6.0,4.0,13.0,2.0,12.0,16.0,31.0,1.0,4.0,5.0,9.0,3.0,4.0,22.0,10.0,4.0,6.0,0.0,8.0,12.0,6.0,15.0,1.0,2.0,7.0,22.0,0.0,10.0,18.0,15.0,8.0,5.0,11.0,5.0,2.0,7.0,40.0,3.0,4.0,20.0,6.0,13.0,34.0,12.0,81.0,20.0,5.0,12.0,14.0,34.0,1.0,2.0,3.0,2.0,10.0,41.0,19.0,1.0,27.0,7.0,4.0,3.0,0.0,9.0,3.0,6.0,2.0,17.0,5.0,1.0,20.0,31.0,2.0,11.0,18.0,11.0,16.0,13.0,9.0,30.0,18.0,4.0,8.0,2.0,20.0,13.0,7.0,5.0,3.0,35.0,16.0,18.0,3.0,2.0,6.0,2.0,39.0,17.0,18.0,3.0,1.0,35.0,3.0,1.0,14.0,3.0,15.0,6.0,19.0,8.0,28.0,8.0,10.0,8.0,3.0,16.0,20.0,23.0,2.0,24.0,7.0,37.0,2.0,4.0,1.0,8.0,6.0,10.0,0.0,1.0,28.0,2.0,5.0,10.0,18.0,16.0,17.0,8.0,20.0,8.0,7.0,43.0,13.0,3.0,7.0,20.0,1.0,6.0,12.0,35.0,8.0,10.0,2.0,14.0,7.0,3.0,1.0,12.0,1.0,2.0,3.0,4.0,14.0,9.0,7.0,10.0,10.0,4.0,11.0,3.0,14.0,25.0,4.0,4.0,10.0,9.0,18.0,20.0,2.0,14.0,4.0,14.0,26.0,25.0,4.0,1.0,4.0,11.0,1.0,13.0,15.0,36.0,30.0,2.0,7.0,5.0,6.0,3.0,7.0,26.0,10.0,2.0,6.0,10.0,11.0,15.0,3.0,3.0,6.0,6.0,9.0,14.0,31.0,3.0,14.0,10.0,4.0,37.0,11.0,8.0,21.0,28.0,13.0,3.0,3.0,16.0,46.0,63.0,0.0,6.0,11.0,19.0,15.0,4.0,6.0,13.0,24.0,73.0,5.0,12.0,3.0,10.0,1.0,4.0,12.0,5.0,9.0,16.0,63.0,17.0,1.0,9.0,21.0,6.0,1.0,2.0,10.0,12.0,12.0,3.0,28.0,3.0,6.0,47.0,8.0,33.0,5.0,14.0,36.0,31.0,22.0,16.0,20.0,21.0,2.0,30.0,21.0,1.0,32.0,6.0,3.0,4.0,6.0,6.0,2.0,7.0,16.0,32.0,10.0,17.0,9.0,13.0,1.0,7.0,16.0,10.0,15.0,6.0,12.0,6.0,13.0,2.0,10.0,12.0,3.0,10.0,1.0,17.0,5.0,14.0,24.0,11.0,27.0,14.0,6.0,8.0,0.0,6.0,14.0,5.0,4.0,4.0,4.0,33.0,4.0,12.0,10.0,35.0,4.0,6.0,12.0,11.0,3.0,2.0,15.0,21.0,23.0,4.0,13.0,19.0,30.0,6.0,21.0,18.0,17.0,6.0,26.0,1.0,25.0,9.0,7.0,10.0,4.0,19.0,6.0,3.0,17.0,22.0,6.0,4.0,10.0,23.0,8.0,6.0,19.0,14.0,6.0,10.0,7.0,1.0,6.0,8.0,21.0,2.0,29.0,3.0,2.0,5.0,10.0,7.0,8.0,24.0,26.0,19.0,3.0,14.0,2.0,3.0,24.0,0.0,13.0,6.0,5.0,5.0,10.0,1.0,9.0,7.0,12.0,4.0,1.0,15.0,8.0,19.0,9.0,2.0,1.0,23.0,5.0,9.0,24.0,10.0,16.0,4.0,5.0,6.0,9.0,1.0,4.0,5.0,8.0,17.0,3.0,14.0,23.0,8.0,38.0,4.0,8.0,0.0,9.0,16.0,13.0,1.0,22.0,3.0,14.0,29.0,9.0,3.0,5.0,9.0,9.0,20.0,0.0,4.0,2.0,21.0,0.0,79.0,7.0,6.0,13.0,26.0,11.0,5.0,11.0,23.0,30.0,7.0,0.0,34.0,5.0,11.0,28.0,1.0,0.0,20.0,19.0,13.0,28.0,16.0,15.0,10.0,1.0,1.0,20.0,6.0,41.0,14.0,5.0,14.0,2.0,2.0,11.0,6.0,3.0,5.0,3.0,0.0,39.0,2.0,1.0,17.0,13.0,11.0,16.0,2.0,25.0,23.0,4.0,7.0,24.0,6.0,15.0,3.0,25.0,35.0,19.0,19.0,6.0,35.0,25.0,5.0,2.0,1.0,23.0,12.0,11.0,5.0,2.0,8.0,13.0,6.0,1.0,5.0,4.0,4.0,7.0,25.0,2.0,6.0,14.0,11.0,4.0,1.0,2.0,7.0,4.0,9.0,6.0,10.0,13.0,23.0,4.0,4.0,22.0,16.0,28.0,8.0,2.0,0.0,4.0,17.0,5.0,3.0,3.0,6.0,8.0,6.0,15.0,4.0,3.0,10.0,13.0,20.0,23.0,1.0,11.0,1.0,18.0,15.0,9.0,6.0,20.0,14.0,16.0,42.0,11.0,7.0,5.0,5.0,3.0,5.0,14.0,4.0,7.0,1.0,7.0,10.0,3.0,20.0,17.0,4.0,28.0,11.0,7.0,7.0,21.0,1.0,5.0,21.0,9.0,4.0,30.0,22.0,3.0,22.0,3.0,6.0,14.0,30.0,4.0,9.0,24.0,5.0,3.0,9.0,1.0,2.0,21.0,3.0,15.0,7.0,5.0,1.0,17.0,2.0,16.0,4.0,3.0,1.0,1.0,2.0,19.0,6.0,1.0,21.0,5.0,10.0,27.0,7.0,2.0,30.0,9.0,5.0,24.0,9.0,1.0,52.0,9.0,13.0,29.0,6.0,11.0,5.0,6.0,1.0,5.0,8.0,27.0,4.0,17.0,6.0,8.0,1.0,7.0,16.0,8.0,17.0,19.0,14.0,4.0,26.0,16.0,11.0,5.0,14.0,12.0,2.0,8.0,34.0,12.0,1.0,9.0,16.0,31.0,13.0,14.0,6.0,10.0,2.0,6.0,2.0,0.0,10.0,11.0,1.0,10.0,4.0,2.0,6.0,5.0,11.0,10.0,21.0,1.0,1.0,15.0,17.0,10.0,4.0,9.0,3.0,1.0,5.0,2.0,7.0,13.0,5.0,8.0,12.0,4.0,12.0,0.0,9.0,8.0,5.0,4.0,3.0,6.0,3.0,26.0,1.0,10.0,6.0,11.0,20.0,6.0,25.0,1.0,3.0,0.0,15.0,4.0,4.0,11.0,13.0,2.0,27.0,1.0,21.0,1.0,14.0,2.0,6.0,36.0,36.0,37.0,0.0,5.0,14.0,12.0,34.0,2.0,3.0,6.0,9.0,5.0,22.0,13.0,5.0,1.0,17.0,16.0,2.0,2.0,1.0,33.0,31.0,19.0,1.0,7.0,7.0,57.0,9.0,3.0,5.0,15.0,12.0,0.0,3.0,32.0,13.0,12.0,17.0,14.0,8.0,19.0,8.0,1.0,12.0,20.0,19.0,2.0,12.0,20.0,1.0,5.0,20.0,4.0,1.0,2.0,12.0,0.0,2.0,9.0,4.0,9.0,3.0,5.0,15.0,15.0,10.0,11.0,31.0,19.0,7.0,26.0,14.0,8.0,17.0,7.0,38.0,18.0,1.0,54.0,2.0,1.0,8.0,6.0,1.0,3.0,7.0,24.0,2.0,3.0,4.0,17.0,11.0,7.0,4.0,11.0,19.0,19.0,2.0,1.0,8.0,11.0,2.0,6.0,2.0,6.0,4.0,6.0,6.0,19.0,8.0,6.0,2.0,10.0,25.0,3.0,17.0,1.0,4.0,2.0,4.0,21.0,19.0,42.0,33.0,13.0,3.0,4.0,24.0,2.0,10.0,1.0,12.0,21.0,3.0,7.0,16.0,15.0,41.0,4.0,30.0,3.0,5.0,12.0,52.0,8.0,2.0,4.0,4.0,14.0,3.0,9.0,1.0,1.0,14.0,6.0,20.0,11.0,0.0,16.0,12.0,12.0,9.0,2.0,0.0,0.0,4.0,11.0,22.0,13.0,3.0,2.0,4.0,2.0,1.0,4.0,11.0,4.0,3.0,4.0,12.0,2.0,8.0,11.0,5.0,15.0,5.0,5.0,15.0,8.0,1.0,6.0,1.0,16.0,3.0,6.0,7.0,1.0,32.0,26.0,1.0,6.0,17.0,16.0,11.0,1.0,4.0,24.0,8.0,3.0,3.0,17.0,7.0,12.0,12.0,7.0,9.0,19.0,2.0,14.0,10.0,2.0,19.0,12.0,11.0,10.0,4.0,21.0,8.0,2.0,1.0,17.0,8.0,5.0,11.0,3.0,19.0,2.0,23.0,11.0,1.0,2.0,3.0,13.0,8.0,12.0,8.0,1.0,6.0,2.0,1.0,18.0,2.0,1.0,3.0,12.0,18.0,69.0,21.0,3.0,4.0,7.0,24.0,7.0,9.0,31.0,10.0,8.0,12.0,7.0,6.0,3.0,11.0,35.0,18.0,11.0,31.0,3.0,3.0,3.0,18.0,5.0,2.0,15.0,4.0,23.0,6.0,16.0,13.0,1.0,3.0,4.0,19.0,13.0,2.0,1.0,26.0,4.0,0.0,20.0,1.0,18.0,18.0,15.0,3.0,2.0,4.0,3.0,0.0,11.0,4.0,10.0,14.0,17.0,6.0,1.0,3.0,21.0,48.0,7.0,35.0,14.0,38.0,3.0,2.0,15.0,12.0,1.0,4.0,11.0,0.0,40.0,11.0,11.0,19.0,7.0,2.0,0.0,22.0,10.0,0.0,29.0,1.0,12.0,11.0,20.0,1.0,1.0,10.0,24.0,19.0,16.0,1.0,11.0,7.0,16.0,3.0,16.0,13.0,39.0,2.0,4.0,11.0,7.0,6.0,1.0,1.0,10.0,11.0,4.0,16.0,8.0,3.0,7.0,4.0,4.0,4.0,11.0,3.0,8.0,3.0,3.0,9.0,2.0,2.0,13.0,3.0,22.0,25.0,3.0,5.0,11.0,6.0,6.0,4.0,4.0,21.0,1.0,7.0,3.0,24.0,5.0,2.0,12.0,4.0,8.0,17.0,24.0,2.0,1.0,25.0,5.0,5.0,2.0,5.0,8.0,4.0,25.0,12.0,4.0,19.0,11.0,6.0,21.0,40.0,8.0,12.0,15.0,77.0,20.0,11.0,1.0,1.0,26.0,3.0,21.0,1.0,1.0,2.0,13.0,9.0,15.0,1.0,29.0,1.0,5.0,21.0,0.0,15.0,1.0,3.0,15.0,13.0,2.0,8.0,16.0,3.0,5.0,5.0,4.0,16.0,13.0,11.0,8.0,5.0,11.0,21.0,10.0,11.0,10.0,11.0,4.0,8.0,2.0,8.0,3.0,25.0,2.0,17.0,1.0,17.0,8.0,5.0,9.0,57.0,4.0,3.0,12.0,5.0,17.0,22.0,10.0,21.0,5.0,11.0,4.0,4.0,6.0,6.0,4.0,21.0,23.0,4.0,5.0,28.0,22.0,16.0,31.0,2.0,12.0,41.0,4.0,3.0,1.0,9.0,29.0,20.0,67.0,17.0,34.0,21.0,5.0,15.0,23.0,19.0,0.0,55.0,7.0,14.0,10.0,20.0,27.0,8.0,9.0,9.0,0.0,18.0,4.0,8.0,22.0,27.0,5.0,14.0,14.0,10.0,6.0,6.0,3.0,22.0,8.0,10.0,8.0,5.0,8.0,21.0,29.0,15.0,19.0,22.0,4.0,4.0,32.0,3.0,1.0,2.0,4.0,23.0,22.0,4.0,5.0,24.0,19.0,2.0,21.0,4.0,19.0,5.0,7.0,1.0,10.0,5.0,8.0,6.0,11.0,2.0,22.0,8.0,0.0,2.0,14.0,11.0,20.0,35.0,4.0,12.0,8.0,14.0,13.0,17.0,9.0,19.0,0.0,27.0,16.0,8.0,6.0,1.0,4.0,13.0,2.0,9.0,7.0,5.0,6.0,1.0,12.0,1.0,3.0,0.0,14.0,12.0,11.0,7.0,1.0,26.0,8.0,10.0,14.0,5.0,3.0,38.0,10.0,3.0,2.0,19.0,12.0,14.0,2.0,8.0,17.0,4.0,5.0,12.0,30.0,4.0,6.0,13.0,7.0,2.0,25.0,14.0,2.0,8.0,6.0,12.0,0.0,5.0,6.0,1.0,2.0,14.0,27.0,2.0,24.0,6.0,2.0,9.0,5.0,17.0,1.0,12.0,10.0,5.0,0.0,21.0,21.0,11.0,20.0,13.0,15.0,5.0,4.0,8.0,4.0,27.0,3.0,7.0,17.0,2.0,2.0,2.0,2.0,3.0,5.0,40.0,27.0,16.0,2.0,7.0,16.0,3.0,17.0,1.0,4.0,18.0,15.0,7.0,5.0,2.0,3.0,1.0,5.0,8.0,7.0,23.0,8.0,8.0,9.0,17.0,1.0,8.0,22.0,52.0,9.0,15.0,17.0,1.0,0.0,8.0,42.0,1.0,2.0,6.0,5.0,11.0,3.0,15.0,4.0,10.0,0.0,5.0,1.0,23.0,0.0,4.0,3.0,15.0,54.0,3.0,7.0,14.0,17.0,7.0,16.0,9.0,33.0,22.0,2.0,4.0,2.0,3.0,3.0,7.0,2.0,5.0,24.0,2.0,1.0,6.0,10.0,7.0,16.0,14.0,2.0,15.0,0.0,14.0,5.0,16.0,12.0,8.0,8.0,22.0,11.0,21.0,8.0,10.0,11.0,19.0,7.0,14.0,14.0,33.0,22.0,21.0,10.0,2.0,4.0,1.0,3.0,36.0,17.0,4.0,4.0,5.0,8.0,7.0,16.0,1.0,6.0,5.0,3.0,19.0,12.0,20.0,39.0,12.0,6.0,7.0,17.0,20.0,17.0,5.0,2.0,10.0,23.0,9.0,21.0,10.0,21.0,12.0,7.0,6.0,1.0,11.0,31.0,1.0,22.0,5.0],\"type\":\"box\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Artists box plot\"},\"width\":650},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4f654629-e61b-4f50-b527-f2e4e8ec2bc6');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "samples = np.array(torch.sum(A1,dim=1))\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Box(y=samples,boxpoints = 'all',\n",
        "                    fillcolor=\"blue\",jitter = 0.3,whiskerwidth = 0.1,boxmean = 'sd', marker_color = 'red',name = 'Artist distribution'))\n",
        "fig.update_layout(title_text = 'Artists box plot',width=650)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e080eafd",
      "metadata": {
        "id": "e080eafd"
      },
      "source": [
        "# GraphSAGE model\n",
        "\n",
        "- Once we also have the features for each instance, and the adjacency matrix of the graph, we can start to design the Graph Convolutional Layers, and the Fully Connected layers, as described in the paper.\n",
        "\n",
        "- Every feature vector has 2613 elements (low level features of the artists), our aim is to embed these vectors in a 100-dimensional space, where the distance between its points (Euclidean distance) represents a musical distance among the artists. (It is not clear however what each dimension stands for).\n",
        "The Graph Neural network attempts to learn this embedded space.\n",
        "\n",
        "- The GraphNN that the paper's authors decided to use is the GraphSAGE model (SAGE stands for Sample and AGgregatE).\n",
        "\n",
        "\n",
        "\n",
        "- This approach proposes a framework that generalizes the GCN to use trainable aggregation functions (beyond simple convolutions). ![Alt text](data:image/png;base64,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 \"GraphSAGE structure\")\n",
        "- This type of approach was introduced in the paper ['Inductive Representation Learning on Large Graphs'](https://arxiv.org/abs/1706.02216), that is also where it was taken the previous image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1121362",
      "metadata": {
        "id": "a1121362"
      },
      "outputs": [],
      "source": [
        "class GraphSAGE(nn.Module):\n",
        "    \n",
        "    def __init__(self,X,A,train_set,test_set,L,batch_size,device, training_mode = True):\n",
        "        \n",
        "        super(GraphSAGE,self).__init__()\n",
        "        self.device=device\n",
        "        self.A=A.to(self.device) #Tensors version of adjacency matrix and Instances\n",
        "        ## There are two types of adjacency matrix that could be useful ##\n",
        "        self.Atrain=self.select(self.A,train_set,train_set).to(self.device)\n",
        "        self.ATot=self.select(self.A,train_set+test_set,train_set+test_set).to(self.device)\n",
        "        \n",
        "        self.feat=100\n",
        "        self.X=torch.tensor(X.tolist(),requires_grad=True).to(self.device)   \n",
        "        self.COO=torch.load('COOA.pt') #This file contains the whole adjacency matrix in coordinate format (which is the torch geometric format)\n",
        "        self.train=train_set\n",
        "        self.test=test_set\n",
        "        self.L=L   #Number of layers\n",
        "        self.lamb=0.8  #Percentage used for the weighted distance to choose the hard positives and the hard negatives.\n",
        "        if training_mode:  #When we train we use this setting, otherwise is faster to set training_mode to false, in the case we want to carry out a forward on a batch of samples. \n",
        "          self.bs=batch_size\n",
        "          self.diz=self.getDiz()\n",
        "          self.mb=self.mini_batches(self.train+self.test,self.bs)\n",
        "          self.OrDiz=self.getCorrenspondancies(self.mb)\n",
        "        self.SG1=SAGEConv(2613,256,normalize=True,aggr=\"mean\")\n",
        "        self.SG2=SAGEConv(256,256,normalize=True,aggr=\"mean\")\n",
        "        self.SG3=SAGEConv(256,256,normalize=True,aggr=\"mean\")\n",
        "        \n",
        "        self.FC1=nn.Linear(256,256)\n",
        "        self.FC2=nn.Linear(256,256)\n",
        "        self.FC3=nn.Linear(256,self.feat)\n",
        "        self.FC4 = nn.Linear(256,256)\n",
        "        \n",
        "    def forward(self,V,b,nbs=-1,eval_mode = False):\n",
        "        Vdiz=self.tracing(V,b, eval_mode)\n",
        "        \n",
        "        # If these statements hold it means that we have already defined the mini batches for the training data, and we don't have to look for their \n",
        "        # neighbors everytime. Otherwise we get the neighbors for them.\n",
        "        if len(V)>500 and nbs!=-1:\n",
        "            OrDiz=self.OrDiz[nbs]\n",
        "        else:\n",
        "            OrDiz=self.getCorr(Vdiz) #Every sample/artist is normalized from 0 to 512(batch_size), in order to get easily the indices from the matrix A.\n",
        "            \n",
        "        for k in range(0,self.L):  #k reach maximum 2, the precise number depends on the number of layers that we decide to use for the GraphSAGE's models\n",
        "            \n",
        "\n",
        "            if k==0:\n",
        "                Es=self.select(self.X,set(),Vdiz[k+1]).T\n",
        "                Anew=self.select(self.A,Vdiz[k+1],Vdiz[k+1])\n",
        "                Anew=self.ConvertAtoCOO(Anew)\n",
        "                Es=self.SG1(Es,Anew).T\n",
        "                Es=F.elu(Es)\n",
        "    \n",
        "            if k==1:\n",
        "                Es=self.select(Es,set(),OrDiz[k+1].keys()).T\n",
        "                Anew=self.select(self.A,Vdiz[k+1],Vdiz[k+1])\n",
        "                Anew=self.ConvertAtoCOO(Anew)\n",
        "                Es=self.SG2(Es,Anew).T\n",
        "                Es=F.elu(Es)\n",
        "                \n",
        "            \n",
        "            if k==2:\n",
        "                Es=self.select(Es,set(),OrDiz[k+1].keys()).T\n",
        "                Anew=self.select(self.A,Vdiz[k+1],Vdiz[k+1])\n",
        "                Anew=self.ConvertAtoCOO(Anew)\n",
        "                Es=self.SG3(Es,Anew).T\n",
        "                Es=F.elu(Es)\n",
        "                \n",
        "            \n",
        "            if k==self.L-1:\n",
        "                Es=self.select(Es,set(),OrDiz[k+2]).T\n",
        "            \n",
        "            \n",
        "        out=self.FC1(Es)\n",
        "        out=self.FC2(out)\n",
        "        out=self.FC3(out)\n",
        "        return out.T\n",
        "    \n",
        "    def getCorrenspondancies(self,mbb):  ## If we are training the normalization of the batch samples is done from the pre-computed mini-batches ##\n",
        "        OrDiz={}\n",
        "        num=int(len(self.train)/self.bs)+1\n",
        "        for j in range(len(mbb[:num])):\n",
        "          Vdiz=self.tracing(mbb[j],1)\n",
        "          OrDiz[j]={}\n",
        "          for k in Vdiz:\n",
        "              OrDiz[j][k]={}\n",
        "              OrDiz[j][k]={i: sorted(list(Vdiz[k]))[i] for i in range(len(Vdiz[k]))}\n",
        "          print(\"Processed {}-th mini-batch\".format(j+1))\n",
        "        return OrDiz\n",
        "    \n",
        "    def getCorr(self,Vdiz): \n",
        "        OrDiz={}\n",
        "        for k in Vdiz:\n",
        "            OrDiz[k]={}\n",
        "            OrDiz[k]={i: sorted(list(Vdiz[k]))[i] for i in range(len(Vdiz[k]))}\n",
        "        return OrDiz\n",
        "            \n",
        "            \n",
        "    \n",
        "    def tracing(self,V,b,eval_mode = False):  # To perform the FFW in the Graph Networks we need to trace the neighbors for each samples. \n",
        "        Vdiz={}                               # This is done through this method and with the 'get_n' method\n",
        "        K=self.L+1\n",
        "        Vdiz[K]=sorted(list(V))\n",
        "        for k in range(K-1,0,-1):\n",
        "            d=set()\n",
        "            for idx in Vdiz[k+1]: \n",
        "                d=d.union(self.get_n(idx,b, eval_mode))\n",
        "                \n",
        "            Vdiz[k]=d\n",
        "        return Vdiz\n",
        "            \n",
        "    def get_n(self,idx,b, eval_mode): #This function is the neighbor's function. Given a batch index we get its neighborhood.\n",
        "        if b==1:\n",
        "            A=self.Atrain\n",
        "        else:\n",
        "            A=self.ATot\n",
        "        t=torch.nonzero(A[idx])\n",
        "        s=set()\n",
        "        \n",
        "        for k in t:\n",
        "            if t.shape[0]!=0 and eval_mode == False:\n",
        "              s.add(k.item())\n",
        "            \n",
        "            elif eval_mode == True:\n",
        "              if idx in self.test:\n",
        "                if k.item() not in self.test:\n",
        "                  s.add(k.item())\n",
        "              else:\n",
        "                s.add(k.item())\n",
        "            \n",
        "            else:\n",
        "              continue\n",
        "        s.add(idx)     \n",
        "        return s\n",
        "    \n",
        "    def select(self,mat,row,col):  #Given a set of indices for rows or column or both, we get the respective elements.\n",
        "        col=sorted(list(col))      #This is applied when we get the t matrix.\n",
        "       \n",
        "        c=0\n",
        "        if row==set():\n",
        "            col=torch.tensor(col,dtype=torch.int32).to(self.device)\n",
        "            ma=torch.index_select(mat.to(self.device),1,col)\n",
        "            return ma\n",
        "        else:\n",
        "            row=torch.tensor(sorted(list(row))).to(self.device)\n",
        "            col=torch.tensor(col).to(self.device)\n",
        "            ma=torch.index_select(mat,0,row)\n",
        "            ma=torch.index_select(ma,1,col)\n",
        "            return ma\n",
        "    \n",
        "   \n",
        "    def getDiz(self):   # This method is used to get the positives and negatives for each samples, and eventually it is helpful to track them inside the mini-batches,\n",
        "        diz={}          # thanks to the previously described methods.\n",
        "        for k in range(self.COO.shape[1]):\n",
        "            cn=int(self.COO[0][k].item())\n",
        "            # if cn>self.train[-1]:\n",
        "            #     break\n",
        "            \n",
        "            if cn not in diz:\n",
        "                diz[cn]=[[int(self.COO[1][k])]]\n",
        "                r=randrange(len(self.train))\n",
        "                while self.A[int(cn)][r]!=0:\n",
        "                    r=randrange(len(self.train))\n",
        "                diz[cn].append([r])\n",
        "            elif cn in diz:\n",
        "                diz[cn][0].append(int(self.COO[1][k]))\n",
        "                r=randrange(len(self.train))\n",
        "                while self.A[int(cn)][r]!=0:\n",
        "                    r=randrange(len(self.train))\n",
        "                diz[cn][1].append(r)\n",
        "                \n",
        "        return diz\n",
        "\n",
        "    def ConvertAtoCOO(self,SA): # This function easily converts the adjacency matrix format to the coordinate matrix format, which is the format used in torch-geometric.\n",
        "        Anew=torch.nonzero(SA).T.type(torch.LongTensor)\n",
        "        return Anew.to(self.device)\n",
        "\n",
        "    def getHardP_N(self,currentB,tensor): # This method returns for a given batch its respective positives and negatives.\n",
        "      samples=self.mbbPosNeg[currentB]\n",
        "      positives=torch.zeros((tensor.shape[0],tensor.shape[1]))\n",
        "      negatives=torch.zeros((tensor.shape[0],tensor.shape[1]))\n",
        "      mbbList=sorted(list(self.mb[currentB]))\n",
        "      for k in samples:\n",
        "        pos=samples[k][0]\n",
        "        neg=samples[k][1]\n",
        "        distDizP={kdist:((tensor[mbbList.index(k)]-tensor[mbbList.index(kdist)])**2).sum().item() for kdist in pos}\n",
        "        distDizN={kdist:((tensor[mbbList.index(k)]-tensor[mbbList.index(kdist)])**2).sum().item() for kdist in neg}\n",
        "        summP=sum(list(distDizP.values()))\n",
        "        summN=sum(list(distDizN.values()))\n",
        "        if len(distDizP)!=0 and summP!=0:\n",
        "          distDizP={kdist:distDizP[kdist]/summP for kdist in distDizP}\n",
        "        else:\n",
        "          distDizP[k]=0.5\n",
        "        if len(distDizN)!=0 and summN!=0:\n",
        "          distDizN={kdist:distDizN[kdist]/summN for kdist in distDizN}\n",
        "        else:\n",
        "          distDizN[k]=0.5\n",
        "        keysP=list(distDizP.keys())\n",
        "        keysN=list(distDizN.keys())\n",
        "        \n",
        "        for dist in keysP:\n",
        "          if distDizP[dist]>=self.lamb and len(distDizP)!=1:\n",
        "            distDizP.pop(dist)\n",
        "        \n",
        "        for dist in keysN:\n",
        "          if distDizN[dist]<= 1-self.lamb and len(distDizN)!=1:\n",
        "            distDizN.pop(dist)\n",
        "        \n",
        "        \n",
        "        positives[mbbList.index(k)]=tensor[mbbList.index(max(distDizP,key=distDizP.get))]\n",
        "        negatives[mbbList.index(k)]=tensor[mbbList.index(min(distDizN,key=distDizN.get))]\n",
        "      \n",
        "      return positives,negatives\n",
        "        \n",
        "        \n",
        "    \n",
        "    \n",
        "    def mini_batches(self,indices,bs=32): #This function generates a list of minibatches, of size bs\n",
        "        indexN=indices.copy()           #sets are unordered data structure, so there is no need to shuffle them. \n",
        "        indicesTot=[indexN[:len(self.train)],indexN[self.test[0]:]] #In this method we also take the possible positive and negative for each of the sample.\n",
        "        mbList=[]\n",
        "        self.mbbPosNeg={} \n",
        "        c=0   \n",
        "        num=int(len(self.train)/self.bs)+1     #Lists of lists of mini_batches indices \n",
        "        for indicesN in indicesTot:\n",
        "          u=0\n",
        "          if len(indicesN)==len(indexN[self.test[0]:]):\n",
        "            mb=set(indicesN)\n",
        "            mbList.append(mb)\n",
        "            self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "            update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "            self.mbbPosNeg[c].update(update)\n",
        "            return mbList\n",
        "          while len(indicesN)!=0:\n",
        "              mb=set()\n",
        "                                  #Inner list, with the indices of a particular mini_batch\n",
        "              while len(mb)<bs:\n",
        "                  if len(indicesN)==0:\n",
        "                      mbList.append(mb)\n",
        "                      self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "                      update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "                      self.mbbPosNeg[c].update(update)\n",
        "                      u=1\n",
        "                      c+=1\n",
        "                      break\n",
        "\n",
        "                  r=choice(indicesN)\n",
        "                  sample=indicesN.pop(indicesN.index(r))\n",
        "                  mb.add(sample)\n",
        "              if u!=1:\n",
        "                self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "                update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "                self.mbbPosNeg[c].update(update)\n",
        "                mbList.append(mb)\n",
        "                c+=1\n",
        "        return mbList          #obj.mini_batches(#,bs=128) #: train_,train,val,test, we get lists of list of batches from here\n",
        "    \n",
        "    \n",
        "    def getNegSample(self,key,mb): ## This method looks for the closest 4 negatives in a batch, for each samples in it.\n",
        "      l=[]\n",
        "      for j in mb:\n",
        "        if j!=key:\n",
        "          if key not in self.diz:\n",
        "            l.append(j)\n",
        "            if len(l)==4:\n",
        "              return l\n",
        "          else:\n",
        "            if j not in self.diz[key][0]:\n",
        "              l.append(j)\n",
        "              if len(l)==4:\n",
        "                return l  \n",
        "\n",
        "\n",
        "\n",
        "    def calcG(self,ID):  #This method is used for the evaluation of accuracy, in particular it computes the denominator\n",
        "        if ID>200:       # as described in the paper.\n",
        "            ID=200\n",
        "        c=1\n",
        "        somm=0\n",
        "        while c<=ID:\n",
        "            somm+=1/(math.log2(1+c))\n",
        "            c+=1\n",
        "        return somm\n",
        "\n",
        "    def evalAcc(self,S,kneigh,b):  #This function is to compute accuracy for the test and train set. \n",
        "        S = sorted(S)\n",
        "        S1 = sorted(self.train + S)\n",
        "        \n",
        "        T = self.forward(S1,b, nbs = -1, eval_mode = True)\n",
        "\n",
        "        test_embs = self.select(T,set(),S).to(torch.device('cpu')).detach().T.numpy()\n",
        "        T=T.detach().to(torch.device(\"cpu\")).numpy().transpose()\n",
        "        \n",
        "        neigh=NearestNeighbors(n_neighbors=(kneigh+1),algorithm='ball_tree').fit(test_embs) #With the K-NN we get the nearest \n",
        "        \n",
        "        dist,ind=neigh.kneighbors(test_embs)   \n",
        "        \n",
        "        acc=[]\n",
        "        A_acc=self.select(self.A,S,S)\n",
        "\n",
        "        c=0\n",
        "        for k in S:\n",
        "            summ=0\n",
        "            \n",
        "            ideal = A_acc[ind[c][0]].sum().item()\n",
        "            \n",
        "            \n",
        "            \n",
        "            den=self.calcG(ideal)\n",
        "            if den==0:\n",
        "                c+=1\n",
        "                continue  \n",
        "            for j in range(len(ind[c][1:])):\n",
        "                if A_acc[ind[c][0]][ind[c][1:][j]].item()!=0:\n",
        "                    summ+= 1/(math.log2(1+(j+1)))\n",
        "                    \n",
        "                else:\n",
        "                    continue\n",
        "            c+=1    \n",
        "            summ/=den\n",
        "            acc.append(summ)\n",
        "        return acc\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zgzkf8087Heo",
      "metadata": {
        "id": "zgzkf8087Heo"
      },
      "source": [
        "## Utilities\n",
        "* In the next cell are defined specific functions for our task.\n",
        "* 'TrainingPipeLine' is simply the pipeline of our training, and it comprises also the computation of the Normalized Discounted Cumulative Gain (nDCG).\n",
        "*There are also functions that are used laterly the notebook, such as 'Save_Model', 'Load_Model', 'plot_arrays', 'plot_metrics', 'get_accuracy', 'get_embeddings', 'get_nearest_artists'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e580b5e",
      "metadata": {
        "id": "5e580b5e",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "def TrainingPipeLine(model, optimizer, scheduler,loss, training, testing, num_epochs,KNN):\n",
        "    start=time.time()\n",
        "    bt=1 # Considers only the training samples from the adjacency matrix.\n",
        "    btot=2 # Considers either the training and either the testing samples from the asjacency matrix.\n",
        "    history_lossTr={}\n",
        "    history_lossTe={}\n",
        "    history_accuracy={}\n",
        "    mbb=model.mb\n",
        "    for epoch in range(num_epochs):\n",
        "        print(\"Processing epoch n°\",epoch+1)\n",
        "        num=int(len(training)/batch_size)+1\n",
        "        startEP=time.time()\n",
        "        history_lossTr[epoch+1]=[]\n",
        "        for k in range(len(mbb[:num])):\n",
        "            \n",
        "            print(\"Processing {}-th epoch: {}/{} mini-batch\".format(epoch+1,k+1,num))\n",
        "          \n",
        "\n",
        "            Ex=model(mbb[k],bt,nbs=k)\n",
        "            anchors=Ex.T\n",
        "            currentB=k\n",
        "            positives,negatives=model.getHardP_N(currentB,anchors)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            lossTr=loss(anchors,positives.detach().to(device),negatives.detach().to(device))\n",
        "            lossTr.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            history_lossTr[epoch+1].append(lossTr.item())\n",
        "        \n",
        "        \n",
        "        with torch.no_grad():\n",
        "            history_lossTe[epoch+1]=[]\n",
        "            for k in range(num,num+len(mbb[num:])):\n",
        "                Ex=model(mbb[k],btot)\n",
        "                anchors=Ex.T\n",
        "                currentB=k\n",
        "                positives,negatives=model.getHardP_N(currentB,anchors)\n",
        "\n",
        "                lossTe=loss(anchors,positives.detach().to(device),negatives.detach().to(device))\n",
        "                history_lossTe[epoch+1]=lossTe.item()\n",
        "                \n",
        "\n",
        "            history_lossTr[epoch+1]=sum(history_lossTr[epoch+1])/len(history_lossTr[epoch+1])\n",
        "\n",
        "            print(\"Evaluating the epoch n°\",epoch+1)\n",
        "            #accTr=model.evalAcc(training,KNN,bt)\n",
        "            accTe=model.evalAcc(testing,KNN,btot)\n",
        "            #TrainAcc=np.mean(np.array(accTr))\n",
        "            TestAcc=np.mean(np.array(accTe))\n",
        "            history_accuracy[epoch+1]=TestAcc\n",
        "            print(\"Processesed epoch n° {},\\tTest accuracy: {:.4f}\\tTest Loss: {:.4f}\\tTrain Loss: {:.8f}\\t\".format((epoch+1),TestAcc,history_lossTe[epoch+1],history_lossTr[epoch+1]))\n",
        "            endEP=time.time()\n",
        "            scheduler.step()\n",
        "            print(\"Requested time for processing {}-th epoch was: {:.4f} secs.\".format(epoch+1,endEP-startEP))\n",
        "    return model, optimizer, history_lossTr, history_accuracy, history_lossTe\n",
        "\n",
        "def Save_Model(path,model, optimizer, history_lossTr, history_accuracy, history_lossTe):\n",
        "    num_epochs=max(list(history_lossTr.keys()))\n",
        "    checkpoint={\n",
        "        \"epoch\":num_epochs,\n",
        "        \"modelState\":model.state_dict(),\n",
        "        \"optimizerState\":optimizer.state_dict(),\n",
        "        \"Loss_trainHistory\":history_lossTr,\n",
        "        \"Accuracy_History\":history_accuracy,\n",
        "        \"Loss_testHistory\":history_lossTe\n",
        "    }\n",
        "    torch.save(checkpoint,path)\n",
        "    \n",
        "def Load_Model(path, device):\n",
        "    model_checkpoint=torch.load(path, map_location = device)\n",
        "    return model_checkpoint\n",
        "\n",
        "## For all the plots was used the plotly library, because it makes really easy to interact with the most famous data visualization tools. ##\n",
        "def plot_arrays(metrics, conf_name, loss = True):\n",
        "    num_epochs=len(metrics[0])\n",
        "    fig1 = go.Figure()\n",
        "    if loss:\n",
        "      text = ['Loss on the TrainSet', 'Loss on the TestSet','TrainSet Loss VS. TestSet Loss in '+ conf_name,\"Loss\"]\n",
        "\n",
        "    \n",
        "\n",
        "      \n",
        "\n",
        "      fig1.add_trace(go.Scatter(x=np.array(range(num_epochs)), y=np.array(metrics[0]),\n",
        "                  mode='lines+markers',\n",
        "                  name=text[0], line=dict(color=\"navy\", width=4))) \n",
        "    if loss == False:\n",
        "      text = [\"acc\",\"Accuracy on TestSet\", \"Accuracy on TestSet in \"+ conf_name, \"Accuracy\"]\n",
        "    \n",
        "    fig1.add_trace(go.Scatter(x=np.array(range(num_epochs)), y= np.array(metrics[1]) if loss else np.array(metrics[0]),\n",
        "                        mode='lines+markers',\n",
        "                        name=text[1],line=dict(color=\"firebrick\", width=4)))\n",
        "    \n",
        "    fig1.update_layout(title=text[2],\n",
        "                xaxis_title='epochs',\n",
        "                yaxis_title=text[3])\n",
        "    \n",
        "\n",
        "    fig1.show()\n",
        "\n",
        "def plot_metrics(train_diz,test_diz, conf_name, loss = True):\n",
        "  if loss:\n",
        "    metrics = [[train_diz[key] for key in list(sorted(train_diz.keys()))],[test_diz[key] for key in list(sorted(test_diz.keys()))]]\n",
        "  else:\n",
        "    metrics = [[test_diz[key] for key in list(sorted(test_diz.keys()))]]\n",
        "  plot_arrays(metrics, conf_name, loss)\n",
        "\n",
        "def get_accuracy(model_name, device, instance, model_path = None, n_layers = False):\n",
        "  models = [\"SAGE1\",\"SAGE2\", \"SAGE3\",\"conf1\",\"conf2\",\"conf3\",\"conf4\"]\n",
        "  arch_paths = [\"models/one_layerSAGE.pt\", \"models/two_layerSAGE.pt\", \"models/three_layerSAGE.pt\", \"models/conf1.pt\", \"models/conf2.pt\", \"models/conf3.pt\", \"models/conf4.pt\"]\n",
        "  btot = 2\n",
        "  K = 200\n",
        "  training=list(range(0,10189+1))\n",
        "  testing=list(range(10190,11260+1))\n",
        "  if model_name not in models:\n",
        "    print(\"the model name inserted is not valid, choose one among these choices: \",models)\n",
        "    return\n",
        "  if n_layers != False:\n",
        "    if model_path!= None:\n",
        "      patt = model_path\n",
        "    else:\n",
        "      patt = arch_paths[n_layers-1]\n",
        "    model = GraphSAGE(instance,A1,training,testing,n_layers,512, device, training_mode = False).to(torch.device(device))\n",
        "    model_check = Load_Model(patt, device)\n",
        "    model.load_state_dict(model_check['modelState'])\n",
        "\n",
        "    accuracy = model.evalAcc(testing,K,btot)\n",
        "\n",
        "    accuracy = np.mean(np.array(accuracy))\n",
        "    \n",
        "\n",
        "    return accuracy\n",
        "  \n",
        "  else:\n",
        "    if model_path!= None:\n",
        "      patt = model_path\n",
        "    else:\n",
        "      patt = arch_paths[models.index(model_name)]\n",
        "    if model_name == \"conf1\":\n",
        "      model = Conf1(instance,A1,training,testing,512,device, training_mode = False).to(torch.device(device))\n",
        "      model_check = Load_Model(patt, device)\n",
        "      model.load_state_dict(model_check['modelState'])\n",
        "      accuracy = model.evalAcc(testing,200,btot)\n",
        "      accuracy = np.mean(np.array(accuracy))\n",
        "      \n",
        "      return accuracy\n",
        "      \n",
        "    elif model_name == \"conf2\":\n",
        "      model = Conf2(instance,A1,training,testing,512,device, training_mode = False).to(torch.device(device))\n",
        "      model_check = Load_Model(patt, device)\n",
        "      model.load_state_dict(model_check['modelState'])\n",
        "      accuracy = model.evalAcc(testing,K,btot)\n",
        "\n",
        "      accuracy = np.mean(np.array(accuracy))\n",
        "    \n",
        "\n",
        "      return accuracy\n",
        "\n",
        "    elif model_name == \"conf3\":\n",
        "      model = Conf3(instance,A1,training,testing,512,device, training_mode = False).to(torch.device(device))\n",
        "      model_check = Load_Model(patt, device)\n",
        "      model.load_state_dict(model_check['modelState'])\n",
        "      accuracy = model.evalAcc(testing,K,btot)\n",
        "\n",
        "      accuracy = np.mean(np.array(accuracy))\n",
        "      \n",
        "\n",
        "      return accuracy\n",
        "\n",
        "    elif model_name == \"conf4\":\n",
        "\n",
        "      model = Conf4(instance,A1,training,testing,512,device, training_mode = False).to(torch.device(device))\n",
        "      model_check = Load_Model(patt, device)\n",
        "      model.load_state_dict(model_check['modelState'])\n",
        "      accuracy = model.evalAcc(testing,K,btot)\n",
        "\n",
        "      accuracy = np.mean(np.array(accuracy))\n",
        "      \n",
        "\n",
        "      return accuracy\n",
        "\n",
        "def get_nearest_artists(embedding, artist_name, K, artist_to_id, id_to_artist):\n",
        "  Knew = K+50\n",
        "  T=embedding.detach().to(torch.device(\"cpu\")).numpy().transpose()\n",
        "  neigh=NearestNeighbors(n_neighbors=Knew,algorithm='kd_tree').fit(T)#With the K-NN we get the nearest \n",
        "  dist,ind = neigh.kneighbors(T[int(artist_to_id[artist_name])].reshape((1,-1))) \n",
        "  \n",
        "  artist_id = artist_to_id[artist_name]\n",
        "\n",
        "  neighbors_list = list(ind[0])[1:]\n",
        "  dist_list = list(dist[0])[1:]\n",
        "  neighbors_ = []\n",
        "  c = 1\n",
        "  while len(neighbors_)<K:\n",
        "    if id_to_artist[str(neighbors_list[c])]!=None:\n",
        "      neighbors_.append((id_to_artist[str(neighbors_list[c])],round(dist_list[c],4)))\n",
        "      c+=1\n",
        "    else:\n",
        "      c+=1\n",
        "\n",
        "  #neighbors_list = [id_to_artist[str(artist)] for artist in neighbors_list if str(artist) in id_to_artist]\n",
        "  \n",
        "  return neighbors_\n",
        "\n",
        "def get_embeddings(model_name,instance, device, model_path = None, n_layers = False):\n",
        "  models = [\"SAGE1\",\"SAGE2\", \"SAGE3\",\"conf1\",\"conf2\",\"conf3\",\"conf4\"]\n",
        "  arch_paths = [\"models/one_layerSAGE.pt\", \"models/two_layerSAGE.pt\", \"models/three_layerSAGE.pt\", \"models/conf1.pt\", \"models/conf2.pt\", \"models/conf3.pt\", \"models/conf4.pt\"]\n",
        "  btot = 2\n",
        "  training=list(range(0,10189+1))\n",
        "  testing=list(range(10190,11260+1))\n",
        "  if model_name not in models:\n",
        "    print(\"the model name inserted is not valid, choose one among these choices: \",models)\n",
        "    return\n",
        "  if n_layers != False:\n",
        "    if model_path!= None:\n",
        "      patt = model_path\n",
        "    else:\n",
        "      patt = arch_paths[n_layers-1]\n",
        "    model = GraphSAGE(instance,A1,training,testing,n_layers,512, device, training_mode = False).to(torch.device(device))\n",
        "    model_check = Load_Model(patt, device)\n",
        "    model.load_state_dict(model_check['modelState'])\n",
        "    embeddings = model(training+testing, btot)\n",
        "\n",
        "    \n",
        "\n",
        "    return embeddings\n",
        "  \n",
        "  else:\n",
        "    if model_path!= None:\n",
        "      patt = model_path\n",
        "    else:\n",
        "      patt = arch_paths[models.index(model_name)]\n",
        "    if model_name == \"conf1\":\n",
        "      model = Conf1(instance,A1,training,testing,512,device, training_mode = False).to(torch.device(device))\n",
        "      model_check = Load_Model(patt, device)\n",
        "      model.load_state_dict(model_check['modelState'])\n",
        "      embeddings = model(training+testing, btot)\n",
        "      return embeddings\n",
        "      \n",
        "    elif model_name == \"conf2\":\n",
        "      model = Conf2(instance,A1,training,testing,512,device, training_mode = False).to(torch.device(device))\n",
        "      model_check = Load_Model(patt, device)\n",
        "      model.load_state_dict(model_check['modelState'])\n",
        "      embeddings = model(training+testing, btot)\n",
        "      return embeddings\n",
        "\n",
        "    elif model_name == \"conf3\":\n",
        "      model = Conf3(instance,A1,training,testing,512,device, training_mode = False).to(torch.device(device))\n",
        "      model_check = Load_Model(patt, device)\n",
        "      model.load_state_dict(model_check['modelState'])\n",
        "      embeddings = model(training+testing, btot)\n",
        "      return embeddings\n",
        "\n",
        "    elif model_name == \"conf4\":\n",
        "      model = Conf4(instance,A1,training,testing,512,device, training_mode = False).to(torch.device(device))\n",
        "      model_check = Load_Model(patt, device)\n",
        "      model.load_state_dict(model_check['modelState'])\n",
        "      embeddings = model(training+testing, btot)\n",
        "      return embeddings\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4789afc0",
      "metadata": {
        "id": "4789afc0"
      },
      "source": [
        "## First Configuration #1\n",
        "\n",
        "- Through torch_geometric we have to use the Coordinate format (COO), to represent the graph data structure.\n",
        "- Thus, in the class definition for the first configuration requested we have to convert our Adjacency matrix in a COO format.\n",
        "\n",
        "- Network design requested:\n",
        "\n",
        "1. Linear(Input, 256) \n",
        "2. Linear(256, 256)\n",
        "3. GCNConv(256, 256)\n",
        "4. GCNConv(256, 256)\n",
        "5. TripletLoss()\n",
        "\n",
        "* GCNConv is an architecture that was presented in the paper ['Semi-Supervised Classification with Graph Convolutional Networks'](https://arxiv.org/abs/1609.02907), that is a way to encode in a latent representation the Graph's nodes, as in the case of GraphSAGE.  \n",
        "In the end of the notebook the performances over all the architectures are compared."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f779093d",
      "metadata": {
        "id": "f779093d"
      },
      "outputs": [],
      "source": [
        "## All the methods for this class are the same as in the GraphSAGE class, the only changes are about the forward method and the constructor. ##  \n",
        "\n",
        "class Conf1(nn.Module): ## lr=0.0001 weigth_decay=0.01\n",
        "    \n",
        "    def __init__(self,X,A,train_set,test_set,batch_size,device, training_mode = True):\n",
        "        super(Conf1,self).__init__()\n",
        "        self.device=device\n",
        "        self.A=A.to(self.device) #Tensors version of adjacency matrix and Instances\n",
        "        self.Atrain=self.select(self.A,train_set,train_set).to(self.device)\n",
        "        self.ATot=self.select(self.A,train_set+test_set,train_set+test_set).to(self.device)\n",
        "        self.L=2\n",
        "        self.X=torch.tensor(X.tolist(),requires_grad=True).to(self.device)   \n",
        "        self.COO=torch.load('COOA.pt')\n",
        "        self.train=train_set\n",
        "        self.test=test_set\n",
        "        self.lamb=0.8\n",
        "        if training_mode:\n",
        "          self.diz=self.getDiz()\n",
        "          self.bs=batch_size\n",
        "          self.mb=self.mini_batches(self.train+self.test,self.bs)\n",
        "          self.OrDiz=self.getCorrenspondancies(self.mb)\n",
        "        self.out=256\n",
        "        self.l1=nn.Linear(2613,self.out)\n",
        "        self.l2=nn.Linear(self.out,self.out)\n",
        "        self.GCN1=GCNConv(self.out,self.out)\n",
        "        self.GCN2=GCNConv(self.out,self.out)\n",
        "        \n",
        "        self.COO=torch.load('COOA.pt')\n",
        "        \n",
        "    \n",
        "    def forward(self,V,b,nbs=-1,eval_mode = False):\n",
        "        Vdiz=self.tracing(V,b, eval_mode)\n",
        "        \n",
        "        if len(V)>500 and nbs!=-1:\n",
        "            OrDiz=self.OrDiz[nbs]\n",
        "        else:\n",
        "            OrDiz=self.getCorr(Vdiz)\n",
        "        \n",
        "        ## Fully Connected layers ##\n",
        "        Es=self.select(self.X,set(),Vdiz[1]).T\n",
        "        Es=F.elu(self.l1(Es))\n",
        "        Es=F.elu(self.l2(Es))\n",
        "        \n",
        "        ## First Layer ##\n",
        "        Anew=self.select(self.A,Vdiz[1],Vdiz[1])\n",
        "        Anew=self.ConvertAtoCOO(Anew)\n",
        "        Es=self.GCN1(Es,Anew).T\n",
        "        Es=F.elu(Es)\n",
        "        \n",
        "        ## Second Layer ##\n",
        "        Es=self.select(Es,set(),OrDiz[2].keys()).T\n",
        "        Anew=self.select(self.A,Vdiz[2],Vdiz[2])\n",
        "        Anew=self.ConvertAtoCOO(Anew)\n",
        "        Es=self.GCN2(Es,Anew).T\n",
        "        Es=F.elu(Es)\n",
        "        Es=self.select(Es,set(),OrDiz[3])\n",
        "        \n",
        "        return Es\n",
        "    \n",
        "    def getCorrenspondancies(self,mbb):\n",
        "        OrDiz={}\n",
        "        num=int(len(self.train)/self.bs)+1\n",
        "        for j in range(len(mbb[:num])):\n",
        "          Vdiz=self.tracing(mbb[j],1)\n",
        "          OrDiz[j]={}\n",
        "          for k in Vdiz:\n",
        "              OrDiz[j][k]={}\n",
        "              OrDiz[j][k]={i: sorted(list(Vdiz[k]))[i] for i in range(len(Vdiz[k]))}\n",
        "          print(\"Processed {}-th mini-batch\".format(j+1))\n",
        "        return OrDiz\n",
        "    \n",
        "    def getCorr(self,Vdiz):\n",
        "        OrDiz={}\n",
        "        for k in Vdiz:\n",
        "            OrDiz[k]={}\n",
        "            OrDiz[k]={i: sorted(list(Vdiz[k]))[i] for i in range(len(Vdiz[k]))}\n",
        "        return OrDiz\n",
        "            \n",
        "            \n",
        "    \n",
        "    def tracing(self,V,b,eval_mode = False):\n",
        "        Vdiz={}\n",
        "        K=self.L+1\n",
        "        Vdiz[K]=sorted(list(V))\n",
        "        for k in range(K-1,0,-1):\n",
        "            d=set()\n",
        "            for idx in Vdiz[k+1]: \n",
        "                d=d.union(self.get_n(idx,b, eval_mode))\n",
        "                \n",
        "            Vdiz[k]=d\n",
        "        return Vdiz\n",
        "            \n",
        "    def get_n(self,idx,b, eval_mode): #This function is the neighbor's function. Given a batch index we get its neighborhood.\n",
        "        if b==1:\n",
        "            A=self.Atrain\n",
        "        else:\n",
        "            A=self.ATot\n",
        "        t=torch.nonzero(A[idx])\n",
        "        s=set()\n",
        "        \n",
        "        for k in t:\n",
        "            if t.shape[0]!=0 and eval_mode == False:\n",
        "              s.add(k.item())\n",
        "            \n",
        "            elif eval_mode == True:\n",
        "              if idx in self.test:  #If the target artist is in the test set, we need to add only those artist that are in the training set, not its test neighbors.\n",
        "                if k.item() not in self.test:\n",
        "                  s.add(k.item())\n",
        "              else:                 #If the target artist is in the train set, we accept all its neighbors\n",
        "                s.add(k.item())\n",
        "            \n",
        "            else:\n",
        "              continue\n",
        "        s.add(idx)     \n",
        "        return s\n",
        "    \n",
        "    def select(self,mat,row,col):  #Given a set of indices for rows or column or both, we get the respective elements.\n",
        "        col=sorted(list(col))      #This is applied when we get the t matrix.\n",
        "       \n",
        "        c=0\n",
        "        if row==set():\n",
        "            col=torch.tensor(col,dtype=torch.int32).to(self.device)\n",
        "            ma=torch.index_select(mat,1,col)\n",
        "            return ma\n",
        "        else:\n",
        "            row=torch.tensor(sorted(list(row))).to(self.device)\n",
        "            col=torch.tensor(col).to(self.device)\n",
        "            ma=torch.index_select(mat,0,row)\n",
        "            ma=torch.index_select(ma,1,col)\n",
        "            return ma\n",
        "    \n",
        "   \n",
        "    def getDiz(self):\n",
        "        diz={}\n",
        "        for k in range(self.COO.shape[1]):\n",
        "            cn=int(self.COO[0][k].item())\n",
        "            # if cn>self.train[-1]:\n",
        "            #     break\n",
        "            \n",
        "            if cn not in diz:\n",
        "                diz[cn]=[[int(self.COO[1][k])]]\n",
        "                r=randrange(len(self.train))\n",
        "                while self.A[int(cn)][r]!=0:\n",
        "                    r=randrange(len(self.train))\n",
        "                diz[cn].append([r])\n",
        "            elif cn in diz:\n",
        "                diz[cn][0].append(int(self.COO[1][k]))\n",
        "                r=randrange(len(self.train))\n",
        "                while self.A[int(cn)][r]!=0:\n",
        "                    r=randrange(len(self.train))\n",
        "                diz[cn][1].append(r)\n",
        "                \n",
        "        return diz\n",
        "    def ConvertAtoCOO(self,SA):\n",
        "        Anew=torch.nonzero(SA).T.type(torch.LongTensor)\n",
        "        return Anew.to(self.device)\n",
        "\n",
        "    def getHardP_N(self,currentB,tensor):\n",
        "      samples=self.mbbPosNeg[currentB]\n",
        "      positives=torch.zeros((tensor.shape[0],tensor.shape[1]))\n",
        "      negatives=torch.zeros((tensor.shape[0],tensor.shape[1]))\n",
        "      mbbList=sorted(list(self.mb[currentB]))\n",
        "      for k in samples:\n",
        "        pos=samples[k][0]\n",
        "        neg=samples[k][1]\n",
        "        distDizP={kdist:((tensor[mbbList.index(k)]-tensor[mbbList.index(kdist)])**2).sum().item() for kdist in pos}\n",
        "        distDizN={kdist:((tensor[mbbList.index(k)]-tensor[mbbList.index(kdist)])**2).sum().item() for kdist in neg}\n",
        "        summP=sum(list(distDizP.values()))\n",
        "        summN=sum(list(distDizN.values()))\n",
        "        if len(distDizP)!=0 and summP!=0:\n",
        "          distDizP={kdist:distDizP[kdist]/summP for kdist in distDizP}\n",
        "        else:\n",
        "          distDizP[k]=0.5\n",
        "        if len(distDizN)!=0 and summN!=0:\n",
        "          distDizN={kdist:distDizN[kdist]/summN for kdist in distDizN}\n",
        "        else:\n",
        "          distDizN[k]=0.5\n",
        "        keysP=list(distDizP.keys())\n",
        "        keysN=list(distDizN.keys())\n",
        "        \n",
        "        for dist in keysP:\n",
        "          if distDizP[dist]>=self.lamb and len(distDizP)!=1:\n",
        "            distDizP.pop(dist)\n",
        "        \n",
        "        for dist in keysN:\n",
        "          if distDizN[dist]<= 1-self.lamb and len(distDizN)!=1:\n",
        "            distDizN.pop(dist)\n",
        "        \n",
        "        \n",
        "        positives[mbbList.index(k)]=tensor[mbbList.index(max(distDizP,key=distDizP.get))]\n",
        "        negatives[mbbList.index(k)]=tensor[mbbList.index(min(distDizN,key=distDizN.get))]\n",
        "      \n",
        "      return positives,negatives\n",
        "        \n",
        "        \n",
        "    \n",
        "    \n",
        "    def mini_batches(self,indices,bs=32): #This function generates a list of minibatches, of size bs\n",
        "        indexN=indices.copy()           #sets are unordered data structure, so there is no need to shuffle them. \n",
        "        indicesTot=[indexN[:len(self.train)],indexN[self.test[0]:]]\n",
        "        mbList=[]\n",
        "        self.mbbPosNeg={} \n",
        "        c=0   \n",
        "        num=int(len(self.train)/self.bs)+1     #Lists of lists of mini_batches indices \n",
        "        for indicesN in indicesTot:\n",
        "          u=0\n",
        "          if len(indicesN)==len(indexN[self.test[0]:]):\n",
        "            mb=set(indicesN)\n",
        "            mbList.append(mb)\n",
        "            self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "            update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "            self.mbbPosNeg[c].update(update)\n",
        "            return mbList\n",
        "          while len(indicesN)!=0:\n",
        "              mb=set()\n",
        "                                  #Inner list, with the indices of a particular mini_batch\n",
        "              while len(mb)<bs:\n",
        "                  if len(indicesN)==0:\n",
        "                      mbList.append(mb)\n",
        "                      self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "                      update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "                      self.mbbPosNeg[c].update(update)\n",
        "                      u=1\n",
        "                      c+=1\n",
        "                      break\n",
        "\n",
        "                  r=choice(indicesN)\n",
        "                  sample=indicesN.pop(indicesN.index(r))\n",
        "                  mb.add(sample)\n",
        "              if u!=1:\n",
        "                self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "                update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "                self.mbbPosNeg[c].update(update)\n",
        "                mbList.append(mb)\n",
        "                c+=1\n",
        "        return mbList          #obj.mini_batches(#,bs=128) #: train_,train,val,test, we get lists of list of batches from here\n",
        "    \n",
        "    \n",
        "    def getNegSample(self,key,mb):\n",
        "      l=[]\n",
        "      for j in mb:\n",
        "        if j!=key:\n",
        "          if key not in self.diz:\n",
        "            l.append(j)\n",
        "            if len(l)==4:\n",
        "              return l\n",
        "          else:\n",
        "            if j not in self.diz[key][0]:\n",
        "              l.append(j)\n",
        "              if len(l)==4:\n",
        "                return l  \n",
        "\n",
        "\n",
        "\n",
        "    def calcG(self,ID):  #This method is used for the evaluation of accuracy, in particular it computes the denominator\n",
        "        if ID>200:       # as described in the paper.\n",
        "            ID=200\n",
        "        c=1\n",
        "        somm=0\n",
        "        while c<=ID:\n",
        "            somm+=1/(math.log2(1+c))\n",
        "            c+=1\n",
        "        return somm\n",
        "\n",
        "    def evalAcc(self,S,kneigh,b):  #This function is to compute accuracy for the test and train set. \n",
        "        S = sorted(S)\n",
        "        S1 = sorted(self.train + S)\n",
        "        \n",
        "        T = self.forward(S1,b, nbs = -1, eval_mode = True) # Embeddings are created either with the training and test artists\n",
        "\n",
        "        test_embs = self.select(T,set(),S).to(torch.device('cpu')).detach().T.numpy()\n",
        "        T=T.detach().to(torch.device(\"cpu\")).numpy().transpose()\n",
        "        \n",
        "        neigh=NearestNeighbors(n_neighbors=(kneigh+1),algorithm='ball_tree').fit(test_embs) #With the K-NN we get the nearest \n",
        "        \n",
        "        dist,ind=neigh.kneighbors(test_embs)   \n",
        "        \n",
        "        acc=[]\n",
        "        A_acc=self.select(self.A,S,S)\n",
        "\n",
        "        c=0\n",
        "        for k in S:\n",
        "            summ=0\n",
        "            # ideal=len([i for i in range(self.test[0],self.test[0]+A_acc[k,:].shape[0]) if A_acc[k,i]!=0]) \n",
        "            \n",
        "            ideal = A_acc[ind[c][0]].sum().item()\n",
        "            \n",
        "            \n",
        "            \n",
        "            den=self.calcG(ideal)\n",
        "            if den==0:\n",
        "                c+=1\n",
        "                continue  \n",
        "            for j in range(len(ind[c][1:])):\n",
        "                if A_acc[ind[c][0]][ind[c][1:][j]].item()!=0:\n",
        "                    summ+= 1/(math.log2(1+(j+1)))\n",
        "                    \n",
        "                else:\n",
        "                    continue\n",
        "            c+=1    \n",
        "            summ/=den\n",
        "            acc.append(summ)\n",
        "        return acc\n",
        "    \n",
        "    \n",
        "        \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a474560",
      "metadata": {
        "id": "4a474560"
      },
      "source": [
        "## Second Configuration #2\n",
        "\n",
        "- Through torch_geometric we have to use the Coordinate format (COO), to represent the graph data structure.\n",
        "- Thus, in the class definition for the first configuration requested we have to convert our Adjacency matrix in a COO format.\n",
        "\n",
        "- Network design requested:\n",
        "\n",
        "1. GCNConv(Input, 256)\n",
        "2. GraphConv(256, 256)\n",
        "3. GCNConv(256, 256)\n",
        "4. GCNConv(256, 256)\n",
        "5. Linear(256, 256) (**new**)\n",
        "6. Linear(256, 256) (**new**)\n",
        "7. TripletLoss()\n",
        "\n",
        "* This is the only architecture which implements 4 Graph Layers, the others reach at most 3 layers. Moreover in this architecture there is also one 'GraphConv' layer that is a kind of layer introduced in the paper ['Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks'](https://arxiv.org/abs/1810.02244).\n",
        "* At the beginning we tried this architecture without including the FCC layers, but we have noticed that the performances increased with their introduction. \n",
        "* Although this Network seems to be the most complex, it is not the best at performing the Artist Similarity task.\n",
        "\n",
        "* The 'GCNConv' layer is the same as in the first configuration. \n",
        "\n",
        "In the end of the notebook the performances over all the architectures are compared."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "143b8411",
      "metadata": {
        "id": "143b8411"
      },
      "outputs": [],
      "source": [
        "## All the methods for this class are the same as in the GraphSAGE class, the only changes are about the forward method and the constructor. ##  \n",
        "\n",
        "class Conf2(nn.Module): ## lr=0.00001 weigth_decay=0.01\n",
        "    \n",
        "    def __init__(self,X,A,train_set,test_set,batch_size,device, training_mode = True):\n",
        "        super(Conf2,self).__init__()\n",
        "        self.device=device\n",
        "        self.A=A.to(self.device) #Tensors version of adjacency matrix and Instances\n",
        "        self.Atrain=self.select(self.A,train_set,train_set).to(self.device)\n",
        "        self.ATot=self.select(self.A,train_set+test_set,train_set+test_set).to(self.device)\n",
        "        self.L=4\n",
        "        self.X=torch.tensor(X.tolist(),requires_grad=True).to(self.device)   \n",
        "        self.COO=torch.load('COOA.pt')\n",
        "        self.train=train_set\n",
        "        self.test=test_set\n",
        "        self.lamb=0.8\n",
        "        if training_mode:\n",
        "          self.diz=self.getDiz()\n",
        "          self.bs=batch_size\n",
        "          self.mb=self.mini_batches(self.train+self.test,self.bs)\n",
        "          self.OrDiz=self.getCorrenspondancies(self.mb)\n",
        "        self.n_input=2613\n",
        "        \n",
        "        self.out=256\n",
        "        self.GCN1=GCNConv(self.n_input,self.out)\n",
        "        self.Graph=GraphConv(self.out,self.out)\n",
        "        self.GCN2=GCNConv(self.out,self.out)\n",
        "        self.GCN3=GCNConv(self.out,self.out)\n",
        "        \n",
        "        self.l1 = nn.Linear(self.out,self.out)\n",
        "        self.l2 = nn.Linear(self.out,self.out)\n",
        "    \n",
        "    def forward(self,V,b,nbs=-1,eval_mode = False):\n",
        "        Vdiz=self.tracing(V,b, eval_mode)\n",
        "        \n",
        "        if len(V)>500 and nbs!=-1:\n",
        "            OrDiz=self.OrDiz[nbs]\n",
        "        else:\n",
        "            OrDiz=self.getCorr(Vdiz)\n",
        "        \n",
        "        ### First Layer ####\n",
        "        Es=self.select(self.X,set(),Vdiz[1]).T\n",
        "        Anew=self.select(self.A,Vdiz[1],Vdiz[1])\n",
        "        Anew=self.ConvertAtoCOO(Anew)\n",
        "        Es=F.elu(self.GCN1(Es,Anew).T)\n",
        "        \n",
        "        ### Second Layer ###\n",
        "        Es=self.select(Es,set(),OrDiz[2].keys()).T\n",
        "        Anew=self.select(self.A,Vdiz[2],Vdiz[2])\n",
        "        Anew=self.ConvertAtoCOO(Anew)\n",
        "        Es=F.elu(self.Graph(Es,Anew).T)\n",
        "        \n",
        "        ### Third Layer ###\n",
        "        Es=self.select(Es,set(),OrDiz[3].keys()).T\n",
        "        Anew=self.select(self.A,Vdiz[3],Vdiz[3])\n",
        "        Anew=self.ConvertAtoCOO(Anew)\n",
        "        Es=F.elu(self.GCN2(Es,Anew).T)\n",
        "        \n",
        "        ### Fourth Layer ###\n",
        "        Es=self.select(Es,set(),OrDiz[4].keys()).T\n",
        "        Anew=self.select(self.A,Vdiz[4],Vdiz[4])\n",
        "        Anew=self.ConvertAtoCOO(Anew)\n",
        "        Es=F.elu(self.GCN3(Es,Anew).T)\n",
        "        \n",
        "        Es=self.select(Es,set(),OrDiz[5].keys())\n",
        "        \n",
        "        Es=F.elu(self.l1(Es.T))\n",
        "        Es=F.elu(self.l2(Es))\n",
        "\n",
        "\n",
        "        return Es.T\n",
        "        \n",
        "          \n",
        "        \n",
        "               \n",
        "          \n",
        "        \n",
        "            \n",
        "            \n",
        "    def getCorrenspondancies(self,mbb):\n",
        "        OrDiz={}\n",
        "        num=int(len(self.train)/self.bs)+1\n",
        "        for j in range(len(mbb[:num])):\n",
        "          Vdiz=self.tracing(mbb[j],1)\n",
        "          OrDiz[j]={}\n",
        "          for k in Vdiz:\n",
        "              OrDiz[j][k]={}\n",
        "              OrDiz[j][k]={i: sorted(list(Vdiz[k]))[i] for i in range(len(Vdiz[k]))}\n",
        "          print(\"Processed {}-th mini-batch\".format(j+1))\n",
        "        return OrDiz\n",
        "    \n",
        "    def getCorr(self,Vdiz):\n",
        "        OrDiz={}\n",
        "        for k in Vdiz:\n",
        "            OrDiz[k]={}\n",
        "            OrDiz[k]={i: sorted(list(Vdiz[k]))[i] for i in range(len(Vdiz[k]))}\n",
        "        return OrDiz\n",
        "            \n",
        "            \n",
        "    \n",
        "    def tracing(self,V,b,eval_mode = False):\n",
        "        Vdiz={}\n",
        "        K=self.L+1\n",
        "        Vdiz[K]=sorted(list(V))\n",
        "        for k in range(K-1,0,-1):\n",
        "            d=set()\n",
        "            for idx in Vdiz[k+1]: \n",
        "                d=d.union(self.get_n(idx,b, eval_mode))\n",
        "                \n",
        "            Vdiz[k]=d\n",
        "        return Vdiz\n",
        "            \n",
        "    def get_n(self,idx,b, eval_mode): #This function is the neighbor's function. Given a batch index we get its neighborhood.\n",
        "        if b==1:\n",
        "            A=self.Atrain\n",
        "        else:\n",
        "            A=self.ATot\n",
        "        t=torch.nonzero(A[idx])\n",
        "        s=set()\n",
        "        \n",
        "        for k in t:\n",
        "            if t.shape[0]!=0 and eval_mode == False:\n",
        "              s.add(k.item())\n",
        "            \n",
        "            elif eval_mode == True:\n",
        "              if idx in self.test:\n",
        "                if k.item() not in self.test:\n",
        "                  s.add(k.item())\n",
        "              else:\n",
        "                s.add(k.item())\n",
        "            \n",
        "            else:\n",
        "              continue\n",
        "        s.add(idx)     \n",
        "        return s\n",
        "    \n",
        "    def select(self,mat,row,col):  #Given a set of indices for rows or column or both, we get the respective elements.\n",
        "        col=sorted(list(col))      #This is applied when we get the t matrix.\n",
        "       \n",
        "        c=0\n",
        "        if row==set():\n",
        "            col=torch.tensor(col,dtype=torch.int32).to(self.device)\n",
        "            ma=torch.index_select(mat,1,col)\n",
        "            return ma\n",
        "        else:\n",
        "            row=torch.tensor(sorted(list(row))).to(self.device)\n",
        "            col=torch.tensor(col).to(self.device)\n",
        "            ma=torch.index_select(mat,0,row)\n",
        "            ma=torch.index_select(ma,1,col)\n",
        "            return ma\n",
        "    \n",
        "   \n",
        "    def getDiz(self):\n",
        "        diz={}\n",
        "        for k in range(self.COO.shape[1]):\n",
        "            cn=int(self.COO[0][k].item())\n",
        "            # if cn>self.train[-1]:\n",
        "            #     break\n",
        "            \n",
        "            if cn not in diz:\n",
        "                diz[cn]=[[int(self.COO[1][k])]]\n",
        "                r=randrange(len(self.train))\n",
        "                while self.A[int(cn)][r]!=0:\n",
        "                    r=randrange(len(self.train))\n",
        "                diz[cn].append([r])\n",
        "            elif cn in diz:\n",
        "                diz[cn][0].append(int(self.COO[1][k]))\n",
        "                r=randrange(len(self.train))\n",
        "                while self.A[int(cn)][r]!=0:\n",
        "                    r=randrange(len(self.train))\n",
        "                diz[cn][1].append(r)\n",
        "                \n",
        "        return diz\n",
        "    def ConvertAtoCOO(self,SA):\n",
        "        Anew=torch.nonzero(SA).T.type(torch.LongTensor)\n",
        "        return Anew.to(self.device)\n",
        "\n",
        "    def getHardP_N(self,currentB,tensor):\n",
        "      samples=self.mbbPosNeg[currentB]\n",
        "      positives=torch.zeros((tensor.shape[0],tensor.shape[1]))\n",
        "      negatives=torch.zeros((tensor.shape[0],tensor.shape[1]))\n",
        "      mbbList=sorted(list(self.mb[currentB]))\n",
        "      for k in samples:\n",
        "        pos=samples[k][0]\n",
        "        neg=samples[k][1]\n",
        "        distDizP={kdist:((tensor[mbbList.index(k)]-tensor[mbbList.index(kdist)])**2).sum().item() for kdist in pos}\n",
        "        distDizN={kdist:((tensor[mbbList.index(k)]-tensor[mbbList.index(kdist)])**2).sum().item() for kdist in neg}\n",
        "        summP=sum(list(distDizP.values()))\n",
        "        summN=sum(list(distDizN.values()))\n",
        "        if len(distDizP)!=0 and summP!=0:\n",
        "          distDizP={kdist:distDizP[kdist]/summP for kdist in distDizP}\n",
        "        else:\n",
        "          distDizP[k]=0.5\n",
        "        if len(distDizN)!=0 and summN!=0:\n",
        "          distDizN={kdist:distDizN[kdist]/summN for kdist in distDizN}\n",
        "        else:\n",
        "          distDizN[k]=0.5\n",
        "        keysP=list(distDizP.keys())\n",
        "        keysN=list(distDizN.keys())\n",
        "        \n",
        "        for dist in keysP:\n",
        "          if distDizP[dist]>=self.lamb and len(distDizP)!=1:\n",
        "            distDizP.pop(dist)\n",
        "        \n",
        "        for dist in keysN:\n",
        "          if distDizN[dist]<= 1-self.lamb and len(distDizN)!=1:\n",
        "            distDizN.pop(dist)\n",
        "        \n",
        "        \n",
        "        positives[mbbList.index(k)]=tensor[mbbList.index(max(distDizP,key=distDizP.get))]\n",
        "        negatives[mbbList.index(k)]=tensor[mbbList.index(min(distDizN,key=distDizN.get))]\n",
        "      \n",
        "      return positives,negatives\n",
        "        \n",
        "        \n",
        "    \n",
        "    \n",
        "    def mini_batches(self,indices,bs=32): #This function generates a list of minibatches, of size bs\n",
        "        indexN=indices.copy()           #sets are unordered data structure, so there is no need to shuffle them. \n",
        "        indicesTot=[indexN[:len(self.train)],indexN[self.test[0]:]]\n",
        "        mbList=[]\n",
        "        self.mbbPosNeg={} \n",
        "        c=0   \n",
        "        num=int(len(self.train)/self.bs)+1     #Lists of lists of mini_batches indices \n",
        "        for indicesN in indicesTot:\n",
        "          u=0\n",
        "          if len(indicesN)==len(indexN[self.test[0]:]):\n",
        "            mb=set(indicesN)\n",
        "            mbList.append(mb)\n",
        "            self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "            update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "            self.mbbPosNeg[c].update(update)\n",
        "            return mbList\n",
        "          while len(indicesN)!=0:\n",
        "              mb=set()\n",
        "                                  #Inner list, with the indices of a particular mini_batch\n",
        "              while len(mb)<bs:\n",
        "                  if len(indicesN)==0:\n",
        "                      mbList.append(mb)\n",
        "                      self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "                      update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "                      self.mbbPosNeg[c].update(update)\n",
        "                      u=1\n",
        "                      c+=1\n",
        "                      break\n",
        "\n",
        "                  r=choice(indicesN)\n",
        "                  sample=indicesN.pop(indicesN.index(r))\n",
        "                  mb.add(sample)\n",
        "              if u!=1:\n",
        "                self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "                update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "                self.mbbPosNeg[c].update(update)\n",
        "                mbList.append(mb)\n",
        "                c+=1\n",
        "        return mbList          #obj.mini_batches(#,bs=128) #: train_,train,val,test, we get lists of list of batches from here\n",
        "    \n",
        "    \n",
        "    def getNegSample(self,key,mb):\n",
        "      l=[]\n",
        "      for j in mb:\n",
        "        if j!=key:\n",
        "          if key not in self.diz:\n",
        "            l.append(j)\n",
        "            if len(l)==4:\n",
        "              return l\n",
        "          else:\n",
        "            if j not in self.diz[key][0]:\n",
        "              l.append(j)\n",
        "              if len(l)==4:\n",
        "                return l  \n",
        "\n",
        "\n",
        "\n",
        "    def calcG(self,ID):  #This method is used for the evaluation of accuracy, in particular it computes the denominator\n",
        "        if ID>200:       # as described in the paper.\n",
        "            ID=200\n",
        "        c=1\n",
        "        somm=0\n",
        "        while c<=ID:\n",
        "            somm+=1/(math.log2(1+c))\n",
        "            c+=1\n",
        "        return somm\n",
        "\n",
        "    def evalAcc(self,S,kneigh,b):  #This function is to compute accuracy for the test and train set. \n",
        "        S = sorted(S)\n",
        "        S1 = sorted(self.train + S)\n",
        "        \n",
        "        T = self.forward(S1,b, nbs = -1, eval_mode = True)\n",
        "\n",
        "        test_embs = self.select(T,set(),S).to(torch.device('cpu')).detach().T.numpy()\n",
        "        T=T.detach().to(torch.device(\"cpu\")).numpy().transpose()\n",
        "        \n",
        "        neigh=NearestNeighbors(n_neighbors=(kneigh+1),algorithm='ball_tree').fit(test_embs) #With the K-NN we get the nearest \n",
        "        \n",
        "        dist,ind=neigh.kneighbors(test_embs)   \n",
        "        \n",
        "        acc=[]\n",
        "        A_acc=self.select(self.A,S,S)\n",
        "\n",
        "        c=0\n",
        "        for k in S:\n",
        "            summ=0\n",
        "            # ideal=len([i for i in range(self.test[0],self.test[0]+A_acc[k,:].shape[0]) if A_acc[k,i]!=0]) \n",
        "            \n",
        "            ideal = A_acc[ind[c][0]].sum().item()\n",
        "            \n",
        "            \n",
        "            \n",
        "            den=self.calcG(ideal)\n",
        "            if den==0:\n",
        "                c+=1\n",
        "                continue  \n",
        "            for j in range(len(ind[c][1:])):\n",
        "                if A_acc[ind[c][0]][ind[c][1:][j]].item()!=0:\n",
        "                    summ+= 1/(math.log2(1+(j+1)))\n",
        "                    \n",
        "                else:\n",
        "                    continue\n",
        "            c+=1    \n",
        "            summ/=den\n",
        "            acc.append(summ)\n",
        "        return acc\n",
        "        \n",
        "        \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc8899a8",
      "metadata": {
        "id": "dc8899a8"
      },
      "source": [
        "## Third Configuration #3\n",
        "\n",
        "- Through torch_geometric we have to use the Coordinate format (COO), to represent the graph data structure.\n",
        "- Thus, in the class definition for the first configuration requested we have to convert our Adjacency matrix in a COO format.\n",
        "\n",
        "- Network design requested:\n",
        "\n",
        "1. Linear(Input, 256)\n",
        "2. Linear(256, 256)\n",
        "3. Linear(256, 256) (**new**)\n",
        "3. GATConv(256, 256)\n",
        "4. GATConv(256, 256)\n",
        "5. TripletLoss()\n",
        "\n",
        "* This configuration appears to be way better than the others, it is not easy to explain why this happens, but is amazing to see how it outperforms the other architectures, even though it has just 2 Graph layers.\n",
        "* Also in this case there were made some modifications in the architecture, indeed at the beginning there were just 2 FCC layers, but by introducing another layer we have slightly improved our perfomances on the task.\n",
        "* In this architecture the Graph layers are the ones described in [Graph Attention Networks](https://arxiv.org/abs/1710.10903).\n",
        "\n",
        "In the end of the notebook the performances over all the architectures are compared."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c6191ba",
      "metadata": {
        "id": "3c6191ba"
      },
      "outputs": [],
      "source": [
        "## All the methods for this class are the same as in the GraphSAGE class, the only changes are about the forward method and the constructor. ##  \n",
        "\n",
        "class Conf3(nn.Module):   ## lr=0.0001 weigth_decay=0.01\n",
        "    \n",
        "    def __init__(self,X,A,train_set,test_set,batch_size,device, training_mode = True):\n",
        "        super(Conf3,self).__init__()\n",
        "        self.device=device\n",
        "        self.A=A.to(self.device) #Tensors version of adjacency matrix and Instances\n",
        "        self.Atrain=self.select(self.A,train_set,train_set).to(self.device)\n",
        "        self.ATot=self.select(self.A,train_set+test_set,train_set+test_set).to(self.device)\n",
        "        self.L=2\n",
        "        self.X=torch.tensor(X.tolist(),requires_grad=True).to(self.device)   \n",
        "        self.COO=torch.load('COOA.pt')\n",
        "        self.train=train_set\n",
        "        self.test=test_set\n",
        "        self.lamb=0.8\n",
        "        if training_mode:\n",
        "          self.diz=self.getDiz()\n",
        "          self.bs=batch_size\n",
        "          self.mb=self.mini_batches(self.train+self.test,self.bs)\n",
        "          self.OrDiz=self.getCorrenspondancies(self.mb)\n",
        "          \n",
        "        self.n_input=2613\n",
        "        self.n_out=256\n",
        "        self.l1=nn.Linear(self.n_input,self.n_out)\n",
        "        self.l2=nn.Linear(self.n_out,self.n_out)\n",
        "        self.l3=nn.Linear(self.n_out,self.n_out)\n",
        "\n",
        "        self.GAT1=GATConv(self.n_out,self.n_out)\n",
        "        self.GAT2=GATConv(self.n_out,self.n_out)\n",
        "        \n",
        "    \n",
        "    \n",
        "    def forward(self,V,b,nbs=-1,eval_mode = False):\n",
        "        Vdiz=self.tracing(V,b, eval_mode)\n",
        "        \n",
        "        if len(V)>500 and nbs!=-1:\n",
        "            OrDiz=self.OrDiz[nbs]\n",
        "        else:\n",
        "            OrDiz=self.getCorr(Vdiz)\n",
        "        \n",
        "        ## Fully Connected layers ##\n",
        "        Es=self.select(self.X,set(),Vdiz[1]).T\n",
        "        Es=F.elu(self.l1(Es))\n",
        "        Es=F.elu(self.l2(Es))\n",
        "        Es=F.elu(self.l3(Es))\n",
        "\n",
        "        \n",
        "        ## First Layer ##\n",
        "        Anew=self.select(self.A,Vdiz[1],Vdiz[1])\n",
        "        Anew=self.ConvertAtoCOO(Anew)\n",
        "        Es=self.GAT1(Es,Anew).T\n",
        "        Es=F.elu(Es)\n",
        "        \n",
        "        ## Second Layer ##\n",
        "        Es=self.select(Es,set(),OrDiz[2].keys()).T\n",
        "        Anew=self.select(self.A,Vdiz[2],Vdiz[2])\n",
        "        Anew=self.ConvertAtoCOO(Anew)\n",
        "        Es=self.GAT2(Es,Anew).T\n",
        "        Es=F.elu(Es)\n",
        "        Es=self.select(Es,set(),OrDiz[3])\n",
        "        \n",
        "        return Es\n",
        "    \n",
        "    def getCorrenspondancies(self,mbb):\n",
        "        OrDiz={}\n",
        "        num=int(len(self.train)/self.bs)+1\n",
        "        for j in range(len(mbb[:num])):\n",
        "          Vdiz=self.tracing(mbb[j],1)\n",
        "          OrDiz[j]={}\n",
        "          for k in Vdiz:\n",
        "              OrDiz[j][k]={}\n",
        "              OrDiz[j][k]={i: sorted(list(Vdiz[k]))[i] for i in range(len(Vdiz[k]))}\n",
        "          print(\"Processed {}-th mini-batch\".format(j+1))\n",
        "        return OrDiz\n",
        "    \n",
        "    def getCorr(self,Vdiz):\n",
        "        OrDiz={}\n",
        "        for k in Vdiz:\n",
        "            OrDiz[k]={}\n",
        "            OrDiz[k]={i: sorted(list(Vdiz[k]))[i] for i in range(len(Vdiz[k]))}\n",
        "        return OrDiz\n",
        "            \n",
        "            \n",
        "    \n",
        "    def tracing(self,V,b,eval_mode = False):\n",
        "        Vdiz={}\n",
        "        K=self.L+1\n",
        "        Vdiz[K]=sorted(list(V))\n",
        "        for k in range(K-1,0,-1):\n",
        "            d=set()\n",
        "            for idx in Vdiz[k+1]: \n",
        "                d=d.union(self.get_n(idx,b, eval_mode))\n",
        "                \n",
        "            Vdiz[k]=d\n",
        "        return Vdiz\n",
        "            \n",
        "    def get_n(self,idx,b, eval_mode): #This function is the neighbor's function. Given a batch index we get its neighborhood.\n",
        "        if b==1:\n",
        "            A=self.Atrain\n",
        "        else:\n",
        "            A=self.ATot\n",
        "        t=torch.nonzero(A[idx])\n",
        "        s=set()\n",
        "        \n",
        "        for k in t:\n",
        "            if t.shape[0]!=0 and eval_mode == False:\n",
        "              s.add(k.item())\n",
        "            \n",
        "            elif eval_mode == True:\n",
        "              if idx in self.test:\n",
        "                if k.item() not in self.test:\n",
        "                  s.add(k.item())\n",
        "              else:\n",
        "                s.add(k.item())\n",
        "            \n",
        "            else:\n",
        "              continue\n",
        "        s.add(idx)     \n",
        "        return s\n",
        "    \n",
        "    def select(self,mat,row,col):  #Given a set of indices for rows or column or both, we get the respective elements.\n",
        "        col=sorted(list(col))      #This is applied when we get the t matrix.\n",
        "       \n",
        "        c=0\n",
        "        if row==set():\n",
        "            col=torch.tensor(col,dtype=torch.int32).to(self.device)\n",
        "            ma=torch.index_select(mat,1,col)\n",
        "            return ma\n",
        "        else:\n",
        "            row=torch.tensor(sorted(list(row))).to(self.device)\n",
        "            col=torch.tensor(col).to(self.device)\n",
        "            ma=torch.index_select(mat,0,row)\n",
        "            ma=torch.index_select(ma,1,col)\n",
        "            return ma\n",
        "    \n",
        "   \n",
        "    def getDiz(self):\n",
        "        diz={}\n",
        "        for k in range(self.COO.shape[1]):\n",
        "            cn=int(self.COO[0][k].item())\n",
        "            # if cn>self.train[-1]:\n",
        "            #     break\n",
        "            \n",
        "            if cn not in diz:\n",
        "                diz[cn]=[[int(self.COO[1][k])]]\n",
        "                r=randrange(len(self.train))\n",
        "                while self.A[int(cn)][r]!=0:\n",
        "                    r=randrange(len(self.train))\n",
        "                diz[cn].append([r])\n",
        "            elif cn in diz:\n",
        "                diz[cn][0].append(int(self.COO[1][k]))\n",
        "                r=randrange(len(self.train))\n",
        "                while self.A[int(cn)][r]!=0:\n",
        "                    r=randrange(len(self.train))\n",
        "                diz[cn][1].append(r)\n",
        "                \n",
        "        return diz\n",
        "    def ConvertAtoCOO(self,SA):\n",
        "        Anew=torch.nonzero(SA).T.type(torch.LongTensor)\n",
        "        return Anew.to(self.device)\n",
        "\n",
        "    def getHardP_N(self,currentB,tensor):\n",
        "      samples=self.mbbPosNeg[currentB]\n",
        "      positives=torch.zeros((tensor.shape[0],tensor.shape[1]))\n",
        "      negatives=torch.zeros((tensor.shape[0],tensor.shape[1]))\n",
        "      mbbList=sorted(list(self.mb[currentB]))\n",
        "      for k in samples:\n",
        "        pos=samples[k][0]\n",
        "        neg=samples[k][1]\n",
        "        distDizP={kdist:((tensor[mbbList.index(k)]-tensor[mbbList.index(kdist)])**2).sum().item() for kdist in pos}\n",
        "        distDizN={kdist:((tensor[mbbList.index(k)]-tensor[mbbList.index(kdist)])**2).sum().item() for kdist in neg}\n",
        "        summP=sum(list(distDizP.values()))\n",
        "        summN=sum(list(distDizN.values()))\n",
        "        if len(distDizP)!=0 and summP!=0:\n",
        "          distDizP={kdist:distDizP[kdist]/summP for kdist in distDizP}\n",
        "        else:\n",
        "          distDizP[k]=0.5\n",
        "        if len(distDizN)!=0 and summN!=0:\n",
        "          distDizN={kdist:distDizN[kdist]/summN for kdist in distDizN}\n",
        "        else:\n",
        "          distDizN[k]=0.5\n",
        "        keysP=list(distDizP.keys())\n",
        "        keysN=list(distDizN.keys())\n",
        "        \n",
        "        for dist in keysP:\n",
        "          if distDizP[dist]>=self.lamb and len(distDizP)!=1:\n",
        "            distDizP.pop(dist)\n",
        "        \n",
        "        for dist in keysN:\n",
        "          if distDizN[dist]<= 1-self.lamb and len(distDizN)!=1:\n",
        "            distDizN.pop(dist)\n",
        "        \n",
        "        \n",
        "        positives[mbbList.index(k)]=tensor[mbbList.index(max(distDizP,key=distDizP.get))]\n",
        "        negatives[mbbList.index(k)]=tensor[mbbList.index(min(distDizN,key=distDizN.get))]\n",
        "      \n",
        "      return positives,negatives\n",
        "        \n",
        "        \n",
        "    \n",
        "    \n",
        "    def mini_batches(self,indices,bs=32): #This function generates a list of minibatches, of size bs\n",
        "        indexN=indices.copy()           #sets are unordered data structure, so there is no need to shuffle them. \n",
        "        indicesTot=[indexN[:len(self.train)],indexN[self.test[0]:]]\n",
        "        mbList=[]\n",
        "        self.mbbPosNeg={} \n",
        "        c=0   \n",
        "        num=int(len(self.train)/self.bs)+1     #Lists of lists of mini_batches indices \n",
        "        for indicesN in indicesTot:\n",
        "          u=0\n",
        "          if len(indicesN)==len(indexN[self.test[0]:]):\n",
        "            mb=set(indicesN)\n",
        "            mbList.append(mb)\n",
        "            self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "            update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "            self.mbbPosNeg[c].update(update)\n",
        "            return mbList\n",
        "          while len(indicesN)!=0:\n",
        "              mb=set()\n",
        "                                  #Inner list, with the indices of a particular mini_batch\n",
        "              while len(mb)<bs:\n",
        "                  if len(indicesN)==0:\n",
        "                      mbList.append(mb)\n",
        "                      self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "                      update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "                      self.mbbPosNeg[c].update(update)\n",
        "                      u=1\n",
        "                      c+=1\n",
        "                      break\n",
        "\n",
        "                  r=choice(indicesN)\n",
        "                  sample=indicesN.pop(indicesN.index(r))\n",
        "                  mb.add(sample)\n",
        "              if u!=1:\n",
        "                self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "                update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "                self.mbbPosNeg[c].update(update)\n",
        "                mbList.append(mb)\n",
        "                c+=1\n",
        "        return mbList          #obj.mini_batches(#,bs=128) #: train_,train,val,test, we get lists of list of batches from here\n",
        "    \n",
        "    \n",
        "    def getNegSample(self,key,mb):\n",
        "      l=[]\n",
        "      for j in mb:\n",
        "        if j!=key:\n",
        "          if key not in self.diz:\n",
        "            l.append(j)\n",
        "            if len(l)==4:\n",
        "              return l\n",
        "          else:\n",
        "            if j not in self.diz[key][0]:\n",
        "              l.append(j)\n",
        "              if len(l)==4:\n",
        "                return l  \n",
        "\n",
        "\n",
        "\n",
        "    def calcG(self,ID):  #This method is used for the evaluation of accuracy, in particular it computes the denominator\n",
        "        if ID>200:       # as described in the paper.\n",
        "            ID=200\n",
        "        c=1\n",
        "        somm=0\n",
        "        while c<=ID:\n",
        "            somm+=1/(math.log2(1+c))\n",
        "            c+=1\n",
        "        return somm\n",
        "\n",
        "    def evalAcc(self,S,kneigh,b):  #This function is to compute accuracy for the test and train set. \n",
        "        S = sorted(S)\n",
        "        S1 = sorted(self.train + S)\n",
        "        \n",
        "        T = self.forward(S1,b, nbs = -1, eval_mode = True)\n",
        "\n",
        "        test_embs = self.select(T,set(),S).to(torch.device('cpu')).detach().T.numpy()\n",
        "        T=T.detach().to(torch.device(\"cpu\")).numpy().transpose()\n",
        "        \n",
        "        neigh=NearestNeighbors(n_neighbors=(kneigh+1),algorithm='ball_tree').fit(test_embs) #With the K-NN we get the nearest \n",
        "        \n",
        "        dist,ind=neigh.kneighbors(test_embs)   \n",
        "        \n",
        "        acc=[]\n",
        "        A_acc=self.select(self.A,S,S)\n",
        "\n",
        "        c=0\n",
        "        for k in S:\n",
        "            summ=0\n",
        "            # ideal=len([i for i in range(self.test[0],self.test[0]+A_acc[k,:].shape[0]) if A_acc[k,i]!=0]) \n",
        "            \n",
        "            ideal = A_acc[ind[c][0]].sum().item()\n",
        "            \n",
        "            \n",
        "            \n",
        "            den=self.calcG(ideal)\n",
        "            if den==0:\n",
        "                c+=1\n",
        "                continue  \n",
        "            for j in range(len(ind[c][1:])):\n",
        "                if A_acc[ind[c][0]][ind[c][1:][j]].item()!=0:\n",
        "                    summ+= 1/(math.log2(1+(j+1)))\n",
        "                    \n",
        "                else:\n",
        "                    continue\n",
        "            c+=1    \n",
        "            summ/=den\n",
        "            acc.append(summ)\n",
        "        return acc\n",
        "            \n",
        "      \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a31428c7",
      "metadata": {
        "id": "a31428c7"
      },
      "source": [
        "## Fourth Configuration ##\n",
        "\n",
        "- Through torch_geometric we have to use the Coordinate format (COO), to represent the graph data structure.\n",
        "- Thus, in the class definition for the first configuration requested we have to convert our Adjacency matrix in a COO format.\n",
        "\n",
        "- Network design requested:\n",
        "\n",
        "1. GATConv(Input, 256)\n",
        "2. GATConv(256, 256)\n",
        "3. Linear(256, 256)\n",
        "4. Linear(256, 256)\n",
        "5. TripletLoss()\n",
        "\n",
        "* Also with this 'GAT-based' architecture we obtain good results, indeed this is similar to the third configuration, but the FCC layers are localized right after the Graph layers, similarly to the GraphSAGE's architectures.\n",
        "\n",
        "In the end of the notebook the performances over all the architectures are compared."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd8e1414",
      "metadata": {
        "id": "bd8e1414"
      },
      "outputs": [],
      "source": [
        "## All the methods for this class are the same as in the GraphSAGE class, the only changes are about the forward method and the constructor. ##  \n",
        "\n",
        "class Conf4(nn.Module):  ## lr=0.00001 weigth_decay=0.01\n",
        "    \n",
        "    def __init__(self,X,A,train_set,test_set,batch_size,device, training_mode = True):\n",
        "        super(Conf4,self).__init__()\n",
        "        self.device=device\n",
        "        self.A=A.to(self.device) #Tensors version of adjacency matrix and Instances\n",
        "        self.Atrain=self.select(self.A,train_set,train_set).to(self.device)\n",
        "        self.ATot=self.select(self.A,train_set+test_set,train_set+test_set).to(self.device)\n",
        "        self.L=2\n",
        "        self.X=torch.tensor(X.tolist(),requires_grad=True).to(self.device)   \n",
        "        self.COO=torch.load('COOA.pt')\n",
        "        self.train=train_set\n",
        "        self.test=test_set\n",
        "        self.lamb=0.8\n",
        "        if training_mode:\n",
        "          self.diz=self.getDiz()\n",
        "          self.bs=batch_size\n",
        "          self.mb=self.mini_batches(self.train+self.test,self.bs)\n",
        "          self.OrDiz=self.getCorrenspondancies(self.mb)\n",
        "        \n",
        "        self.n_input=2613\n",
        "        self.n_out=256\n",
        "        self.l1=nn.Linear(self.n_out,self.n_out)\n",
        "        self.l2=nn.Linear(self.n_out,self.n_out)\n",
        "\n",
        "        self.GAT1=GATConv(self.n_input,self.n_out)\n",
        "        self.GAT2=GATConv(self.n_out,self.n_out)\n",
        "        \n",
        "    \n",
        "    \n",
        "    def forward(self,V,b,nbs=-1,eval_mode = False):\n",
        "        Vdiz=self.tracing(V,b, eval_mode)\n",
        "        \n",
        "        if len(V)>500 and nbs!=-1:\n",
        "            OrDiz=self.OrDiz[nbs]\n",
        "        else:\n",
        "            OrDiz=self.getCorr(Vdiz)\n",
        "        \n",
        "        ## First Layer ##\n",
        "        Es=self.select(self.X,set(),Vdiz[1]).T\n",
        "        Anew=self.select(self.A,Vdiz[1],Vdiz[1])\n",
        "        Anew=self.ConvertAtoCOO(Anew)\n",
        "        Es=self.GAT1(Es,Anew).T\n",
        "        Es=F.elu(Es)\n",
        "        ## Second Layer ##\n",
        "        Es=self.select(Es,set(),OrDiz[2].keys()).T\n",
        "        Anew=self.select(self.A,Vdiz[2],Vdiz[2])\n",
        "        Anew=self.ConvertAtoCOO(Anew)\n",
        "        Es=self.GAT2(Es,Anew)\n",
        "        Es=F.elu(Es).T\n",
        "        \n",
        "        Es=self.select(Es,set(),OrDiz[3]).T\n",
        "        ## Fully Connected layers ##\n",
        "        \n",
        "        Es=F.elu(self.l1(Es))\n",
        "        \n",
        "        Es=F.elu(self.l2(Es))\n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "        return Es.T\n",
        "    \n",
        "    def getCorrenspondancies(self,mbb):\n",
        "        OrDiz={}\n",
        "        num=int(len(self.train)/self.bs)+1\n",
        "        for j in range(len(mbb[:num])):\n",
        "          Vdiz=self.tracing(mbb[j],1)\n",
        "          OrDiz[j]={}\n",
        "          for k in Vdiz:\n",
        "              OrDiz[j][k]={}\n",
        "              OrDiz[j][k]={i: sorted(list(Vdiz[k]))[i] for i in range(len(Vdiz[k]))}\n",
        "          print(\"Processed {}-th mini-batch\".format(j+1))\n",
        "        return OrDiz\n",
        "    \n",
        "    def getCorr(self,Vdiz):\n",
        "        OrDiz={}\n",
        "        for k in Vdiz:\n",
        "            OrDiz[k]={}\n",
        "            OrDiz[k]={i: sorted(list(Vdiz[k]))[i] for i in range(len(Vdiz[k]))}\n",
        "        return OrDiz\n",
        "            \n",
        "            \n",
        "    \n",
        "    def tracing(self,V,b,eval_mode = False):\n",
        "        Vdiz={}\n",
        "        K=self.L+1\n",
        "        Vdiz[K]=sorted(list(V))\n",
        "        for k in range(K-1,0,-1):\n",
        "            d=set()\n",
        "            for idx in Vdiz[k+1]: \n",
        "                d=d.union(self.get_n(idx,b, eval_mode))\n",
        "                \n",
        "            Vdiz[k]=d\n",
        "        return Vdiz\n",
        "            \n",
        "    def get_n(self,idx,b, eval_mode): #This function is the neighbor's function. Given a batch index we get its neighborhood.\n",
        "        if b==1:\n",
        "            A=self.Atrain\n",
        "        else:\n",
        "            A=self.ATot\n",
        "        t=torch.nonzero(A[idx])\n",
        "        s=set()\n",
        "        \n",
        "        for k in t:\n",
        "            if t.shape[0]!=0 and eval_mode == False:\n",
        "              s.add(k.item())\n",
        "            \n",
        "            elif eval_mode == True:\n",
        "              if idx in self.test:\n",
        "                if k.item() not in self.test:\n",
        "                  s.add(k.item())\n",
        "              else:\n",
        "                s.add(k.item())\n",
        "            \n",
        "            else:\n",
        "              continue\n",
        "        s.add(idx)     \n",
        "        return s\n",
        "    \n",
        "    def select(self,mat,row,col):  #Given a set of indices for rows or column or both, we get the respective elements.\n",
        "        col=sorted(list(col))      #This is applied when we get the t matrix.\n",
        "       \n",
        "        c=0\n",
        "        if row==set():\n",
        "            col=torch.tensor(col,dtype=torch.int32).to(self.device)\n",
        "            ma=torch.index_select(mat,1,col)\n",
        "            return ma\n",
        "        else:\n",
        "            row=torch.tensor(sorted(list(row))).to(self.device)\n",
        "            col=torch.tensor(col).to(self.device)\n",
        "            ma=torch.index_select(mat,0,row)\n",
        "            ma=torch.index_select(ma,1,col)\n",
        "            return ma\n",
        "    \n",
        "   \n",
        "    def getDiz(self):\n",
        "        diz={}\n",
        "        for k in range(self.COO.shape[1]):\n",
        "            cn=int(self.COO[0][k].item())\n",
        "            # if cn>self.train[-1]:\n",
        "            #     break\n",
        "            \n",
        "            if cn not in diz:\n",
        "                diz[cn]=[[int(self.COO[1][k])]]\n",
        "                r=randrange(len(self.train))\n",
        "                while self.A[int(cn)][r]!=0:\n",
        "                    r=randrange(len(self.train))\n",
        "                diz[cn].append([r])\n",
        "            elif cn in diz:\n",
        "                diz[cn][0].append(int(self.COO[1][k]))\n",
        "                r=randrange(len(self.train))\n",
        "                while self.A[int(cn)][r]!=0:\n",
        "                    r=randrange(len(self.train))\n",
        "                diz[cn][1].append(r)\n",
        "                \n",
        "        return diz\n",
        "    def ConvertAtoCOO(self,SA):\n",
        "        Anew=torch.nonzero(SA).T.type(torch.LongTensor)\n",
        "        return Anew.to(self.device)\n",
        "\n",
        "    def getHardP_N(self,currentB,tensor):\n",
        "      samples=self.mbbPosNeg[currentB]\n",
        "      positives=torch.zeros((tensor.shape[0],tensor.shape[1]))\n",
        "      negatives=torch.zeros((tensor.shape[0],tensor.shape[1]))\n",
        "      mbbList=sorted(list(self.mb[currentB]))\n",
        "      for k in samples:\n",
        "        pos=samples[k][0]\n",
        "        neg=samples[k][1]\n",
        "        distDizP={kdist:((tensor[mbbList.index(k)]-tensor[mbbList.index(kdist)])**2).sum().item() for kdist in pos}\n",
        "        distDizN={kdist:((tensor[mbbList.index(k)]-tensor[mbbList.index(kdist)])**2).sum().item() for kdist in neg}\n",
        "        summP=sum(list(distDizP.values()))\n",
        "        summN=sum(list(distDizN.values()))\n",
        "        if len(distDizP)!=0 and summP!=0:\n",
        "          distDizP={kdist:distDizP[kdist]/summP for kdist in distDizP}\n",
        "        else:\n",
        "          distDizP[k]=0.5\n",
        "        if len(distDizN)!=0 and summN!=0:\n",
        "          distDizN={kdist:distDizN[kdist]/summN for kdist in distDizN}\n",
        "        else:\n",
        "          distDizN[k]=0.5\n",
        "        keysP=list(distDizP.keys())\n",
        "        keysN=list(distDizN.keys())\n",
        "        \n",
        "        for dist in keysP:\n",
        "          if distDizP[dist]>=self.lamb and len(distDizP)!=1:\n",
        "            distDizP.pop(dist)\n",
        "        \n",
        "        for dist in keysN:\n",
        "          if distDizN[dist]<= 1-self.lamb and len(distDizN)!=1:\n",
        "            distDizN.pop(dist)\n",
        "        \n",
        "        \n",
        "        positives[mbbList.index(k)]=tensor[mbbList.index(max(distDizP,key=distDizP.get))]\n",
        "        negatives[mbbList.index(k)]=tensor[mbbList.index(min(distDizN,key=distDizN.get))]\n",
        "      \n",
        "      return positives,negatives\n",
        "        \n",
        "        \n",
        "    \n",
        "    \n",
        "    def mini_batches(self,indices,bs=32): #This function generates a list of minibatches, of size bs\n",
        "        indexN=indices.copy()           #sets are unordered data structure, so there is no need to shuffle them. \n",
        "        indicesTot=[indexN[:len(self.train)],indexN[self.test[0]:]]\n",
        "        mbList=[]\n",
        "        self.mbbPosNeg={} \n",
        "        c=0   \n",
        "        num=int(len(self.train)/self.bs)+1     #Lists of lists of mini_batches indices \n",
        "        for indicesN in indicesTot:\n",
        "          u=0\n",
        "          if len(indicesN)==len(indexN[self.test[0]:]):\n",
        "            mb=set(indicesN)\n",
        "            mbList.append(mb)\n",
        "            self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "            update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "            self.mbbPosNeg[c].update(update)\n",
        "            return mbList\n",
        "          while len(indicesN)!=0:\n",
        "              mb=set()\n",
        "                                  #Inner list, with the indices of a particular mini_batch\n",
        "              while len(mb)<bs:\n",
        "                  if len(indicesN)==0:\n",
        "                      mbList.append(mb)\n",
        "                      self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "                      update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "                      self.mbbPosNeg[c].update(update)\n",
        "                      u=1\n",
        "                      c+=1\n",
        "                      break\n",
        "\n",
        "                  r=choice(indicesN)\n",
        "                  sample=indicesN.pop(indicesN.index(r))\n",
        "                  mb.add(sample)\n",
        "              if u!=1:\n",
        "                self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "                update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "                self.mbbPosNeg[c].update(update)\n",
        "                mbList.append(mb)\n",
        "                c+=1\n",
        "        return mbList          #obj.mini_batches(#,bs=128) #: train_,train,val,test, we get lists of list of batches from here\n",
        "    \n",
        "    \n",
        "    def getNegSample(self,key,mb):\n",
        "      l=[]\n",
        "      for j in mb:\n",
        "        if j!=key:\n",
        "          if key not in self.diz:\n",
        "            l.append(j)\n",
        "            if len(l)==4:\n",
        "              return l\n",
        "          else:\n",
        "            if j not in self.diz[key][0]:\n",
        "              l.append(j)\n",
        "              if len(l)==4:\n",
        "                return l  \n",
        "\n",
        "\n",
        "\n",
        "    def calcG(self,ID):  #This method is used for the evaluation of accuracy, in particular it computes the denominator\n",
        "        if ID>200:       # as described in the paper.\n",
        "            ID=200\n",
        "        c=1\n",
        "        somm=0\n",
        "        while c<=ID:\n",
        "            somm+=1/(math.log2(1+c))\n",
        "            c+=1\n",
        "        return somm\n",
        "\n",
        "    def evalAcc(self,S,kneigh,b):  #This function is to compute accuracy for the test and train set. \n",
        "        S = sorted(S)\n",
        "        S1 = sorted(self.train + S)\n",
        "        \n",
        "        T = self.forward(S1,b, nbs = -1, eval_mode = True)\n",
        "\n",
        "        test_embs = self.select(T,set(),S).to(torch.device('cpu')).detach().T.numpy()\n",
        "        T=T.detach().to(torch.device(\"cpu\")).numpy().transpose()\n",
        "        \n",
        "        neigh=NearestNeighbors(n_neighbors=(kneigh+1),algorithm='ball_tree').fit(test_embs) #With the K-NN we get the nearest \n",
        "        \n",
        "        dist,ind=neigh.kneighbors(test_embs)   \n",
        "        \n",
        "        acc=[]\n",
        "        A_acc=self.select(self.A,S,S)\n",
        "\n",
        "        c=0\n",
        "        for k in S:\n",
        "            summ=0\n",
        "            # ideal=len([i for i in range(self.test[0],self.test[0]+A_acc[k,:].shape[0]) if A_acc[k,i]!=0]) \n",
        "            \n",
        "            ideal = A_acc[ind[c][0]].sum().item()\n",
        "            \n",
        "            \n",
        "            \n",
        "            den=self.calcG(ideal)\n",
        "            if den==0:\n",
        "                c+=1\n",
        "                continue  \n",
        "            for j in range(len(ind[c][1:])):\n",
        "                if A_acc[ind[c][0]][ind[c][1:][j]].item()!=0:\n",
        "                    summ+= 1/(math.log2(1+(j+1)))\n",
        "                    \n",
        "                else:\n",
        "                    continue\n",
        "            c+=1    \n",
        "            summ/=den\n",
        "            acc.append(summ)\n",
        "        return acc\n",
        "            \n",
        "      \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb895db8",
      "metadata": {
        "id": "bb895db8"
      },
      "source": [
        "# Training step\n",
        "- In the following cell is possible to choose different hyperparameters to train the network.\n",
        "- In the hyperparameters tuning we must take into account: the number of layer (they try from 0 to 3 graph layers), the batch size, and the dimension of the projection matrices (in the aggregation step).\n",
        "- It is also possible to try previously described configurations.\n",
        "- There are also other hyperparameters of course, but they already are  deeply described in the paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06328f36",
      "metadata": {
        "id": "06328f36"
      },
      "outputs": [],
      "source": [
        "#### Possible partition of the dataset ####\n",
        "train_=list(range(0,9021+1)) #Train set, without val\n",
        "train=list(range(0,10189+1)) #Train set, with val\n",
        "val=list(range(9022,10189+1))\n",
        "test=list(range(10190,11260+1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ff785ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ff785ed",
        "outputId": "018833c2-241f-4ace-8ab1-8d335f02ef39",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 1-th mini-batch\n",
            "Processed 2-th mini-batch\n",
            "Processed 3-th mini-batch\n",
            "Processed 4-th mini-batch\n",
            "Processed 5-th mini-batch\n",
            "Processed 6-th mini-batch\n",
            "Processed 7-th mini-batch\n",
            "Processed 8-th mini-batch\n",
            "Processed 9-th mini-batch\n",
            "Processed 10-th mini-batch\n",
            "Processed 11-th mini-batch\n",
            "Processed 12-th mini-batch\n",
            "Processed 13-th mini-batch\n",
            "Processed 14-th mini-batch\n",
            "Processed 15-th mini-batch\n",
            "Processed 16-th mini-batch\n",
            "Processed 17-th mini-batch\n",
            "Processed 18-th mini-batch\n",
            "Processed 19-th mini-batch\n",
            "Processed 20-th mini-batch\n",
            "Adjusting learning rate of group 0 to 1.0000e-10.\n"
          ]
        }
      ],
      "source": [
        "## train_/val stands for the splitting for the model selection/ validation, whereas the splitting train/test is for the comparison of the results.\n",
        "training=train\n",
        "testing=test\n",
        "\n",
        "n_layer=3      #n_of graph conv.layer, if we are using the GraphSAGE configuration.\n",
        "batch_size=512 #This is the batch size used in the paper which inspired artist similarity, since it was not specified in the Artist similarity paper.\n",
        "\n",
        "device=torch.device(\"cuda\")\n",
        "XX = torch.randn((2613,11261))\n",
        "model= GraphSAGE(XX,A1,training,testing,n_layer,batch_size,device).to(device) #Conf3(X1,A1,training,testing,batch_size,device).to(device)\n",
        "num_epochs=1 #According to the paper there will be 50 epochs for each experiment \n",
        "\n",
        "triplet_loss = nn.TripletMarginLoss(margin=0.2, p=2)\n",
        "KNN=200\n",
        "#### Tune the learning rate and the weight decay regularization term ####\n",
        "lr=1e-10                         #[1e-6,1e-7,1e-8,1e-9,1-10]\n",
        "weight_d=0.01\n",
        "#lr=min([1,((1-0.9)/2)])    #linear warm-up described in the paper, beta2 = 0.9\n",
        "\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=lr,weight_decay=weight_d)\n",
        "\n",
        "scheduler=lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min= 0, last_epoch= -1, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "751972a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "751972a1",
        "outputId": "68b71010-fc0c-4bdf-d2a1-25e4fd6a714d",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing epoch n° 1\n",
            "Processing 1-th epoch: 1/20 mini-batch\n",
            "Processing 1-th epoch: 2/20 mini-batch\n",
            "Processing 1-th epoch: 3/20 mini-batch\n",
            "Processing 1-th epoch: 4/20 mini-batch\n",
            "Processing 1-th epoch: 5/20 mini-batch\n",
            "Processing 1-th epoch: 6/20 mini-batch\n",
            "Processing 1-th epoch: 7/20 mini-batch\n",
            "Processing 1-th epoch: 8/20 mini-batch\n",
            "Processing 1-th epoch: 9/20 mini-batch\n",
            "Processing 1-th epoch: 10/20 mini-batch\n",
            "Processing 1-th epoch: 11/20 mini-batch\n",
            "Processing 1-th epoch: 12/20 mini-batch\n",
            "Processing 1-th epoch: 13/20 mini-batch\n",
            "Processing 1-th epoch: 14/20 mini-batch\n",
            "Processing 1-th epoch: 15/20 mini-batch\n",
            "Processing 1-th epoch: 16/20 mini-batch\n",
            "Processing 1-th epoch: 17/20 mini-batch\n",
            "Processing 1-th epoch: 18/20 mini-batch\n",
            "Processing 1-th epoch: 19/20 mini-batch\n",
            "Processing 1-th epoch: 20/20 mini-batch\n",
            "Evaluating the epoch n° 1\n",
            "Processesed epoch n° 1,\tTest accuracy: 0.0776\tTest Loss: 0.1640\tTrain Loss: 0.14945741\t\n",
            "Adjusting learning rate of group 0 to 0.0000e+00.\n",
            "Requested time for processing 1-th epoch was: 148.8494 secs.\n"
          ]
        }
      ],
      "source": [
        "#### This line is for the training of the network ####\n",
        "mdl, optim, lossTr, accuracy, lossTe=TrainingPipeLine(model, optimizer, scheduler,triplet_loss, training, testing, num_epochs, KNN)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39165f93",
      "metadata": {
        "id": "39165f93"
      },
      "source": [
        "## Save and load a model\n",
        "\n",
        "* In the following cell is possible to save the trained model, and eventually to load it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "241a938b",
      "metadata": {
        "id": "241a938b"
      },
      "outputs": [],
      "source": [
        "path=\"models/three_layersSAGE_random.pt\" ## Change the path to save the trained model where you wish.\n",
        "\n",
        "#### This line calls the function to save the previous obtained results (from the training of the model) ####\n",
        "#Save_Model(path,mdl,optim,lossTr,accuracy,lossTe)\n",
        "device = 'cuda'\n",
        "\n",
        "#### This line can be uncommented in order to get data from one of our pre-trained model ####\n",
        "#model_check=Load_Model(\"models/conf2NEW.pt\", device)\n",
        "# print(model_check[\"Accuracy_History\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uikN7uw7q89I",
      "metadata": {
        "id": "uikN7uw7q89I"
      },
      "source": [
        "## Accuracy results\n",
        "* Choose the architecture amongst the 7, and see the results.\n",
        "* The obtained results are shown in results, and are plotted in the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Vj8o4fGyrKQM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj8o4fGyrKQM",
        "outputId": "f6032a62-3e92-497d-9344-440c3e7409d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.4274988132047857"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "models = [\"SAGE1\",\"SAGE2\", \"SAGE3\",\"conf1\",\"conf2\",\"conf3\",\"conf4\",\"random_conf3\", \"random_SAGE3\"]\n",
        "results = [0.26275006124936195,0.3189057310486129,0.4274988132047857,0.5669277224607767,0.47781317707844545,0.6927919457182362,0.6213292268763897,0.6982752015757381,0.08483794916268922]\n",
        "XX = torch.randn((2613,11261))\n",
        "\n",
        "get_accuracy(\"SAGE3\",device = 'cuda', instance = X1, model_path = 'models/three_layerSAGENEW.pt',n_layers = 3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x7mRyEYmUBdV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "x7mRyEYmUBdV",
        "outputId": "a0c85ee2-a8fa-4a87-9cf4-328330a3c280"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"ba3c8232-a4c4-4ec9-ae86-258cfe12dcb7\" class=\"plotly-graph-div\" style=\"height:550px; width:500px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ba3c8232-a4c4-4ec9-ae86-258cfe12dcb7\")) {                    Plotly.newPlot(                        \"ba3c8232-a4c4-4ec9-ae86-258cfe12dcb7\",                        [{\"name\":\"GraphSAGE1\",\"text\":\"0.2628\",\"textposition\":\"auto\",\"y\":[0.26275006124936195],\"type\":\"bar\"},{\"name\":\"GraphSAGE2\",\"text\":\"0.3189\",\"textposition\":\"auto\",\"y\":[0.3189057310486129],\"type\":\"bar\"},{\"name\":\"GraphSAGE3\",\"text\":\"0.4275\",\"textposition\":\"auto\",\"y\":[0.4274988132047857],\"type\":\"bar\"},{\"name\":\"Graphrandom_SAGE3\",\"text\":\"0.0848\",\"textposition\":\"auto\",\"y\":[0.08483794916268922],\"type\":\"bar\"},{\"name\":\"conf1\",\"text\":\"0.5669\",\"textposition\":\"auto\",\"y\":[0.5669277224607767],\"type\":\"bar\"},{\"name\":\"conf2\",\"text\":\"0.4778\",\"textposition\":\"auto\",\"y\":[0.47781317707844545],\"type\":\"bar\"},{\"name\":\"conf3\",\"text\":\"0.6928\",\"textposition\":\"auto\",\"y\":[0.6927919457182362],\"type\":\"bar\"},{\"name\":\"random_conf3\",\"text\":\"0.6983\",\"textposition\":\"auto\",\"y\":[0.6982752015757381],\"type\":\"bar\"},{\"name\":\"conf4\",\"text\":\"0.6213\",\"textposition\":\"auto\",\"y\":[0.6213292268763897],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"tickfont\":{\"size\":14}},\"yaxis\":{\"title\":{\"text\":\"Normalized Discounted Cumulative Gain\",\"font\":{\"size\":16}},\"tickfont\":{\"size\":14}},\"legend\":{\"x\":0,\"y\":1.0,\"bgcolor\":\"rgba(255, 255, 255, 0)\",\"bordercolor\":\"rgba(255, 255, 255, 0)\"},\"title\":{\"text\":\"Performances over the different architectures\"},\"bargap\":0.15,\"bargroupgap\":0.1,\"width\":500,\"height\":550},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ba3c8232-a4c4-4ec9-ae86-258cfe12dcb7');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "prefix = 'Graph'\n",
        "fig = go.Figure(data=[\n",
        "    go.Bar(name=prefix+models[0], y=[results[0]],text = round(results[0],4), textposition='auto'),\n",
        "    go.Bar(name=prefix+models[1], y=[results[1]],text = round(results[1],4), textposition='auto'),\n",
        "    go.Bar(name=prefix+models[2], y=[results[2]],text = round(results[2],4), textposition='auto'),\n",
        "    go.Bar(name=prefix+models[8], y =[results[8]],text = round(results[8],4), textposition='auto'),\n",
        "    go.Bar(name=models[3], y=[results[3]],text = round(results[3],4), textposition='auto'),\n",
        "    go.Bar(name=models[4], y=[results[4]],text = round(results[4],4), textposition='auto'),\n",
        "    go.Bar(name=models[5], y=[results[5]],text = round(results[5],4), textposition='auto'),\n",
        "    go.Bar(name=models[7], y=[results[7]],text = round(results[7],4), textposition='auto'),\n",
        "    go.Bar(name=models[6], y=[results[6]],text = round(results[6],4), textposition='auto')\n",
        "])\n",
        "fig.update_layout(\n",
        "    title='Performances over the different architectures',\n",
        "    xaxis_tickfont_size=14,\n",
        "    yaxis=dict(\n",
        "        title='Normalized Discounted Cumulative Gain',\n",
        "        titlefont_size=16,\n",
        "        tickfont_size=14,\n",
        "    ),\n",
        "    legend=dict(\n",
        "        x=0,\n",
        "        y=1.0,\n",
        "        bgcolor='rgba(255, 255, 255, 0)',\n",
        "        bordercolor='rgba(255, 255, 255, 0)'\n",
        "    ),\n",
        "    \n",
        "    bargap=0.15, # gap between bars of adjacent location coordinates.\n",
        "    bargroupgap=0.1 # gap between bars of the same location coordinate.\n",
        ")\n",
        "fig.update_layout(width = 500, height = 550)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tO9B1osddXff",
      "metadata": {
        "id": "tO9B1osddXff"
      },
      "source": [
        "As was described in the paper's authors GraphSAGE networks lose in accuracy when we are using a random low level features vector. But if we use the same random approach with the GAT-based architecture (conf3), we don't lose any performance in accuracy, we could get even better results. In fact, the adjacency matrix is based more on musicological features, instead of low level features. So we can say that GraphSage layers are not able to generalize the instance vectors as well as the GAT layers."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m11QuOt-8xqP",
      "metadata": {
        "id": "m11QuOt-8xqP"
      },
      "source": [
        "## Let's get the artists embeddings\n",
        "Now, given one of the 7 configurations we can test how much are plausible (from a musical point of view), its nearest neighbors.\n",
        "* Firstly, we need to know some artists that are from the test set, so we need to look for them. They are identified by all the indices from 10190 to 11260.\n",
        "* Then we get the points in the embedding space of all the dataset.\n",
        "* Then we compute for a certain arbitrary artist its K-nearest neighbors.\n",
        "* To compute the nearest neighbors we use the same function that was used to compute the accuracy. \n",
        "* Remember that the Graph of artists is obtained through the opinion of experts and the attributes of the nodes represents the low level features. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vuc2r0eWr6X0",
      "metadata": {
        "id": "vuc2r0eWr6X0"
      },
      "outputs": [],
      "source": [
        "test_list = list(range(10190,11261))\n",
        "for index in test_list:\n",
        "  print(diz_of_artist[str(index)])   #Ringo Starr, Giacomo Puccini, Michael Jackson, Gigi D'Agostino, Snoop Dogg, Alex Britti, Nancy Sinatra, Rod Stewart."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "filDDR1eDYyf",
      "metadata": {
        "id": "filDDR1eDYyf"
      },
      "source": [
        "* If you want to look for embedding by yourself you can change the setting of the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HV-NWMbkDgPq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV-NWMbkDgPq",
        "outputId": "ae9c1a57-2de0-4efd-fb0c-c91c238f3683"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "The 20 nearest artist in the embedded space for Roger Waters are:\n",
            "\n",
            "[('Yes', 0.1261), ('The Alan Parsons Project', 0.1299), ('Pink Floyd', 0.1422), ('Greg Lake', 0.1436), ('Emerson, Lake & Palmer', 0.1449), ('Van der Graaf Generator', 0.1772), ('Procol Harum', 0.1901), ('Steely Dan', 0.1918), ('Peter Gabriel', 0.1932), ('Gary Wright', 0.1974), ('Anderson Bruford Wakeman Howe', 0.1974), ('Be Bop Deluxe', 0.2027), ('The Moody Blues', 0.2063), ('Roxy Music', 0.2068), ('Jeff Lynne', 0.2094), ('Mick Abrahams', 0.2106), ('David Bowie', 0.2157), ('Phil Manzanera', 0.2169), ('Dire Straits', 0.2203), ('Terry Reid', 0.2208)]\n"
          ]
        }
      ],
      "source": [
        "K = 20 # Number of neighbors of that we are going to look for #\n",
        "device = 'cuda'\n",
        "model_name = 'conf3' ## Choose the model ##\n",
        "random = False\n",
        "\n",
        "if random:\n",
        "  instance = XX\n",
        "else:\n",
        "  instance = X1\n",
        "\n",
        "## Compute the embeddings based on the architecture ##\n",
        "embs = get_embeddings(model_name, instance, device, model_path = \"models/conf3NEW.pt\") #, n_layers = 3)\n",
        "\n",
        "## Choose the embedding ##\n",
        "embedding = embs\n",
        "\n",
        "artist_name = 'Roger Waters'\n",
        "print(\"\\nThe {} nearest artist in the embedded space for {} are:\\n\".format(K,artist_name))\n",
        "ind = get_nearest_artists(embedding,artist_name,K,art_to_code,diz_of_artist)\n",
        "print(ind)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5v1_X2dT-DVY",
      "metadata": {
        "id": "5v1_X2dT-DVY"
      },
      "source": [
        "According to this list and based on our musicological knowledge we have chosen to consider the following artists: Ringo Starr, Giacomo Puccini, Michael Jackson, Gigi D'Agostino, Snoop Dogg, Alex Britti, Nancy Sinatra, Rod Stewart.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd2972f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd2972f7",
        "outputId": "57fbe8eb-56a6-402a-dcf3-ccb452da5b42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "The 20 nearest artist in the embedded space for Ringo Starr are:\n",
            "\n",
            "[('Jim Dickinson', 0.1548), ('Tom Petty', 0.1564), ('Steve Winwood', 0.1574), ('John Fogerty', 0.1613), ('David Essex', 0.1619), ('Dire Straits', 0.1638), ('Bruce Springsteen', 0.1642), ('Fleetwood Mac', 0.1678), ('Jeff Lynne', 0.1729), ('Tom Cochrane', 0.1732), ('The Kinks', 0.174), ('Steve Miller Band', 0.1761), ('Eric Burdon', 0.181), ('The Doobie Brothers', 0.1819), ('Eric Clapton', 0.1847), ('Al Anderson', 0.1849), ('Bill Wyman’s Rhythm Kings', 0.1856), ('Timothy B. Schmit', 0.1875), ('The Move', 0.1901), ('Don Johnson', 0.1911)]\n",
            "\n",
            "The 20 nearest artist in the embedded space for Giacomo Puccini are:\n",
            "\n",
            "[('Samuel Barber', 0.6817), ('Ned Rorem', 0.6817), ('Sir Neville Marriner', 1.037), ('Cecilia Bartoli', 1.0712), ('Academy of St Martin in the Fields', 1.0728), ('Antal Doráti', 1.0859), ('Herbert von Karajan', 1.1361), ('English Chamber Orchestra', 1.1409), ('Kiri Te Kanawa', 1.163), ('Béla Bartók', 1.1817), ('Plácido Domingo', 1.1991), ('Royal Philharmonic Orchestra', 1.2239), ('Ruth Etting', 1.2257), ('Bryn Terfel', 1.2269), ('Frederica von Stade', 1.2381), ('Philharmonia Orchestra', 1.2861), ('London Symphony Orchestra', 1.289), ('André Previn', 1.2918), ('Montserrat Caballé', 1.2924), ('Royal Liverpool Philharmonic Orchestra', 1.2952)]\n",
            "\n",
            "The 20 nearest artist in the embedded space for Michael Jackson are:\n",
            "\n",
            "[('Stephanie Mills', 0.1588), ('Charlie Wilson', 0.1599), ('Billy Ocean', 0.1667), ('Teena Marie', 0.1822), ('The Jacksons', 0.1938), ('Atlantic Starr', 0.1965), ('Lenny Williams', 0.207), ('Alexander O’Neal', 0.2107), ('Mtume', 0.2121), ('Giorgio Moroder', 0.2211), ('Sydney Youngblood', 0.2238), ('Shalamar', 0.2257), ('Luther Vandross', 0.2345), ('Terence Trent D’Arby', 0.2385), ('Cheryl Lynn', 0.2392), ('Rick James', 0.2408), ('Lisa Stansfield', 0.2489), ('Chic', 0.2519), ('Stacy Lattisaw', 0.2522), ('Jon Secada', 0.2532)]\n",
            "\n",
            "The 20 nearest artist in the embedded space for Gigi D’Agostino are:\n",
            "\n",
            "[('Mylo', 0.2315), ('Bob Sinclar', 0.2439), ('Junkie XL', 0.2505), ('Safri Duo', 0.2512), ('Alice DeeJay', 0.2596), ('Basement Jaxx', 0.2705), ('Pulsedriver', 0.2877), ('U96', 0.2913), ('Andrew Weatherall', 0.2944), ('Hot Banditoz', 0.2953), ('Faithless', 0.313), ('Danzel', 0.3131), ('Vitalic', 0.315), ('Kosheen', 0.3167), ('Eric Prydz', 0.3227), ('Tiësto', 0.3228), ('Ultra Naté', 0.3356), ('Deep Dish', 0.3403), ('SebastiAn', 0.3407), (\"Guns n' Bombs\", 0.344)]\n",
            "\n",
            "The 20 nearest artist in the embedded space for Snoop Dogg are:\n",
            "\n",
            "[('2Pac', 0.1406), ('Tha Dogg Pound', 0.1415), ('Mack 10', 0.1471), ('Luniz', 0.1524), ('Benzino', 0.1555), ('Obie Trice', 0.1575), ('Spice 1', 0.1643), ('Too $hort', 0.1655), ('Fler', 0.1661), ('Kurupt', 0.1677), ('Eminem', 0.1752), ('DJ Quik', 0.1846), ('JAY‐Z', 0.1869), ('Afroman', 0.1883), ('Scarface', 0.1911), ('Stat Quo', 0.1972), ('Tony Yayo', 0.2019), ('Clipse', 0.205), ('Nas', 0.2062), ('Crooked I', 0.2063)]\n",
            "\n",
            "The 20 nearest artist in the embedded space for Alex Britti are:\n",
            "\n",
            "[('Alex Baroni', 0.1665), ('Francesco Renga', 0.1937), ('Paolo Meneguzzi', 0.2097), ('Eros Ramazzotti', 0.2648), ('Luca Carboni', 0.2908), ('Antonello Venditti', 0.2963), ('Pino Daniele', 0.3012), ('Marco Masini', 0.3254), ('Francesco De Gregori', 0.3301), ('Ligabue', 0.3304), ('Lucio Dalla', 0.3451), ('Aleks Syntek', 0.3553), ('Elio e le Storie Tese', 0.3628), ('Giorgia', 0.3647), ('Juanes', 0.3704), ('Chayanne', 0.3705), ('Pascal Obispo', 0.3723), ('Alejandro Sanz', 0.3764), ('Manolo García', 0.3789), ('Dyango', 0.3818)]\n",
            "\n",
            "The 20 nearest artist in the embedded space for Nancy Sinatra are:\n",
            "\n",
            "[('Dusty Springfield', 0.1921), ('Cilla Black', 0.2103), ('Harpers Bizarre', 0.2162), ('Helen Shapiro', 0.2193), ('Sonny & Cher', 0.2256), ('The 5th Dimension', 0.2257), ('Bobbie Gentry', 0.2353), ('Paul Anka', 0.2527), ('Neil Sedaka', 0.2543), ('Frankie Valli', 0.2568), ('Pat Boone', 0.2617), ('Bobby Goldsboro', 0.2624), ('Barbara Lewis', 0.2769), ('Captain & Tennille', 0.2781), ('Barry Manilow', 0.2815), ('Joe South', 0.2892), ('Bobby Vinton', 0.293), ('Lynn Anderson', 0.2954), ('Frankie Avalon', 0.2958), ('Brenda Lee', 0.2973)]\n",
            "\n",
            "The 20 nearest artist in the embedded space for Rod Stewart are:\n",
            "\n",
            "[('Fleetwood Mac', 0.117), ('Ringo Starr', 0.1201), ('Phil Collins', 0.1244), ('Dire Straits', 0.141), ('Paul Carrack', 0.143), ('John Waite', 0.1438), ('Bruce Springsteen', 0.144), ('Tom Cochrane', 0.1474), ('Stevie Nicks', 0.1477), ('The Doobie Brothers', 0.1525), ('Daryl Hall & John Oates', 0.1531), ('Steve Perry', 0.1543), ('Jim Dickinson', 0.156), ('Eric Clapton', 0.1569), ('Jeff Lynne', 0.16), ('Billy Joel', 0.1602), ('Steve Miller Band', 0.1614), ('Don Johnson', 0.1627), ('Jesse ‘Ed’ Davis', 0.1644), ('John Fogerty', 0.1645)]\n"
          ]
        }
      ],
      "source": [
        "K = 20 # Number of neighbors of that we are going to look for #\n",
        "artist_list = ['Ringo Starr', 'Giacomo Puccini', 'Michael Jackson', \"Gigi D’Agostino\", 'Snoop Dogg','Alex Britti','Nancy Sinatra','Rod Stewart']\n",
        "device = 'cuda'\n",
        "model_name = 'conf3' ## Choose the model ##\n",
        "XX = torch.randn((2613,11261))\n",
        "## Compute the embeddings based on the architecture ##\n",
        "embs = get_embeddings(model_name,X1, device, model_path = \"models/conf3NEW.pt\")#, n_layers = 3)\n",
        "\n",
        "\n",
        "\n",
        "## Choose the embedding ##\n",
        "embedding = embs\n",
        "\n",
        "\n",
        "\n",
        "for artist_name in artist_list:\n",
        "  print(\"\\nThe {} nearest artist in the embedded space for {} are:\\n\".format(K,artist_name))\n",
        "  ind = get_nearest_artists(embedding,artist_name,K,art_to_code,diz_of_artist)\n",
        "  print(ind)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
