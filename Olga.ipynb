{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4fmrN5VAWUrJ",
      "metadata": {
        "id": "4fmrN5VAWUrJ"
      },
      "source": [
        "# Neural Network project, 2022\n",
        "## - Artist similarity with Graph Neural Networks (re-implementation)\n",
        "- Andrea Giuseppe Di Francesco, 1836928\n",
        "- Giuliano Giampietro, 2024160\n",
        "\n",
        "* In this notebook we present a complete re-implementation of the paper ['Artist similarity with Graph Neural Network'](https://arxiv.org/abs/2107.14541). \n",
        "* Since the project's code wasn't provided by the authors, except for the [dataset](https://gitlab.com/fdlm/olga://paperswithcode.com/paper/artist-similarity-with-graph-neural-networks), we attempted to repeat the experiments described in the paper, and we have additionally tried 4 additional GNNs architectures, provided by the Phd student Indro Spinelli.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "serwR-KUl2Ym",
      "metadata": {
        "id": "serwR-KUl2Ym"
      },
      "source": [
        "## - Importing the libraries\n",
        "\n",
        "In the following cell we import the libraries that we used to carry out our experiments, and to extract the dataset. Since we worked with the Graph Neural Networks (GNN), it was very helpful to use the [pytorch geometric library](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html), that contains a lot of useful classes that implement the most famous GNNs architectures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d8aee866",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: musicbrainzngs in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (0.7.1)\n",
            "Requirement already satisfied: spacy-sentence-bert in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (0.1.2)\n",
            "Requirement already satisfied: protobuf in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from spacy-sentence-bert) (3.19.6)\n",
            "Requirement already satisfied: sentence-transformers in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from spacy-sentence-bert) (2.2.2)\n",
            "Requirement already satisfied: spacy<4.0.0,>=3.0.0 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from spacy-sentence-bert) (3.4.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (0.6.2)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (0.4.2)\n",
            "Requirement already satisfied: jinja2 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (3.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (2.4.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (2.0.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (2.28.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (0.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (21.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (4.64.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (1.10.2)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (8.1.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (3.0.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (1.0.9)\n",
            "Requirement already satisfied: setuptools in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (59.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (2.0.8)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (1.23.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (3.0.10)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (3.3.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (1.0.3)\n",
            "Requirement already satisfied: scipy in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from sentence-transformers->spacy-sentence-bert) (1.9.3)\n",
            "Requirement already satisfied: torch>=1.6.0 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from sentence-transformers->spacy-sentence-bert) (1.12.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from sentence-transformers->spacy-sentence-bert) (4.21.3)\n",
            "Requirement already satisfied: scikit-learn in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from sentence-transformers->spacy-sentence-bert) (1.1.3)\n",
            "Requirement already satisfied: sentencepiece in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from sentence-transformers->spacy-sentence-bert) (0.1.97)\n",
            "Requirement already satisfied: nltk in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from sentence-transformers->spacy-sentence-bert) (3.7)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from sentence-transformers->spacy-sentence-bert) (0.10.1)\n",
            "Requirement already satisfied: torchvision in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from sentence-transformers->spacy-sentence-bert) (0.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers->spacy-sentence-bert) (4.3.0)\n",
            "Requirement already satisfied: filelock in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers->spacy-sentence-bert) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers->spacy-sentence-bert) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from packaging>=20.0->spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (2.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (1.26.12)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (0.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->spacy-sentence-bert) (2022.9.13)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->spacy-sentence-bert) (0.12.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from typer<0.5.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from jinja2->spacy<4.0.0,>=3.0.0->spacy-sentence-bert) (2.1.1)\n",
            "Requirement already satisfied: joblib in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from nltk->sentence-transformers->spacy-sentence-bert) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from scikit-learn->sentence-transformers->spacy-sentence-bert) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages (from torchvision->sentence-transformers->spacy-sentence-bert) (9.2.0)\n",
            "1.12.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# !pip install plotly\n",
        "!pip install musicbrainzngs\n",
        "# !pip install torchmetrics\n",
        "!pip install spacy-sentence-bert\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "# !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "# !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "# !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9e657a64",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e657a64",
        "outputId": "263c1dba-6510-4de0-dcae-62182872e4b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fb85c5f1890>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import json\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchmetrics.functional import pairwise_euclidean_distance\n",
        "# from torch_geometric.nn import GATConv, SAGEConv\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler\n",
        "import random\n",
        "from random import choice,randrange\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import math\n",
        "import time\n",
        "# from torch_geometric.nn import GCNConv,GraphConv,GATConv,SAGEConv\n",
        "import musicbrainzngs as mbr\n",
        "import spacy_sentence_bert\n",
        "\n",
        "random_seed=80085\n",
        "\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e5bfd991",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: 100%|██████████| 744/744 [00:00<00:00, 770kB/s]\n",
            "Downloading: 100%|██████████| 190/190 [00:00<00:00, 325kB/s]\n",
            "Downloading: 100%|██████████| 3.92k/3.92k [00:00<00:00, 2.39MB/s]\n",
            "Downloading: 100%|██████████| 672/672 [00:00<00:00, 475kB/s]\n",
            "Downloading: 100%|██████████| 122/122 [00:00<00:00, 69.0kB/s]\n",
            "Downloading: 100%|██████████| 456k/456k [00:00<00:00, 996kB/s]  \n",
            "Downloading: 100%|██████████| 499M/499M [00:43<00:00, 11.5MB/s] \n",
            "Downloading: 100%|██████████| 52.0/52.0 [00:00<00:00, 31.4kB/s]\n",
            "Downloading: 100%|██████████| 239/239 [00:00<00:00, 139kB/s]\n",
            "Downloading: 100%|██████████| 1.36M/1.36M [00:00<00:00, 1.97MB/s]\n",
            "Downloading: 100%|██████████| 1.17k/1.17k [00:00<00:00, 910kB/s]\n",
            "Downloading: 100%|██████████| 798k/798k [00:00<00:00, 1.38MB/s]\n",
            "Downloading: 100%|██████████| 229/229 [00:00<00:00, 105kB/s]\n"
          ]
        }
      ],
      "source": [
        "sentence_selector = spacy_sentence_bert.load_model('en_stsb_roberta_base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5a78feb",
      "metadata": {},
      "outputs": [],
      "source": [
        "sentence_selector('classic pop and rock').similarity(sentence_selector('pop music'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbd20535",
      "metadata": {
        "id": "cbd20535"
      },
      "source": [
        "## Loading of the dataset Olga\n",
        "\n",
        " - In the next cell there is the raw dataset provided by the paper's authors **'Artist similarity with Graph Neural Networks'**.\n",
        " - Along the columns we have information about the [Musicbrainz_id](https://musicbrainz.org/) of an artist, its partition in the dataset (train,val,test), and the [AcousticBrainz](https://acousticbrainz.org/) low level features of the artist, taken from a sample of 25 songs. \n",
        " - Unfortunately, at the best of our efforts, it was not possible to recover all the information that were described in the [paper](https://arxiv.org/pdf/2107.14541.pdf). Indeed the artists contained in Olga are 17.673, whereas we were able to extract [Allmusic](https://www.allmusic.com/) ids only from 11.261 artists. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9c407599",
      "metadata": {
        "id": "9c407599"
      },
      "outputs": [],
      "source": [
        "olga=pd.read_csv('olga.csv')\n",
        "#train 0-14138, #val 14139-15905, #test 15906-17673 (indices)\n",
        "olga[:30]\n",
        "\n",
        "mbr.auth('ggiamp', 'fallinggiant')\n",
        "mbr.set_useragent(\n",
        "    \"python-musicbrainzngs-example\",\n",
        "    \"0.1\",\n",
        "    \"https://github.com/alastair/python-musicbrainzngs/\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08648966",
      "metadata": {
        "id": "08648966"
      },
      "source": [
        "### How do we retrieve the Graph topology?\n",
        "\n",
        "- Thanks to the musicbrainz_id of each artist, we can get the link to its AllMusic profile, and from there we get also the information about its related artists. Each AllMusic link is related to a unique artist, indeed we can spot a 12 numbers identifier for each of these.\n",
        "- After having obtained the AllMusic link for each artist in the dataset (if exists), we want to associate to each artist its related ones. We do this just for those that can be re-mapped in the dataset's musicbrainz_ids, because we have associated tracks features for those.\n",
        "- Also this passage is probably very lossy, in fact, for each artist there could be a lot of similar artists (according to the AllMusic information), but we don't have the feature vectors for all of them.\n",
        "- The following class contains methods that extract information about all the artists in the dataset, but the price to pay is a high computational cost. \n",
        "For this reason it was run just once, and the information was stored in different files, such as 'MsbMapped.json', 'graphSimilarities.json', 'dizofartist.json'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "3712d1b8",
      "metadata": {
        "id": "3712d1b8",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "class DatasetOlga(): #In this class, we obtain through different methods the main characteristics of the graph of artists\n",
        "                    # thanks to the available information in the olga dataset\n",
        "    def __init__(self,olga):\n",
        "        self.olga=olga\n",
        "        self.mb=olga.musicbrainz_id\n",
        "        self.artists={} #Needed for obtaining the mapping from musicbrainz to the allmusic ids\n",
        "        self.l=len(self.mb)\n",
        "        self.d={}       #Needed for obtaining a dict. where keys are artists, and values are the artists similar to them, based on self.artists\n",
        "        self.NI={}      #Dict. that will contain the artist's features\n",
        "    \n",
        "    def get_mapping(self,i):                                                                                                 #This method returns the allmusic page of an artist (if exists), given his id from the dataset \n",
        "        response = requests.get(f'https://musicbrainz.org/ws/2/artist/{str(self.mb[i])}?inc=url-rels&fmt=json')\n",
        "        if response.ok:\n",
        "            data = response.json()\n",
        "            refs = [r['url']['resource'] for r in data['relations'] if r['type'] == 'allmusic']        \n",
        "            return refs[0] if len(refs) != 0 else \"Not found\"\n",
        "\n",
        "    def get_artist_name(self,i):                                                                                                 #This method returns the allmusic page of an artist (if exists), given his id from the dataset \n",
        "        response = requests.get(f'https://musicbrainz.org/ws/2/artist/{str(self.mb[i])}?inc=url-rels&fmt=json')\n",
        "        if response.ok:\n",
        "            data = response.json()\n",
        "            data = dict(data)\n",
        "            return data['name']\n",
        "\n",
        "\n",
        "\n",
        "    def get_mappingList(self,init,end,increm=500):\n",
        "        Lmusicbrainz_id=self.mb[init:end] #We can specify the range of the artists of our interest, for the purpose of this NN task\n",
        "        length=len(Lmusicbrainz_id)       #we will take all of them into consideration.\n",
        "        c=0\n",
        "        for i in range(len(Lmusicbrainz_id)):\n",
        "            mapp=self.get_mapping(i)   #get_mapping method again.\n",
        "            if mapp==None:\n",
        "                while mapp==None:\n",
        "                    mapp=self.get_mapping(i)\n",
        "                    \n",
        "            if mapp!=\"Not found\":   #Some of the ids has not a respective allmusic id, so we lose that information\n",
        "                mapp=str(mapp)      #Mapp are strings of links\n",
        "                key=mapp[-12:]\n",
        "                self.artists[key]=i\n",
        "            c+=1\n",
        "            if c%increm==0 or c==30:\n",
        "                    print(\"{}/{} artists were processed\".format(c,length)) #This is just to keep track of the processed artist\n",
        "                    \n",
        "            \n",
        "        self.save_data(self.artists,'MsbMapped1.json')  #We do save the Artists Ids map, this function, when called, takes a lot\n",
        "                                                        #of time, for this reason its result is already saved in the file:\n",
        "        return self.artists                             # 'MsbMapped1.json'\n",
        "    \n",
        "    \n",
        "    def get_GraphDict(self,name='MsbMapped.json',increm=500):\n",
        "        session=HTMLSession()\n",
        "        c=0 #Counter\n",
        "        artID=self.load_data(name) #We load the mapped artists (between MusicBrainz Ids, and AllMusic Ids)\n",
        "        # print(len(artID)\n",
        "        length=len(artID.keys())\n",
        "        for k in artID.keys(): #dict of mapped mbids, this has to be computed before from getmapping\n",
        "            if k!=None:\n",
        "                url='https://www.allmusic.com/artist/'+ k+ '/related' #k is just the code, every link for the artist is distinguished \n",
        "                r=session.get(url)                                    #by a unique code in the link.\n",
        "                sess=r.html.find('body',first=True)\n",
        "                div=sess.find('.overflow-container')                  #The information of the related artists are exctracted\n",
        "                divn=div[0]                                           #from the html of the allmusic's related web page\n",
        "                divn=divn.find('.content-container')\n",
        "                divn=divn[0]\n",
        "                divn=divn.find('.content')\n",
        "                divn=divn[0]\n",
        "                divn=divn.find('section',first=True)\n",
        "                if divn==None:\n",
        "                    self.d[artID[k]]=[] #That artist has not related artists (or we have missing information)\n",
        "                    continue\n",
        "                artists=divn.find('li')\n",
        "                artistL=[]\n",
        "\n",
        "\n",
        "                for i in range(len(artists)):\n",
        "                    art=artists[i]\n",
        "                    art=art.find('a')            #We look for all the k's related artists links\n",
        "                    link=list(art[0].absolute_links)[0] #Absolute_link returns a one-element set, that we convert into a list and\n",
        "                    link=str(link)[-12:]                #we get its code\n",
        "                    if link in artID.keys(): #g is the dict of all the mapped musicbrainz_ids\n",
        "                        artistL.append(self.artists[link]) #Some of the related artists may not be in the musicbrainz_ids list.\n",
        "                self.d[artID[k]]=artistL\n",
        "                c+=1\n",
        "                if c%increm==0 or c==30:\n",
        "                    print(\"{}/{} artists were processed\".format(c,length))\n",
        "        self.save_data(self.d,'graphSimilarities1.json') #Here we save the connection amongst the artists, obtained with this method\n",
        "        print(\"Done...\")     #Also it takes some time to process, for this reason the result of this method can be \n",
        "        return self.d        #found at the 'graphSimilarities.json' file.\n",
        "\n",
        "    def get_genres(self,name='MsbMapped.json',increm=500):\n",
        "        \n",
        "        c=0 #Counter\n",
        "        artID=self.load_data(name) #We load the mapped artists (between MusicBrainz Ids, and AllMusic Ids)\n",
        "        valid_ids = sorted(list(artID.values()))\n",
        "        self.occurrencies = {}\n",
        "        self.artist_genre = {}\n",
        "        print('Num of artist: {}', len(valid_ids))\n",
        "        self.lost = 0\n",
        "        for artist_num in range(len(valid_ids)):\n",
        "          print(len(self.occurrencies))\n",
        "          print('Artist {}/{}'.format(artist_num, len(valid_ids)))\n",
        "          art_id = self.olga.iloc[valid_ids[artist_num], 1]\n",
        "          result = mbr.get_artist_by_id(art_id,\n",
        "              includes=['tags'])\n",
        "          \n",
        "          if 'tag-list' in result['artist']:\n",
        "            genre_list = [genre['name'] for genre in result['artist']['tag-list']]\n",
        "            self.artist_genre[artist_num] = genre_list, result['artist']['name']\n",
        "            for genre in genre_list:\n",
        "              if genre not in self.occurrencies:\n",
        "                self.occurrencies[genre] = 1\n",
        "              else:\n",
        "                self.occurrencies[genre] += 1\n",
        "          else:\n",
        "            self.lost += 1\n",
        "            print('Lost artist {}'.format(self.lost))\n",
        "            self.artist_genre[artist_num] = [], result['artist']['name']\n",
        "\n",
        "\n",
        "        return \n",
        "\n",
        "    def get_artist_genres(self,name='MsbMapped.json',increm=500):\n",
        "        c=0 #Counter\n",
        "        artID=self.load_data(name) #We load the mapped artists (between MusicBrainz Ids, and AllMusic Ids)\n",
        "        valid_ids = sorted(list(artID.values()))\n",
        "        return artID\n",
        "    \n",
        "    def save_data(self,dicti,name):\n",
        "        jfile = open(name, \"w\")\n",
        "        jfile = json.dump(dicti, jfile)\n",
        "    \n",
        "    def load_data(self,name):\n",
        "        jfile = open(name, \"r\")\n",
        "        dicti = json.load(jfile)\n",
        "        return dicti\n",
        "    @staticmethod\n",
        "    def get_the_Kmost_rated_genre(diz, k):\n",
        "        l = []\n",
        "        for i in range(k):\n",
        "            key = max(diz, key = diz.get)\n",
        "            l.append({key: diz[key]})\n",
        "            diz.pop(key)\n",
        "        return l\n",
        "\n",
        "ol = DatasetOlga(olga)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PrIWLDo63SQ5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrIWLDo63SQ5",
        "outputId": "45c069e7-b9ca-4af1-af22-b5f96a9cf15b"
      },
      "outputs": [],
      "source": [
        "occurrencies = ol.load_data('genres_occurrencies.json')\n",
        "art_genre = ol.load_data('artist_genre.json')\n",
        "\n",
        "##############################################\n",
        "ol.get_the_Kmost_rated_genre(occurrencies, 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13f2be61",
      "metadata": {
        "id": "13f2be61"
      },
      "source": [
        "## Graph construction\n",
        "\n",
        "- Once we have obtained the information necessary to construct the Graph topology, and stored them into two json files ('MsbMapped.json','graphSimilarities.json'), we still need to have the Graph data structure to feed the Graph Convolutional Network.\n",
        "\n",
        "- In the following cell are defined the graph's adjacency matrix from the 'graphSimilarities.json', which was previously obtained, and the features of each artist, namely the attributes of the graph's nodes. Those are obtained from a numpy array stored in the file 'acousticbrainz.npy', such file was provided by the paper's authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "145ae3a2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "145ae3a2",
        "outputId": "0dffc503-54a9-4770-875b-ed1951df227e",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "n_features=2613\n",
        "class Graph():  #The purpose of this class is to construct the graph of artists, in particular the Adjacency matrix A, and the  \n",
        "                # node features tensor X\n",
        "        \n",
        "    def __init__(self,mapfile,gfile):  #The expected files are the ones mentioned before.\n",
        "        self.mfile=self.load_data(mapfile)\n",
        "        self.gfile=self.load_data(gfile)\n",
        "        self.ol = DatasetOlga(olga)\n",
        "        self.A=torch.zeros((len(self.mfile),len(self.mfile)))\n",
        "        self.X=torch.zeros((n_features,len(self.mfile)))\n",
        "        self.ord=sorted(list(map(int,self.gfile.keys())))\n",
        "        self.enc1={}\n",
        "        self.enc2={}\n",
        "    \n",
        "    #With the preprocessing step at the previous cell we have lost some information\n",
        "    #and also the ordering of the artists, so i have defined a method that for each previous artist index\n",
        "    #we can encode it to a new ordered list of artists.\n",
        "    \n",
        "    \n",
        "    def encoding1(self):   #From ordered to unordered, Dict are not ordered data structures, so is better to order them before\n",
        "        for k in range(len(self.mfile)): #This encoding is used to get the Instance matrix\n",
        "            self.enc1[k]=self.ord[k]\n",
        "        return self.enc1\n",
        "    \n",
        "    def encoding2(self):   #From unordered to ordered,  From real number, to ordered one.\n",
        "        for k in range(len(self.mfile)): #This encoding is used to get the Adjacency matrix\n",
        "            self.enc2[self.ord[k]]=k\n",
        "        return self.enc2\n",
        "    \n",
        "    def get_instance(self,instances,df=False):#We take the features centroid, obtained from 25 track from artists discographies.\n",
        "        X=np.load(instances)                  #The instances file is provided by the repository mentioned in the paper.\n",
        "        X=torch.from_numpy(X).requires_grad_(True) #We take the allmusicIDs, which contain the key of the artists for which we haven't \n",
        "        c=0                                        # lost information\n",
        "        enc=self.encoding1()\n",
        "        for k in self.mfile:\n",
        "            z=enc[c]\n",
        "            self.X[:,c]=X[z] \n",
        "            c+=1\n",
        "        return self.X\n",
        "    \n",
        "    def get_adjacency(self,symmetry=False,df=False):  #The hypothesis could be either a symmetric matrix (paper), or not.\n",
        "        enc=self.encoding2()\n",
        "        for k in self.gfile:\n",
        "            c1=enc[int(k)]\n",
        "            for j in self.gfile[k]:\n",
        "                c2=enc[int(j)]\n",
        "                if self.A[c2,c1]==1 and symmetry==True:\n",
        "                    continue\n",
        "                self.A[c1,c2]=1\n",
        "                if symmetry:\n",
        "                    self.A[c2,c1]=1\n",
        "\n",
        "            \n",
        "        return self.A\n",
        "    def get_artist_dict(self):\n",
        "      self.id_to_art = {}\n",
        "      for key in self.enc1:\n",
        "        self.id_to_art[key] = self.ol.get_artist_name(self.enc1[key])\n",
        "        print(key)\n",
        "\n",
        "\n",
        "    def load_data(self,name):\n",
        "        jfile = open(name, \"r\")\n",
        "        dicti = json.load(jfile)\n",
        "        return dicti\n",
        "    \n",
        "g=Graph('MsbMapped.json','graphSimilarities.json')\n",
        "X1=g.get_instance('acousticbrainz.npy')\n",
        "A1=g.get_adjacency(symmetry=True)\n",
        "\n",
        "## diz_of_artist contains a mapping from the ids to the artists ##\n",
        "diz_of_artist = ol.load_data('dizofartist.json')\n",
        "\n",
        "## art_to_code is the opposite of diz_of_artist ##\n",
        "art_to_code = {diz_of_artist[key]:key for key in diz_of_artist}\n",
        "## The artists names are used to see how much the different artists are distant, and also to see what are their actual names, instead of their vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VBjS1fftwDay",
      "metadata": {
        "id": "VBjS1fftwDay"
      },
      "outputs": [],
      "source": [
        "torch.save(A1,'adjacency')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1AE6nBR590hF",
      "metadata": {
        "id": "1AE6nBR590hF"
      },
      "outputs": [],
      "source": [
        "samples = np.array(torch.sum(A1,dim=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "--uo5Ltu-Sud",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "--uo5Ltu-Sud",
        "outputId": "d621b7f8-9a13-4069-9cb3-37d95c80ddf2"
      },
      "outputs": [],
      "source": [
        "samples = np.array(torch.sum(A1,dim=1))\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Box(y=samples,boxpoints = 'all',\n",
        "                    fillcolor=\"blue\",jitter = 0.3,whiskerwidth = 0.1,boxmean = 'sd', marker_color = 'red',name = 'Artist distribution'))\n",
        "fig.update_layout(title_text = 'Artists box plot',width=650)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e080eafd",
      "metadata": {
        "id": "e080eafd"
      },
      "source": [
        "# GraphSAGE model\n",
        "\n",
        "- Once we also have the features for each instance, and the adjacency matrix of the graph, we can start to design the Graph Convolutional Layers, and the Fully Connected layers, as described in the paper.\n",
        "\n",
        "- Every feature vector has 2613 elements (low level features of the artists), our aim is to embed these vectors in a 100-dimensional space, where the distance between its points (Euclidean distance) represents a musical distance among the artists. (It is not clear however what each dimension stands for).\n",
        "The Graph Neural network attempts to learn this embedded space.\n",
        "\n",
        "- The GraphNN that the paper's authors decided to use is the GraphSAGE model (SAGE stands for Sample and AGgregatE).\n",
        "\n",
        "\n",
        "\n",
        "- This approach proposes a framework that generalizes the GCN to use trainable aggregation functions (beyond simple convolutions). ![Alt text](data:image/png;base64,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 \"GraphSAGE structure\")\n",
        "- This type of approach was introduced in the paper ['Inductive Representation Learning on Large Graphs'](https://arxiv.org/abs/1706.02216), that is also where it was taken the previous image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1121362",
      "metadata": {
        "id": "a1121362"
      },
      "outputs": [],
      "source": [
        "class GraphSAGE(nn.Module):\n",
        "    \n",
        "    def __init__(self,X,A,train_set,test_set,L,batch_size,device, training_mode = True):\n",
        "        \n",
        "        super(GraphSAGE,self).__init__()\n",
        "        self.device=device\n",
        "        self.A=A.to(self.device) #Tensors version of adjacency matrix and Instances\n",
        "        ## There are two types of adjacency matrix that could be useful ##\n",
        "        self.Atrain=self.select(self.A,train_set,train_set).to(self.device)\n",
        "        self.ATot=self.select(self.A,train_set+test_set,train_set+test_set).to(self.device)\n",
        "        \n",
        "        self.feat=100\n",
        "        self.X=torch.tensor(X.tolist(),requires_grad=True).to(self.device)   \n",
        "        self.COO=torch.load('COOA.pt') #This file contains the whole adjacency matrix in coordinate format (which is the torch geometric format)\n",
        "        self.train=train_set\n",
        "        self.test=test_set\n",
        "        self.L=L   #Number of layers\n",
        "        self.lamb=0.8  #Percentage used for the weighted distance to choose the hard positives and the hard negatives.\n",
        "        if training_mode:  #When we train we use this setting, otherwise is faster to set training_mode to false, in the case we want to carry out a forward on a batch of samples. \n",
        "          self.bs=batch_size\n",
        "          self.diz=self.getDiz()\n",
        "          self.mb=self.mini_batches(self.train+self.test,self.bs)\n",
        "          self.OrDiz=self.getCorrenspondancies(self.mb)\n",
        "        self.SG1=SAGEConv(2613,256,normalize=True,aggr=\"mean\")\n",
        "        self.SG2=SAGEConv(256,256,normalize=True,aggr=\"mean\")\n",
        "        self.SG3=SAGEConv(256,256,normalize=True,aggr=\"mean\")\n",
        "        \n",
        "        self.FC1=nn.Linear(256,256)\n",
        "        self.FC2=nn.Linear(256,256)\n",
        "        self.FC3=nn.Linear(256,self.feat)\n",
        "        self.FC4 = nn.Linear(256,256)\n",
        "        \n",
        "    def forward(self,V,b,nbs=-1,eval_mode = False):\n",
        "        Vdiz=self.tracing(V,b, eval_mode)\n",
        "        \n",
        "        # If these statements hold it means that we have already defined the mini batches for the training data, and we don't have to look for their \n",
        "        # neighbors everytime. Otherwise we get the neighbors for them.\n",
        "        if len(V)>500 and nbs!=-1:\n",
        "            OrDiz=self.OrDiz[nbs]\n",
        "        else:\n",
        "            OrDiz=self.getCorr(Vdiz) #Every sample/artist is normalized from 0 to 512(batch_size), in order to get easily the indices from the matrix A.\n",
        "            \n",
        "        for k in range(0,self.L):  #k reach maximum 2, the precise number depends on the number of layers that we decide to use for the GraphSAGE's models\n",
        "            \n",
        "\n",
        "            if k==0:\n",
        "                Es=self.select(self.X,set(),Vdiz[k+1]).T\n",
        "                Anew=self.select(self.A,Vdiz[k+1],Vdiz[k+1])\n",
        "                Anew=self.ConvertAtoCOO(Anew)\n",
        "                Es=self.SG1(Es,Anew).T\n",
        "                Es=F.elu(Es)\n",
        "    \n",
        "            if k==1:\n",
        "                Es=self.select(Es,set(),OrDiz[k+1].keys()).T\n",
        "                Anew=self.select(self.A,Vdiz[k+1],Vdiz[k+1])\n",
        "                Anew=self.ConvertAtoCOO(Anew)\n",
        "                Es=self.SG2(Es,Anew).T\n",
        "                Es=F.elu(Es)\n",
        "                \n",
        "            \n",
        "            if k==2:\n",
        "                Es=self.select(Es,set(),OrDiz[k+1].keys()).T\n",
        "                Anew=self.select(self.A,Vdiz[k+1],Vdiz[k+1])\n",
        "                Anew=self.ConvertAtoCOO(Anew)\n",
        "                Es=self.SG3(Es,Anew).T\n",
        "                Es=F.elu(Es)\n",
        "                \n",
        "            \n",
        "            if k==self.L-1:\n",
        "                Es=self.select(Es,set(),OrDiz[k+2]).T\n",
        "            \n",
        "            \n",
        "        out=self.FC1(Es)\n",
        "        out=self.FC2(out)\n",
        "        out=self.FC3(out)\n",
        "        return out.T\n",
        "    \n",
        "    def getCorrenspondancies(self,mbb):  ## If we are training the normalization of the batch samples is done from the pre-computed mini-batches ##\n",
        "        OrDiz={}\n",
        "        num=int(len(self.train)/self.bs)+1\n",
        "        for j in range(len(mbb[:num])):\n",
        "          Vdiz=self.tracing(mbb[j],1)\n",
        "          OrDiz[j]={}\n",
        "          for k in Vdiz:\n",
        "              OrDiz[j][k]={}\n",
        "              OrDiz[j][k]={i: sorted(list(Vdiz[k]))[i] for i in range(len(Vdiz[k]))}\n",
        "          print(\"Processed {}-th mini-batch\".format(j+1))\n",
        "        return OrDiz\n",
        "    \n",
        "    def getCorr(self,Vdiz): \n",
        "        OrDiz={}\n",
        "        for k in Vdiz:\n",
        "            OrDiz[k]={}\n",
        "            OrDiz[k]={i: sorted(list(Vdiz[k]))[i] for i in range(len(Vdiz[k]))}\n",
        "        return OrDiz\n",
        "            \n",
        "            \n",
        "    \n",
        "    def tracing(self,V,b,eval_mode = False):  # To perform the FFW in the Graph Networks we need to trace the neighbors for each samples. \n",
        "        Vdiz={}                               # This is done through this method and with the 'get_n' method\n",
        "        K=self.L+1\n",
        "        Vdiz[K]=sorted(list(V))\n",
        "        for k in range(K-1,0,-1):\n",
        "            d=set()\n",
        "            for idx in Vdiz[k+1]: \n",
        "                d=d.union(self.get_n(idx,b, eval_mode))\n",
        "                \n",
        "            Vdiz[k]=d\n",
        "        return Vdiz\n",
        "            \n",
        "    def get_n(self,idx,b, eval_mode): #This function is the neighbor's function. Given a batch index we get its neighborhood.\n",
        "        if b==1:\n",
        "            A=self.Atrain\n",
        "        else:\n",
        "            A=self.ATot\n",
        "        t=torch.nonzero(A[idx])\n",
        "        s=set()\n",
        "        \n",
        "        for k in t:\n",
        "            if t.shape[0]!=0 and eval_mode == False:\n",
        "              s.add(k.item())\n",
        "            \n",
        "            elif eval_mode == True:\n",
        "              if idx in self.test:\n",
        "                if k.item() not in self.test:\n",
        "                  s.add(k.item())\n",
        "              else:\n",
        "                s.add(k.item())\n",
        "            \n",
        "            else:\n",
        "              continue\n",
        "        s.add(idx)     \n",
        "        return s\n",
        "    \n",
        "    def select(self,mat,row,col):  #Given a set of indices for rows or column or both, we get the respective elements.\n",
        "        col=sorted(list(col))      #This is applied when we get the t matrix.\n",
        "       \n",
        "        c=0\n",
        "        if row==set():\n",
        "            col=torch.tensor(col,dtype=torch.int32).to(self.device)\n",
        "            ma=torch.index_select(mat.to(self.device),1,col)\n",
        "            return ma\n",
        "        else:\n",
        "            row=torch.tensor(sorted(list(row))).to(self.device)\n",
        "            col=torch.tensor(col).to(self.device)\n",
        "            ma=torch.index_select(mat,0,row)\n",
        "            ma=torch.index_select(ma,1,col)\n",
        "            return ma\n",
        "    \n",
        "   \n",
        "    def getDiz(self):   # This method is used to get the positives and negatives for each samples, and eventually it is helpful to track them inside the mini-batches,\n",
        "        diz={}          # thanks to the previously described methods.\n",
        "        for k in range(self.COO.shape[1]):\n",
        "            cn=int(self.COO[0][k].item())\n",
        "            # if cn>self.train[-1]:\n",
        "            #     break\n",
        "            \n",
        "            if cn not in diz:\n",
        "                diz[cn]=[[int(self.COO[1][k])]]\n",
        "                r=randrange(len(self.train))\n",
        "                while self.A[int(cn)][r]!=0:\n",
        "                    r=randrange(len(self.train))\n",
        "                diz[cn].append([r])\n",
        "            elif cn in diz:\n",
        "                diz[cn][0].append(int(self.COO[1][k]))\n",
        "                r=randrange(len(self.train))\n",
        "                while self.A[int(cn)][r]!=0:\n",
        "                    r=randrange(len(self.train))\n",
        "                diz[cn][1].append(r)\n",
        "                \n",
        "        return diz\n",
        "\n",
        "    def ConvertAtoCOO(self,SA): # This function easily converts the adjacency matrix format to the coordinate matrix format, which is the format used in torch-geometric.\n",
        "        Anew=torch.nonzero(SA).T.type(torch.LongTensor)\n",
        "        return Anew.to(self.device)\n",
        "\n",
        "    def getHardP_N(self,currentB,tensor): # This method returns for a given batch its respective positives and negatives.\n",
        "      samples=self.mbbPosNeg[currentB]\n",
        "      positives=torch.zeros((tensor.shape[0],tensor.shape[1]))\n",
        "      negatives=torch.zeros((tensor.shape[0],tensor.shape[1]))\n",
        "      mbbList=sorted(list(self.mb[currentB]))\n",
        "      for k in samples:\n",
        "        pos=samples[k][0]\n",
        "        neg=samples[k][1]\n",
        "        distDizP={kdist:((tensor[mbbList.index(k)]-tensor[mbbList.index(kdist)])**2).sum().item() for kdist in pos}\n",
        "        distDizN={kdist:((tensor[mbbList.index(k)]-tensor[mbbList.index(kdist)])**2).sum().item() for kdist in neg}\n",
        "        summP=sum(list(distDizP.values()))\n",
        "        summN=sum(list(distDizN.values()))\n",
        "        if len(distDizP)!=0 and summP!=0:\n",
        "          distDizP={kdist:distDizP[kdist]/summP for kdist in distDizP}\n",
        "        else:\n",
        "          distDizP[k]=0.5\n",
        "        if len(distDizN)!=0 and summN!=0:\n",
        "          distDizN={kdist:distDizN[kdist]/summN for kdist in distDizN}\n",
        "        else:\n",
        "          distDizN[k]=0.5\n",
        "        keysP=list(distDizP.keys())\n",
        "        keysN=list(distDizN.keys())\n",
        "        \n",
        "        for dist in keysP:\n",
        "          if distDizP[dist]>=self.lamb and len(distDizP)!=1:\n",
        "            distDizP.pop(dist)\n",
        "        \n",
        "        for dist in keysN:\n",
        "          if distDizN[dist]<= 1-self.lamb and len(distDizN)!=1:\n",
        "            distDizN.pop(dist)\n",
        "        \n",
        "        \n",
        "        positives[mbbList.index(k)]=tensor[mbbList.index(max(distDizP,key=distDizP.get))]\n",
        "        negatives[mbbList.index(k)]=tensor[mbbList.index(min(distDizN,key=distDizN.get))]\n",
        "      \n",
        "      return positives,negatives\n",
        "        \n",
        "        \n",
        "    \n",
        "    \n",
        "    def mini_batches(self,indices,bs=32): #This function generates a list of minibatches, of size bs\n",
        "        indexN=indices.copy()           #sets are unordered data structure, so there is no need to shuffle them. \n",
        "        indicesTot=[indexN[:len(self.train)],indexN[self.test[0]:]] #In this method we also take the possible positive and negative for each of the sample.\n",
        "        mbList=[]\n",
        "        self.mbbPosNeg={} \n",
        "        c=0   \n",
        "        num=int(len(self.train)/self.bs)+1     #Lists of lists of mini_batches indices \n",
        "        for indicesN in indicesTot:\n",
        "          u=0\n",
        "          if len(indicesN)==len(indexN[self.test[0]:]):\n",
        "            mb=set(indicesN)\n",
        "            mbList.append(mb)\n",
        "            self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "            update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "            self.mbbPosNeg[c].update(update)\n",
        "            return mbList\n",
        "          while len(indicesN)!=0:\n",
        "              mb=set()\n",
        "                                  #Inner list, with the indices of a particular mini_batch\n",
        "              while len(mb)<bs:\n",
        "                  if len(indicesN)==0:\n",
        "                      mbList.append(mb)\n",
        "                      self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "                      update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "                      self.mbbPosNeg[c].update(update)\n",
        "                      u=1\n",
        "                      c+=1\n",
        "                      break\n",
        "\n",
        "                  r=choice(indicesN)\n",
        "                  sample=indicesN.pop(indicesN.index(r))\n",
        "                  mb.add(sample)\n",
        "              if u!=1:\n",
        "                self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "                update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "                self.mbbPosNeg[c].update(update)\n",
        "                mbList.append(mb)\n",
        "                c+=1\n",
        "        return mbList          #obj.mini_batches(#,bs=128) #: train_,train,val,test, we get lists of list of batches from here\n",
        "    \n",
        "    \n",
        "    def getNegSample(self,key,mb): ## This method looks for the closest 4 negatives in a batch, for each samples in it.\n",
        "      l=[]\n",
        "      for j in mb:\n",
        "        if j!=key:\n",
        "          if key not in self.diz:\n",
        "            l.append(j)\n",
        "            if len(l)==4:\n",
        "              return l\n",
        "          else:\n",
        "            if j not in self.diz[key][0]:\n",
        "              l.append(j)\n",
        "              if len(l)==4:\n",
        "                return l  \n",
        "\n",
        "\n",
        "\n",
        "    def calcG(self,ID):  #This method is used for the evaluation of accuracy, in particular it computes the denominator\n",
        "        if ID>200:       # as described in the paper.\n",
        "            ID=200\n",
        "        c=1\n",
        "        somm=0\n",
        "        while c<=ID:\n",
        "            somm+=1/(math.log2(1+c))\n",
        "            c+=1\n",
        "        return somm\n",
        "\n",
        "    def evalAcc(self,S,kneigh,b):  #This function is to compute accuracy for the test and train set. \n",
        "        S = sorted(S)\n",
        "        S1 = sorted(self.train + S)\n",
        "        \n",
        "        T = self.forward(S1,b, nbs = -1, eval_mode = True)\n",
        "\n",
        "        test_embs = self.select(T,set(),S).to(torch.device('cpu')).detach().T.numpy()\n",
        "        T=T.detach().to(torch.device(\"cpu\")).numpy().transpose()\n",
        "        \n",
        "        neigh=NearestNeighbors(n_neighbors=(kneigh+1),algorithm='ball_tree').fit(test_embs) #With the K-NN we get the nearest \n",
        "        \n",
        "        dist,ind=neigh.kneighbors(test_embs)   \n",
        "        \n",
        "        acc=[]\n",
        "        A_acc=self.select(self.A,S,S)\n",
        "\n",
        "        c=0\n",
        "        for k in S:\n",
        "            summ=0\n",
        "            \n",
        "            ideal = A_acc[ind[c][0]].sum().item()\n",
        "            \n",
        "            \n",
        "            \n",
        "            den=self.calcG(ideal)\n",
        "            if den==0:\n",
        "                c+=1\n",
        "                continue  \n",
        "            for j in range(len(ind[c][1:])):\n",
        "                if A_acc[ind[c][0]][ind[c][1:][j]].item()!=0:\n",
        "                    summ+= 1/(math.log2(1+(j+1)))\n",
        "                    \n",
        "                else:\n",
        "                    continue\n",
        "            c+=1    \n",
        "            summ/=den\n",
        "            acc.append(summ)\n",
        "        return acc\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zgzkf8087Heo",
      "metadata": {
        "id": "zgzkf8087Heo"
      },
      "source": [
        "## Utilities\n",
        "* In the next cell are defined specific functions for our task.\n",
        "* 'TrainingPipeLine' is simply the pipeline of our training, and it comprises also the computation of the Normalized Discounted Cumulative Gain (nDCG).\n",
        "*There are also functions that are used laterly the notebook, such as 'Save_Model', 'Load_Model', 'plot_arrays', 'plot_metrics', 'get_accuracy', 'get_embeddings', 'get_nearest_artists'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e580b5e",
      "metadata": {
        "id": "5e580b5e",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "def TrainingPipeLine(model, optimizer, scheduler,loss, training, testing, num_epochs,KNN):\n",
        "    start=time.time()\n",
        "    bt=1 # Considers only the training samples from the adjacency matrix.\n",
        "    btot=2 # Considers either the training and either the testing samples from the asjacency matrix.\n",
        "    history_lossTr={}\n",
        "    history_lossTe={}\n",
        "    history_accuracy={}\n",
        "    mbb=model.mb\n",
        "    for epoch in range(num_epochs):\n",
        "        print(\"Processing epoch n°\",epoch+1)\n",
        "        num=int(len(training)/batch_size)+1\n",
        "        startEP=time.time()\n",
        "        history_lossTr[epoch+1]=[]\n",
        "        for k in range(len(mbb[:num])):\n",
        "            \n",
        "            print(\"Processing {}-th epoch: {}/{} mini-batch\".format(epoch+1,k+1,num))\n",
        "          \n",
        "\n",
        "            Ex=model(mbb[k],bt,nbs=k)\n",
        "            anchors=Ex.T\n",
        "            currentB=k\n",
        "            positives,negatives=model.getHardP_N(currentB,anchors)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            lossTr=loss(anchors,positives.detach().to(device),negatives.detach().to(device))\n",
        "            lossTr.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            history_lossTr[epoch+1].append(lossTr.item())\n",
        "        \n",
        "        \n",
        "        with torch.no_grad():\n",
        "            history_lossTe[epoch+1]=[]\n",
        "            for k in range(num,num+len(mbb[num:])):\n",
        "                Ex=model(mbb[k],btot)\n",
        "                anchors=Ex.T\n",
        "                currentB=k\n",
        "                positives,negatives=model.getHardP_N(currentB,anchors)\n",
        "\n",
        "                lossTe=loss(anchors,positives.detach().to(device),negatives.detach().to(device))\n",
        "                history_lossTe[epoch+1]=lossTe.item()\n",
        "                \n",
        "\n",
        "            history_lossTr[epoch+1]=sum(history_lossTr[epoch+1])/len(history_lossTr[epoch+1])\n",
        "\n",
        "            print(\"Evaluating the epoch n°\",epoch+1)\n",
        "            #accTr=model.evalAcc(training,KNN,bt)\n",
        "            accTe=model.evalAcc(testing,KNN,btot)\n",
        "            #TrainAcc=np.mean(np.array(accTr))\n",
        "            TestAcc=np.mean(np.array(accTe))\n",
        "            history_accuracy[epoch+1]=TestAcc\n",
        "            print(\"Processesed epoch n° {},\\tTest accuracy: {:.4f}\\tTest Loss: {:.4f}\\tTrain Loss: {:.8f}\\t\".format((epoch+1),TestAcc,history_lossTe[epoch+1],history_lossTr[epoch+1]))\n",
        "            endEP=time.time()\n",
        "            scheduler.step()\n",
        "            print(\"Requested time for processing {}-th epoch was: {:.4f} secs.\".format(epoch+1,endEP-startEP))\n",
        "    return model, optimizer, history_lossTr, history_accuracy, history_lossTe\n",
        "\n",
        "def Save_Model(path,model, optimizer, history_lossTr, history_accuracy, history_lossTe):\n",
        "    num_epochs=max(list(history_lossTr.keys()))\n",
        "    checkpoint={\n",
        "        \"epoch\":num_epochs,\n",
        "        \"modelState\":model.state_dict(),\n",
        "        \"optimizerState\":optimizer.state_dict(),\n",
        "        \"Loss_trainHistory\":history_lossTr,\n",
        "        \"Accuracy_History\":history_accuracy,\n",
        "        \"Loss_testHistory\":history_lossTe\n",
        "    }\n",
        "    torch.save(checkpoint,path)\n",
        "    \n",
        "def Load_Model(path, device):\n",
        "    model_checkpoint=torch.load(path, map_location = device)\n",
        "    return model_checkpoint\n",
        "\n",
        "## For all the plots was used the plotly library, because it makes really easy to interact with the most famous data visualization tools. ##\n",
        "def plot_arrays(metrics, conf_name, loss = True):\n",
        "    num_epochs=len(metrics[0])\n",
        "    fig1 = go.Figure()\n",
        "    if loss:\n",
        "      text = ['Loss on the TrainSet', 'Loss on the TestSet','TrainSet Loss VS. TestSet Loss in '+ conf_name,\"Loss\"]\n",
        "\n",
        "    \n",
        "\n",
        "      \n",
        "\n",
        "      fig1.add_trace(go.Scatter(x=np.array(range(num_epochs)), y=np.array(metrics[0]),\n",
        "                  mode='lines+markers',\n",
        "                  name=text[0], line=dict(color=\"navy\", width=4))) \n",
        "    if loss == False:\n",
        "      text = [\"acc\",\"Accuracy on TestSet\", \"Accuracy on TestSet in \"+ conf_name, \"Accuracy\"]\n",
        "    \n",
        "    fig1.add_trace(go.Scatter(x=np.array(range(num_epochs)), y= np.array(metrics[1]) if loss else np.array(metrics[0]),\n",
        "                        mode='lines+markers',\n",
        "                        name=text[1],line=dict(color=\"firebrick\", width=4)))\n",
        "    \n",
        "    fig1.update_layout(title=text[2],\n",
        "                xaxis_title='epochs',\n",
        "                yaxis_title=text[3])\n",
        "    \n",
        "\n",
        "    fig1.show()\n",
        "\n",
        "def plot_metrics(train_diz,test_diz, conf_name, loss = True):\n",
        "  if loss:\n",
        "    metrics = [[train_diz[key] for key in list(sorted(train_diz.keys()))],[test_diz[key] for key in list(sorted(test_diz.keys()))]]\n",
        "  else:\n",
        "    metrics = [[test_diz[key] for key in list(sorted(test_diz.keys()))]]\n",
        "  plot_arrays(metrics, conf_name, loss)\n",
        "\n",
        "def get_accuracy(model_name, device, instance, model_path = None, n_layers = False):\n",
        "  models = [\"SAGE1\",\"SAGE2\", \"SAGE3\",\"conf1\",\"conf2\",\"conf3\",\"conf4\"]\n",
        "  arch_paths = [\"models/one_layerSAGE.pt\", \"models/two_layerSAGE.pt\", \"models/three_layerSAGE.pt\", \"models/conf1.pt\", \"models/conf2.pt\", \"models/conf3.pt\", \"models/conf4.pt\"]\n",
        "  btot = 2\n",
        "  K = 200\n",
        "  training=list(range(0,10189+1))\n",
        "  testing=list(range(10190,11260+1))\n",
        "  if model_name not in models:\n",
        "    print(\"the model name inserted is not valid, choose one among these choices: \",models)\n",
        "    return\n",
        "  if n_layers != False:\n",
        "    if model_path!= None:\n",
        "      patt = model_path\n",
        "    else:\n",
        "      patt = arch_paths[n_layers-1]\n",
        "    model = GraphSAGE(instance,A1,training,testing,n_layers,512, device, training_mode = False).to(torch.device(device))\n",
        "    model_check = Load_Model(patt, device)\n",
        "    model.load_state_dict(model_check['modelState'])\n",
        "\n",
        "    accuracy = model.evalAcc(testing,K,btot)\n",
        "\n",
        "    accuracy = np.mean(np.array(accuracy))\n",
        "    \n",
        "\n",
        "    return accuracy\n",
        "  \n",
        "  else:\n",
        "    if model_path!= None:\n",
        "      patt = model_path\n",
        "    else:\n",
        "      patt = arch_paths[models.index(model_name)]\n",
        "    if model_name == \"conf1\":\n",
        "      model = Conf1(instance,A1,training,testing,512,device, training_mode = False).to(torch.device(device))\n",
        "      model_check = Load_Model(patt, device)\n",
        "      model.load_state_dict(model_check['modelState'])\n",
        "      accuracy = model.evalAcc(testing,200,btot)\n",
        "      accuracy = np.mean(np.array(accuracy))\n",
        "      \n",
        "      return accuracy\n",
        "      \n",
        "    elif model_name == \"conf2\":\n",
        "      model = Conf2(instance,A1,training,testing,512,device, training_mode = False).to(torch.device(device))\n",
        "      model_check = Load_Model(patt, device)\n",
        "      model.load_state_dict(model_check['modelState'])\n",
        "      accuracy = model.evalAcc(testing,K,btot)\n",
        "\n",
        "      accuracy = np.mean(np.array(accuracy))\n",
        "    \n",
        "\n",
        "      return accuracy\n",
        "\n",
        "    elif model_name == \"conf3\":\n",
        "      model = Conf3(instance,A1,training,testing,512,device, training_mode = False).to(torch.device(device))\n",
        "      model_check = Load_Model(patt, device)\n",
        "      model.load_state_dict(model_check['modelState'])\n",
        "      accuracy = model.evalAcc(testing,K,btot)\n",
        "\n",
        "      accuracy = np.mean(np.array(accuracy))\n",
        "      \n",
        "\n",
        "      return accuracy\n",
        "\n",
        "    elif model_name == \"conf4\":\n",
        "\n",
        "      model = Conf4(instance,A1,training,testing,512,device, training_mode = False).to(torch.device(device))\n",
        "      model_check = Load_Model(patt, device)\n",
        "      model.load_state_dict(model_check['modelState'])\n",
        "      accuracy = model.evalAcc(testing,K,btot)\n",
        "\n",
        "      accuracy = np.mean(np.array(accuracy))\n",
        "      \n",
        "\n",
        "      return accuracy\n",
        "\n",
        "def get_nearest_artists(embedding, artist_name, K, artist_to_id, id_to_artist):\n",
        "  Knew = K+50\n",
        "  T=embedding.detach().to(torch.device(\"cpu\")).numpy().transpose()\n",
        "  neigh=NearestNeighbors(n_neighbors=Knew,algorithm='kd_tree').fit(T)#With the K-NN we get the nearest \n",
        "  dist,ind = neigh.kneighbors(T[int(artist_to_id[artist_name])].reshape((1,-1))) \n",
        "  \n",
        "  artist_id = artist_to_id[artist_name]\n",
        "\n",
        "  neighbors_list = list(ind[0])[1:]\n",
        "  dist_list = list(dist[0])[1:]\n",
        "  neighbors_ = []\n",
        "  c = 1\n",
        "  while len(neighbors_)<K:\n",
        "    if id_to_artist[str(neighbors_list[c])]!=None:\n",
        "      neighbors_.append((id_to_artist[str(neighbors_list[c])],round(dist_list[c],4)))\n",
        "      c+=1\n",
        "    else:\n",
        "      c+=1\n",
        "\n",
        "  #neighbors_list = [id_to_artist[str(artist)] for artist in neighbors_list if str(artist) in id_to_artist]\n",
        "  \n",
        "  return neighbors_\n",
        "\n",
        "def get_embeddings(model_name,instance, device, model_path = None, n_layers = False):\n",
        "  models = [\"SAGE1\",\"SAGE2\", \"SAGE3\",\"conf1\",\"conf2\",\"conf3\",\"conf4\"]\n",
        "  arch_paths = [\"models/one_layerSAGE.pt\", \"models/two_layerSAGE.pt\", \"models/three_layerSAGE.pt\", \"models/conf1.pt\", \"models/conf2.pt\", \"models/conf3.pt\", \"models/conf4.pt\"]\n",
        "  btot = 2\n",
        "  training=list(range(0,10189+1))\n",
        "  testing=list(range(10190,11260+1))\n",
        "  if model_name not in models:\n",
        "    print(\"the model name inserted is not valid, choose one among these choices: \",models)\n",
        "    return\n",
        "  if n_layers != False:\n",
        "    if model_path!= None:\n",
        "      patt = model_path\n",
        "    else:\n",
        "      patt = arch_paths[n_layers-1]\n",
        "    model = GraphSAGE(instance,A1,training,testing,n_layers,512, device, training_mode = False).to(torch.device(device))\n",
        "    model_check = Load_Model(patt, device)\n",
        "    model.load_state_dict(model_check['modelState'])\n",
        "    embeddings = model(training+testing, btot)\n",
        "\n",
        "    \n",
        "\n",
        "    return embeddings\n",
        "  \n",
        "  else:\n",
        "    if model_path!= None:\n",
        "      patt = model_path\n",
        "    else:\n",
        "      patt = arch_paths[models.index(model_name)]\n",
        "    if model_name == \"conf1\":\n",
        "      model = Conf1(instance,A1,training,testing,512,device, training_mode = False).to(torch.device(device))\n",
        "      model_check = Load_Model(patt, device)\n",
        "      model.load_state_dict(model_check['modelState'])\n",
        "      embeddings = model(training+testing, btot)\n",
        "      return embeddings\n",
        "      \n",
        "    elif model_name == \"conf2\":\n",
        "      model = Conf2(instance,A1,training,testing,512,device, training_mode = False).to(torch.device(device))\n",
        "      model_check = Load_Model(patt, device)\n",
        "      model.load_state_dict(model_check['modelState'])\n",
        "      embeddings = model(training+testing, btot)\n",
        "      return embeddings\n",
        "\n",
        "    elif model_name == \"conf3\":\n",
        "      model = Conf3(instance,A1,training,testing,512,device, training_mode = False).to(torch.device(device))\n",
        "      model_check = Load_Model(patt, device)\n",
        "      model.load_state_dict(model_check['modelState'])\n",
        "      embeddings = model(training+testing, btot)\n",
        "      return embeddings\n",
        "\n",
        "    elif model_name == \"conf4\":\n",
        "      model = Conf4(instance,A1,training,testing,512,device, training_mode = False).to(torch.device(device))\n",
        "      model_check = Load_Model(patt, device)\n",
        "      model.load_state_dict(model_check['modelState'])\n",
        "      embeddings = model(training+testing, btot)\n",
        "      return embeddings\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4789afc0",
      "metadata": {
        "id": "4789afc0"
      },
      "source": [
        "## First Configuration #1\n",
        "\n",
        "- Through torch_geometric we have to use the Coordinate format (COO), to represent the graph data structure.\n",
        "- Thus, in the class definition for the first configuration requested we have to convert our Adjacency matrix in a COO format.\n",
        "\n",
        "- Network design requested:\n",
        "\n",
        "1. Linear(Input, 256) \n",
        "2. Linear(256, 256)\n",
        "3. GCNConv(256, 256)\n",
        "4. GCNConv(256, 256)\n",
        "5. TripletLoss()\n",
        "\n",
        "* GCNConv is an architecture that was presented in the paper ['Semi-Supervised Classification with Graph Convolutional Networks'](https://arxiv.org/abs/1609.02907), that is a way to encode in a latent representation the Graph's nodes, as in the case of GraphSAGE.  \n",
        "In the end of the notebook the performances over all the architectures are compared."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f779093d",
      "metadata": {
        "id": "f779093d"
      },
      "outputs": [],
      "source": [
        "## All the methods for this class are the same as in the GraphSAGE class, the only changes are about the forward method and the constructor. ##  \n",
        "\n",
        "class Conf1(nn.Module): ## lr=0.0001 weigth_decay=0.01\n",
        "    \n",
        "    def __init__(self,X,A,train_set,test_set,batch_size,device, training_mode = True):\n",
        "        super(Conf1,self).__init__()\n",
        "        self.device=device\n",
        "        self.A=A.to(self.device) #Tensors version of adjacency matrix and Instances\n",
        "        self.Atrain=self.select(self.A,train_set,train_set).to(self.device)\n",
        "        self.ATot=self.select(self.A,train_set+test_set,train_set+test_set).to(self.device)\n",
        "        self.L=2\n",
        "        self.X=torch.tensor(X.tolist(),requires_grad=True).to(self.device)   \n",
        "        self.COO=torch.load('COOA.pt')\n",
        "        self.train=train_set\n",
        "        self.test=test_set\n",
        "        self.lamb=0.8\n",
        "        if training_mode:\n",
        "          self.diz=self.getDiz()\n",
        "          self.bs=batch_size\n",
        "          self.mb=self.mini_batches(self.train+self.test,self.bs)\n",
        "          self.OrDiz=self.getCorrenspondancies(self.mb)\n",
        "        self.out=256\n",
        "        self.l1=nn.Linear(2613,self.out)\n",
        "        self.l2=nn.Linear(self.out,self.out)\n",
        "        self.GCN1=GCNConv(self.out,self.out)\n",
        "        self.GCN2=GCNConv(self.out,self.out)\n",
        "        \n",
        "        self.COO=torch.load('COOA.pt')\n",
        "        \n",
        "    \n",
        "    def forward(self,V,b,nbs=-1,eval_mode = False):\n",
        "        Vdiz=self.tracing(V,b, eval_mode)\n",
        "        \n",
        "        if len(V)>500 and nbs!=-1:\n",
        "            OrDiz=self.OrDiz[nbs]\n",
        "        else:\n",
        "            OrDiz=self.getCorr(Vdiz)\n",
        "        \n",
        "        ## Fully Connected layers ##\n",
        "        Es=self.select(self.X,set(),Vdiz[1]).T\n",
        "        Es=F.elu(self.l1(Es))\n",
        "        Es=F.elu(self.l2(Es))\n",
        "        \n",
        "        ## First Layer ##\n",
        "        Anew=self.select(self.A,Vdiz[1],Vdiz[1])\n",
        "        Anew=self.ConvertAtoCOO(Anew)\n",
        "        Es=self.GCN1(Es,Anew).T\n",
        "        Es=F.elu(Es)\n",
        "        \n",
        "        ## Second Layer ##\n",
        "        Es=self.select(Es,set(),OrDiz[2].keys()).T\n",
        "        Anew=self.select(self.A,Vdiz[2],Vdiz[2])\n",
        "        Anew=self.ConvertAtoCOO(Anew)\n",
        "        Es=self.GCN2(Es,Anew).T\n",
        "        Es=F.elu(Es)\n",
        "        Es=self.select(Es,set(),OrDiz[3])\n",
        "        \n",
        "        return Es\n",
        "    \n",
        "    def getCorrenspondancies(self,mbb):\n",
        "        OrDiz={}\n",
        "        num=int(len(self.train)/self.bs)+1\n",
        "        for j in range(len(mbb[:num])):\n",
        "          Vdiz=self.tracing(mbb[j],1)\n",
        "          OrDiz[j]={}\n",
        "          for k in Vdiz:\n",
        "              OrDiz[j][k]={}\n",
        "              OrDiz[j][k]={i: sorted(list(Vdiz[k]))[i] for i in range(len(Vdiz[k]))}\n",
        "          print(\"Processed {}-th mini-batch\".format(j+1))\n",
        "        return OrDiz\n",
        "    \n",
        "    def getCorr(self,Vdiz):\n",
        "        OrDiz={}\n",
        "        for k in Vdiz:\n",
        "            OrDiz[k]={}\n",
        "            OrDiz[k]={i: sorted(list(Vdiz[k]))[i] for i in range(len(Vdiz[k]))}\n",
        "        return OrDiz\n",
        "            \n",
        "            \n",
        "    \n",
        "    def tracing(self,V,b,eval_mode = False):\n",
        "        Vdiz={}\n",
        "        K=self.L+1\n",
        "        Vdiz[K]=sorted(list(V))\n",
        "        for k in range(K-1,0,-1):\n",
        "            d=set()\n",
        "            for idx in Vdiz[k+1]: \n",
        "                d=d.union(self.get_n(idx,b, eval_mode))\n",
        "                \n",
        "            Vdiz[k]=d\n",
        "        return Vdiz\n",
        "            \n",
        "    def get_n(self,idx,b, eval_mode): #This function is the neighbor's function. Given a batch index we get its neighborhood.\n",
        "        if b==1:\n",
        "            A=self.Atrain\n",
        "        else:\n",
        "            A=self.ATot\n",
        "        t=torch.nonzero(A[idx])\n",
        "        s=set()\n",
        "        \n",
        "        for k in t:\n",
        "            if t.shape[0]!=0 and eval_mode == False:\n",
        "              s.add(k.item())\n",
        "            \n",
        "            elif eval_mode == True:\n",
        "              if idx in self.test:  #If the target artist is in the test set, we need to add only those artist that are in the training set, not its test neighbors.\n",
        "                if k.item() not in self.test:\n",
        "                  s.add(k.item())\n",
        "              else:                 #If the target artist is in the train set, we accept all its neighbors\n",
        "                s.add(k.item())\n",
        "            \n",
        "            else:\n",
        "              continue\n",
        "        s.add(idx)     \n",
        "        return s\n",
        "    \n",
        "    def select(self,mat,row,col):  #Given a set of indices for rows or column or both, we get the respective elements.\n",
        "        col=sorted(list(col))      #This is applied when we get the t matrix.\n",
        "       \n",
        "        c=0\n",
        "        if row==set():\n",
        "            col=torch.tensor(col,dtype=torch.int32).to(self.device)\n",
        "            ma=torch.index_select(mat,1,col)\n",
        "            return ma\n",
        "        else:\n",
        "            row=torch.tensor(sorted(list(row))).to(self.device)\n",
        "            col=torch.tensor(col).to(self.device)\n",
        "            ma=torch.index_select(mat,0,row)\n",
        "            ma=torch.index_select(ma,1,col)\n",
        "            return ma\n",
        "    \n",
        "   \n",
        "    def getDiz(self):\n",
        "        diz={}\n",
        "        for k in range(self.COO.shape[1]):\n",
        "            cn=int(self.COO[0][k].item())\n",
        "            # if cn>self.train[-1]:\n",
        "            #     break\n",
        "            \n",
        "            if cn not in diz:\n",
        "                diz[cn]=[[int(self.COO[1][k])]]\n",
        "                r=randrange(len(self.train))\n",
        "                while self.A[int(cn)][r]!=0:\n",
        "                    r=randrange(len(self.train))\n",
        "                diz[cn].append([r])\n",
        "            elif cn in diz:\n",
        "                diz[cn][0].append(int(self.COO[1][k]))\n",
        "                r=randrange(len(self.train))\n",
        "                while self.A[int(cn)][r]!=0:\n",
        "                    r=randrange(len(self.train))\n",
        "                diz[cn][1].append(r)\n",
        "                \n",
        "        return diz\n",
        "    def ConvertAtoCOO(self,SA):\n",
        "        Anew=torch.nonzero(SA).T.type(torch.LongTensor)\n",
        "        return Anew.to(self.device)\n",
        "\n",
        "    def getHardP_N(self,currentB,tensor):\n",
        "      samples=self.mbbPosNeg[currentB]\n",
        "      positives=torch.zeros((tensor.shape[0],tensor.shape[1]))\n",
        "      negatives=torch.zeros((tensor.shape[0],tensor.shape[1]))\n",
        "      mbbList=sorted(list(self.mb[currentB]))\n",
        "      for k in samples:\n",
        "        pos=samples[k][0]\n",
        "        neg=samples[k][1]\n",
        "        distDizP={kdist:((tensor[mbbList.index(k)]-tensor[mbbList.index(kdist)])**2).sum().item() for kdist in pos}\n",
        "        distDizN={kdist:((tensor[mbbList.index(k)]-tensor[mbbList.index(kdist)])**2).sum().item() for kdist in neg}\n",
        "        summP=sum(list(distDizP.values()))\n",
        "        summN=sum(list(distDizN.values()))\n",
        "        if len(distDizP)!=0 and summP!=0:\n",
        "          distDizP={kdist:distDizP[kdist]/summP for kdist in distDizP}\n",
        "        else:\n",
        "          distDizP[k]=0.5\n",
        "        if len(distDizN)!=0 and summN!=0:\n",
        "          distDizN={kdist:distDizN[kdist]/summN for kdist in distDizN}\n",
        "        else:\n",
        "          distDizN[k]=0.5\n",
        "        keysP=list(distDizP.keys())\n",
        "        keysN=list(distDizN.keys())\n",
        "        \n",
        "        for dist in keysP:\n",
        "          if distDizP[dist]>=self.lamb and len(distDizP)!=1:\n",
        "            distDizP.pop(dist)\n",
        "        \n",
        "        for dist in keysN:\n",
        "          if distDizN[dist]<= 1-self.lamb and len(distDizN)!=1:\n",
        "            distDizN.pop(dist)\n",
        "        \n",
        "        \n",
        "        positives[mbbList.index(k)]=tensor[mbbList.index(max(distDizP,key=distDizP.get))]\n",
        "        negatives[mbbList.index(k)]=tensor[mbbList.index(min(distDizN,key=distDizN.get))]\n",
        "      \n",
        "      return positives,negatives\n",
        "        \n",
        "        \n",
        "    \n",
        "    \n",
        "    def mini_batches(self,indices,bs=32): #This function generates a list of minibatches, of size bs\n",
        "        indexN=indices.copy()           #sets are unordered data structure, so there is no need to shuffle them. \n",
        "        indicesTot=[indexN[:len(self.train)],indexN[self.test[0]:]]\n",
        "        mbList=[]\n",
        "        self.mbbPosNeg={} \n",
        "        c=0   \n",
        "        num=int(len(self.train)/self.bs)+1     #Lists of lists of mini_batches indices \n",
        "        for indicesN in indicesTot:\n",
        "          u=0\n",
        "          if len(indicesN)==len(indexN[self.test[0]:]):\n",
        "            mb=set(indicesN)\n",
        "            mbList.append(mb)\n",
        "            self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "            update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "            self.mbbPosNeg[c].update(update)\n",
        "            return mbList\n",
        "          while len(indicesN)!=0:\n",
        "              mb=set()\n",
        "                                  #Inner list, with the indices of a particular mini_batch\n",
        "              while len(mb)<bs:\n",
        "                  if len(indicesN)==0:\n",
        "                      mbList.append(mb)\n",
        "                      self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "                      update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "                      self.mbbPosNeg[c].update(update)\n",
        "                      u=1\n",
        "                      c+=1\n",
        "                      break\n",
        "\n",
        "                  r=choice(indicesN)\n",
        "                  sample=indicesN.pop(indicesN.index(r))\n",
        "                  mb.add(sample)\n",
        "              if u!=1:\n",
        "                self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "                update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "                self.mbbPosNeg[c].update(update)\n",
        "                mbList.append(mb)\n",
        "                c+=1\n",
        "        return mbList          #obj.mini_batches(#,bs=128) #: train_,train,val,test, we get lists of list of batches from here\n",
        "    \n",
        "    \n",
        "    def getNegSample(self,key,mb):\n",
        "      l=[]\n",
        "      for j in mb:\n",
        "        if j!=key:\n",
        "          if key not in self.diz:\n",
        "            l.append(j)\n",
        "            if len(l)==4:\n",
        "              return l\n",
        "          else:\n",
        "            if j not in self.diz[key][0]:\n",
        "              l.append(j)\n",
        "              if len(l)==4:\n",
        "                return l  \n",
        "\n",
        "\n",
        "\n",
        "    def calcG(self,ID):  #This method is used for the evaluation of accuracy, in particular it computes the denominator\n",
        "        if ID>200:       # as described in the paper.\n",
        "            ID=200\n",
        "        c=1\n",
        "        somm=0\n",
        "        while c<=ID:\n",
        "            somm+=1/(math.log2(1+c))\n",
        "            c+=1\n",
        "        return somm\n",
        "\n",
        "    def evalAcc(self,S,kneigh,b):  #This function is to compute accuracy for the test and train set. \n",
        "        S = sorted(S)\n",
        "        S1 = sorted(self.train + S)\n",
        "        \n",
        "        T = self.forward(S1,b, nbs = -1, eval_mode = True) # Embeddings are created either with the training and test artists\n",
        "\n",
        "        test_embs = self.select(T,set(),S).to(torch.device('cpu')).detach().T.numpy()\n",
        "        T=T.detach().to(torch.device(\"cpu\")).numpy().transpose()\n",
        "        \n",
        "        neigh=NearestNeighbors(n_neighbors=(kneigh+1),algorithm='ball_tree').fit(test_embs) #With the K-NN we get the nearest \n",
        "        \n",
        "        dist,ind=neigh.kneighbors(test_embs)   \n",
        "        \n",
        "        acc=[]\n",
        "        A_acc=self.select(self.A,S,S)\n",
        "\n",
        "        c=0\n",
        "        for k in S:\n",
        "            summ=0\n",
        "            # ideal=len([i for i in range(self.test[0],self.test[0]+A_acc[k,:].shape[0]) if A_acc[k,i]!=0]) \n",
        "            \n",
        "            ideal = A_acc[ind[c][0]].sum().item()\n",
        "            \n",
        "            \n",
        "            \n",
        "            den=self.calcG(ideal)\n",
        "            if den==0:\n",
        "                c+=1\n",
        "                continue  \n",
        "            for j in range(len(ind[c][1:])):\n",
        "                if A_acc[ind[c][0]][ind[c][1:][j]].item()!=0:\n",
        "                    summ+= 1/(math.log2(1+(j+1)))\n",
        "                    \n",
        "                else:\n",
        "                    continue\n",
        "            c+=1    \n",
        "            summ/=den\n",
        "            acc.append(summ)\n",
        "        return acc\n",
        "    \n",
        "    \n",
        "        \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a474560",
      "metadata": {
        "id": "4a474560"
      },
      "source": [
        "## Second Configuration #2\n",
        "\n",
        "- Through torch_geometric we have to use the Coordinate format (COO), to represent the graph data structure.\n",
        "- Thus, in the class definition for the first configuration requested we have to convert our Adjacency matrix in a COO format.\n",
        "\n",
        "- Network design requested:\n",
        "\n",
        "1. GCNConv(Input, 256)\n",
        "2. GraphConv(256, 256)\n",
        "3. GCNConv(256, 256)\n",
        "4. GCNConv(256, 256)\n",
        "5. Linear(256, 256) (**new**)\n",
        "6. Linear(256, 256) (**new**)\n",
        "7. TripletLoss()\n",
        "\n",
        "* This is the only architecture which implements 4 Graph Layers, the others reach at most 3 layers. Moreover in this architecture there is also one 'GraphConv' layer that is a kind of layer introduced in the paper ['Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks'](https://arxiv.org/abs/1810.02244).\n",
        "* At the beginning we tried this architecture without including the FCC layers, but we have noticed that the performances increased with their introduction. \n",
        "* Although this Network seems to be the most complex, it is not the best at performing the Artist Similarity task.\n",
        "\n",
        "* The 'GCNConv' layer is the same as in the first configuration. \n",
        "\n",
        "In the end of the notebook the performances over all the architectures are compared."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "143b8411",
      "metadata": {
        "id": "143b8411"
      },
      "outputs": [],
      "source": [
        "## All the methods for this class are the same as in the GraphSAGE class, the only changes are about the forward method and the constructor. ##  \n",
        "\n",
        "class Conf2(nn.Module): ## lr=0.00001 weigth_decay=0.01\n",
        "    \n",
        "    def __init__(self,X,A,train_set,test_set,batch_size,device, training_mode = True):\n",
        "        super(Conf2,self).__init__()\n",
        "        self.device=device\n",
        "        self.A=A.to(self.device) #Tensors version of adjacency matrix and Instances\n",
        "        self.Atrain=self.select(self.A,train_set,train_set).to(self.device)\n",
        "        self.ATot=self.select(self.A,train_set+test_set,train_set+test_set).to(self.device)\n",
        "        self.L=4\n",
        "        self.X=torch.tensor(X.tolist(),requires_grad=True).to(self.device)   \n",
        "        self.COO=torch.load('COOA.pt')\n",
        "        self.train=train_set\n",
        "        self.test=test_set\n",
        "        self.lamb=0.8\n",
        "        if training_mode:\n",
        "          self.diz=self.getDiz()\n",
        "          self.bs=batch_size\n",
        "          self.mb=self.mini_batches(self.train+self.test,self.bs)\n",
        "          self.OrDiz=self.getCorrenspondancies(self.mb)\n",
        "        self.n_input=2613\n",
        "        \n",
        "        self.out=256\n",
        "        self.GCN1=GCNConv(self.n_input,self.out)\n",
        "        self.Graph=GraphConv(self.out,self.out)\n",
        "        self.GCN2=GCNConv(self.out,self.out)\n",
        "        self.GCN3=GCNConv(self.out,self.out)\n",
        "        \n",
        "        self.l1 = nn.Linear(self.out,self.out)\n",
        "        self.l2 = nn.Linear(self.out,self.out)\n",
        "    \n",
        "    def forward(self,V,b,nbs=-1,eval_mode = False):\n",
        "        Vdiz=self.tracing(V,b, eval_mode)\n",
        "        \n",
        "        if len(V)>500 and nbs!=-1:\n",
        "            OrDiz=self.OrDiz[nbs]\n",
        "        else:\n",
        "            OrDiz=self.getCorr(Vdiz)\n",
        "        \n",
        "        ### First Layer ####\n",
        "        Es=self.select(self.X,set(),Vdiz[1]).T\n",
        "        Anew=self.select(self.A,Vdiz[1],Vdiz[1])\n",
        "        Anew=self.ConvertAtoCOO(Anew)\n",
        "        Es=F.elu(self.GCN1(Es,Anew).T)\n",
        "        \n",
        "        ### Second Layer ###\n",
        "        Es=self.select(Es,set(),OrDiz[2].keys()).T\n",
        "        Anew=self.select(self.A,Vdiz[2],Vdiz[2])\n",
        "        Anew=self.ConvertAtoCOO(Anew)\n",
        "        Es=F.elu(self.Graph(Es,Anew).T)\n",
        "        \n",
        "        ### Third Layer ###\n",
        "        Es=self.select(Es,set(),OrDiz[3].keys()).T\n",
        "        Anew=self.select(self.A,Vdiz[3],Vdiz[3])\n",
        "        Anew=self.ConvertAtoCOO(Anew)\n",
        "        Es=F.elu(self.GCN2(Es,Anew).T)\n",
        "        \n",
        "        ### Fourth Layer ###\n",
        "        Es=self.select(Es,set(),OrDiz[4].keys()).T\n",
        "        Anew=self.select(self.A,Vdiz[4],Vdiz[4])\n",
        "        Anew=self.ConvertAtoCOO(Anew)\n",
        "        Es=F.elu(self.GCN3(Es,Anew).T)\n",
        "        \n",
        "        Es=self.select(Es,set(),OrDiz[5].keys())\n",
        "        \n",
        "        Es=F.elu(self.l1(Es.T))\n",
        "        Es=F.elu(self.l2(Es))\n",
        "\n",
        "\n",
        "        return Es.T\n",
        "        \n",
        "          \n",
        "        \n",
        "               \n",
        "          \n",
        "        \n",
        "            \n",
        "            \n",
        "    def getCorrenspondancies(self,mbb):\n",
        "        OrDiz={}\n",
        "        num=int(len(self.train)/self.bs)+1\n",
        "        for j in range(len(mbb[:num])):\n",
        "          Vdiz=self.tracing(mbb[j],1)\n",
        "          OrDiz[j]={}\n",
        "          for k in Vdiz:\n",
        "              OrDiz[j][k]={}\n",
        "              OrDiz[j][k]={i: sorted(list(Vdiz[k]))[i] for i in range(len(Vdiz[k]))}\n",
        "          print(\"Processed {}-th mini-batch\".format(j+1))\n",
        "        return OrDiz\n",
        "    \n",
        "    def getCorr(self,Vdiz):\n",
        "        OrDiz={}\n",
        "        for k in Vdiz:\n",
        "            OrDiz[k]={}\n",
        "            OrDiz[k]={i: sorted(list(Vdiz[k]))[i] for i in range(len(Vdiz[k]))}\n",
        "        return OrDiz\n",
        "            \n",
        "            \n",
        "    \n",
        "    def tracing(self,V,b,eval_mode = False):\n",
        "        Vdiz={}\n",
        "        K=self.L+1\n",
        "        Vdiz[K]=sorted(list(V))\n",
        "        for k in range(K-1,0,-1):\n",
        "            d=set()\n",
        "            for idx in Vdiz[k+1]: \n",
        "                d=d.union(self.get_n(idx,b, eval_mode))\n",
        "                \n",
        "            Vdiz[k]=d\n",
        "        return Vdiz\n",
        "            \n",
        "    def get_n(self,idx,b, eval_mode): #This function is the neighbor's function. Given a batch index we get its neighborhood.\n",
        "        if b==1:\n",
        "            A=self.Atrain\n",
        "        else:\n",
        "            A=self.ATot\n",
        "        t=torch.nonzero(A[idx])\n",
        "        s=set()\n",
        "        \n",
        "        for k in t:\n",
        "            if t.shape[0]!=0 and eval_mode == False:\n",
        "              s.add(k.item())\n",
        "            \n",
        "            elif eval_mode == True:\n",
        "              if idx in self.test:\n",
        "                if k.item() not in self.test:\n",
        "                  s.add(k.item())\n",
        "              else:\n",
        "                s.add(k.item())\n",
        "            \n",
        "            else:\n",
        "              continue\n",
        "        s.add(idx)     \n",
        "        return s\n",
        "    \n",
        "    def select(self,mat,row,col):  #Given a set of indices for rows or column or both, we get the respective elements.\n",
        "        col=sorted(list(col))      #This is applied when we get the t matrix.\n",
        "       \n",
        "        c=0\n",
        "        if row==set():\n",
        "            col=torch.tensor(col,dtype=torch.int32).to(self.device)\n",
        "            ma=torch.index_select(mat,1,col)\n",
        "            return ma\n",
        "        else:\n",
        "            row=torch.tensor(sorted(list(row))).to(self.device)\n",
        "            col=torch.tensor(col).to(self.device)\n",
        "            ma=torch.index_select(mat,0,row)\n",
        "            ma=torch.index_select(ma,1,col)\n",
        "            return ma\n",
        "    \n",
        "   \n",
        "    def getDiz(self):\n",
        "        diz={}\n",
        "        for k in range(self.COO.shape[1]):\n",
        "            cn=int(self.COO[0][k].item())\n",
        "            # if cn>self.train[-1]:\n",
        "            #     break\n",
        "            \n",
        "            if cn not in diz:\n",
        "                diz[cn]=[[int(self.COO[1][k])]]\n",
        "                r=randrange(len(self.train))\n",
        "                while self.A[int(cn)][r]!=0:\n",
        "                    r=randrange(len(self.train))\n",
        "                diz[cn].append([r])\n",
        "            elif cn in diz:\n",
        "                diz[cn][0].append(int(self.COO[1][k]))\n",
        "                r=randrange(len(self.train))\n",
        "                while self.A[int(cn)][r]!=0:\n",
        "                    r=randrange(len(self.train))\n",
        "                diz[cn][1].append(r)\n",
        "                \n",
        "        return diz\n",
        "    def ConvertAtoCOO(self,SA):\n",
        "        Anew=torch.nonzero(SA).T.type(torch.LongTensor)\n",
        "        return Anew.to(self.device)\n",
        "\n",
        "    def getHardP_N(self,currentB,tensor):\n",
        "      samples=self.mbbPosNeg[currentB]\n",
        "      positives=torch.zeros((tensor.shape[0],tensor.shape[1]))\n",
        "      negatives=torch.zeros((tensor.shape[0],tensor.shape[1]))\n",
        "      mbbList=sorted(list(self.mb[currentB]))\n",
        "      for k in samples:\n",
        "        pos=samples[k][0]\n",
        "        neg=samples[k][1]\n",
        "        distDizP={kdist:((tensor[mbbList.index(k)]-tensor[mbbList.index(kdist)])**2).sum().item() for kdist in pos}\n",
        "        distDizN={kdist:((tensor[mbbList.index(k)]-tensor[mbbList.index(kdist)])**2).sum().item() for kdist in neg}\n",
        "        summP=sum(list(distDizP.values()))\n",
        "        summN=sum(list(distDizN.values()))\n",
        "        if len(distDizP)!=0 and summP!=0:\n",
        "          distDizP={kdist:distDizP[kdist]/summP for kdist in distDizP}\n",
        "        else:\n",
        "          distDizP[k]=0.5\n",
        "        if len(distDizN)!=0 and summN!=0:\n",
        "          distDizN={kdist:distDizN[kdist]/summN for kdist in distDizN}\n",
        "        else:\n",
        "          distDizN[k]=0.5\n",
        "        keysP=list(distDizP.keys())\n",
        "        keysN=list(distDizN.keys())\n",
        "        \n",
        "        for dist in keysP:\n",
        "          if distDizP[dist]>=self.lamb and len(distDizP)!=1:\n",
        "            distDizP.pop(dist)\n",
        "        \n",
        "        for dist in keysN:\n",
        "          if distDizN[dist]<= 1-self.lamb and len(distDizN)!=1:\n",
        "            distDizN.pop(dist)\n",
        "        \n",
        "        \n",
        "        positives[mbbList.index(k)]=tensor[mbbList.index(max(distDizP,key=distDizP.get))]\n",
        "        negatives[mbbList.index(k)]=tensor[mbbList.index(min(distDizN,key=distDizN.get))]\n",
        "      \n",
        "      return positives,negatives\n",
        "        \n",
        "        \n",
        "    \n",
        "    \n",
        "    def mini_batches(self,indices,bs=32): #This function generates a list of minibatches, of size bs\n",
        "        indexN=indices.copy()           #sets are unordered data structure, so there is no need to shuffle them. \n",
        "        indicesTot=[indexN[:len(self.train)],indexN[self.test[0]:]]\n",
        "        mbList=[]\n",
        "        self.mbbPosNeg={} \n",
        "        c=0   \n",
        "        num=int(len(self.train)/self.bs)+1     #Lists of lists of mini_batches indices \n",
        "        for indicesN in indicesTot:\n",
        "          u=0\n",
        "          if len(indicesN)==len(indexN[self.test[0]:]):\n",
        "            mb=set(indicesN)\n",
        "            mbList.append(mb)\n",
        "            self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "            update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "            self.mbbPosNeg[c].update(update)\n",
        "            return mbList\n",
        "          while len(indicesN)!=0:\n",
        "              mb=set()\n",
        "                                  #Inner list, with the indices of a particular mini_batch\n",
        "              while len(mb)<bs:\n",
        "                  if len(indicesN)==0:\n",
        "                      mbList.append(mb)\n",
        "                      self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "                      update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "                      self.mbbPosNeg[c].update(update)\n",
        "                      u=1\n",
        "                      c+=1\n",
        "                      break\n",
        "\n",
        "                  r=choice(indicesN)\n",
        "                  sample=indicesN.pop(indicesN.index(r))\n",
        "                  mb.add(sample)\n",
        "              if u!=1:\n",
        "                self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "                update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "                self.mbbPosNeg[c].update(update)\n",
        "                mbList.append(mb)\n",
        "                c+=1\n",
        "        return mbList          #obj.mini_batches(#,bs=128) #: train_,train,val,test, we get lists of list of batches from here\n",
        "    \n",
        "    \n",
        "    def getNegSample(self,key,mb):\n",
        "      l=[]\n",
        "      for j in mb:\n",
        "        if j!=key:\n",
        "          if key not in self.diz:\n",
        "            l.append(j)\n",
        "            if len(l)==4:\n",
        "              return l\n",
        "          else:\n",
        "            if j not in self.diz[key][0]:\n",
        "              l.append(j)\n",
        "              if len(l)==4:\n",
        "                return l  \n",
        "\n",
        "\n",
        "\n",
        "    def calcG(self,ID):  #This method is used for the evaluation of accuracy, in particular it computes the denominator\n",
        "        if ID>200:       # as described in the paper.\n",
        "            ID=200\n",
        "        c=1\n",
        "        somm=0\n",
        "        while c<=ID:\n",
        "            somm+=1/(math.log2(1+c))\n",
        "            c+=1\n",
        "        return somm\n",
        "\n",
        "    def evalAcc(self,S,kneigh,b):  #This function is to compute accuracy for the test and train set. \n",
        "        S = sorted(S)\n",
        "        S1 = sorted(self.train + S)\n",
        "        \n",
        "        T = self.forward(S1,b, nbs = -1, eval_mode = True)\n",
        "\n",
        "        test_embs = self.select(T,set(),S).to(torch.device('cpu')).detach().T.numpy()\n",
        "        T=T.detach().to(torch.device(\"cpu\")).numpy().transpose()\n",
        "        \n",
        "        neigh=NearestNeighbors(n_neighbors=(kneigh+1),algorithm='ball_tree').fit(test_embs) #With the K-NN we get the nearest \n",
        "        \n",
        "        dist,ind=neigh.kneighbors(test_embs)   \n",
        "        \n",
        "        acc=[]\n",
        "        A_acc=self.select(self.A,S,S)\n",
        "\n",
        "        c=0\n",
        "        for k in S:\n",
        "            summ=0\n",
        "            # ideal=len([i for i in range(self.test[0],self.test[0]+A_acc[k,:].shape[0]) if A_acc[k,i]!=0]) \n",
        "            \n",
        "            ideal = A_acc[ind[c][0]].sum().item()\n",
        "            \n",
        "            \n",
        "            \n",
        "            den=self.calcG(ideal)\n",
        "            if den==0:\n",
        "                c+=1\n",
        "                continue  \n",
        "            for j in range(len(ind[c][1:])):\n",
        "                if A_acc[ind[c][0]][ind[c][1:][j]].item()!=0:\n",
        "                    summ+= 1/(math.log2(1+(j+1)))\n",
        "                    \n",
        "                else:\n",
        "                    continue\n",
        "            c+=1    \n",
        "            summ/=den\n",
        "            acc.append(summ)\n",
        "        return acc\n",
        "        \n",
        "        \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc8899a8",
      "metadata": {
        "id": "dc8899a8"
      },
      "source": [
        "## Third Configuration #3\n",
        "\n",
        "- Through torch_geometric we have to use the Coordinate format (COO), to represent the graph data structure.\n",
        "- Thus, in the class definition for the first configuration requested we have to convert our Adjacency matrix in a COO format.\n",
        "\n",
        "- Network design requested:\n",
        "\n",
        "1. Linear(Input, 256)\n",
        "2. Linear(256, 256)\n",
        "3. Linear(256, 256) (**new**)\n",
        "3. GATConv(256, 256)\n",
        "4. GATConv(256, 256)\n",
        "5. TripletLoss()\n",
        "\n",
        "* This configuration appears to be way better than the others, it is not easy to explain why this happens, but is amazing to see how it outperforms the other architectures, even though it has just 2 Graph layers.\n",
        "* Also in this case there were made some modifications in the architecture, indeed at the beginning there were just 2 FCC layers, but by introducing another layer we have slightly improved our perfomances on the task.\n",
        "* In this architecture the Graph layers are the ones described in [Graph Attention Networks](https://arxiv.org/abs/1710.10903).\n",
        "\n",
        "In the end of the notebook the performances over all the architectures are compared."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c6191ba",
      "metadata": {
        "id": "3c6191ba"
      },
      "outputs": [],
      "source": [
        "## All the methods for this class are the same as in the GraphSAGE class, the only changes are about the forward method and the constructor. ##  \n",
        "\n",
        "class Conf3(nn.Module):   ## lr=0.0001 weigth_decay=0.01\n",
        "    \n",
        "    def __init__(self,X,A,train_set,test_set,batch_size,device, training_mode = True):\n",
        "        super(Conf3,self).__init__()\n",
        "        self.device=device\n",
        "        self.A=A.to(self.device) #Tensors version of adjacency matrix and Instances\n",
        "        self.Atrain=self.select(self.A,train_set,train_set).to(self.device)\n",
        "        self.ATot=self.select(self.A,train_set+test_set,train_set+test_set).to(self.device)\n",
        "        self.L=2\n",
        "        self.X=torch.tensor(X.tolist(),requires_grad=True).to(self.device)   \n",
        "        self.COO=torch.load('COOA.pt')\n",
        "        self.train=train_set\n",
        "        self.test=test_set\n",
        "        self.lamb=0.8\n",
        "        if training_mode:\n",
        "          self.diz=self.getDiz()\n",
        "          self.bs=batch_size\n",
        "          self.mb=self.mini_batches(self.train+self.test,self.bs)\n",
        "          self.OrDiz=self.getCorrenspondancies(self.mb)\n",
        "          \n",
        "        self.n_input=2613\n",
        "        self.n_out=256\n",
        "        self.l1=nn.Linear(self.n_input,self.n_out)\n",
        "        self.l2=nn.Linear(self.n_out,self.n_out)\n",
        "        self.l3=nn.Linear(self.n_out,self.n_out)\n",
        "\n",
        "        self.GAT1=GATConv(self.n_out,self.n_out)\n",
        "        self.GAT2=GATConv(self.n_out,self.n_out)\n",
        "        \n",
        "    \n",
        "    \n",
        "    def forward(self,V,b,nbs=-1,eval_mode = False):\n",
        "        Vdiz=self.tracing(V,b, eval_mode)\n",
        "        \n",
        "        if len(V)>500 and nbs!=-1:\n",
        "            OrDiz=self.OrDiz[nbs]\n",
        "        else:\n",
        "            OrDiz=self.getCorr(Vdiz)\n",
        "        \n",
        "        ## Fully Connected layers ##\n",
        "        Es=self.select(self.X,set(),Vdiz[1]).T\n",
        "        Es=F.elu(self.l1(Es))\n",
        "        Es=F.elu(self.l2(Es))\n",
        "        Es=F.elu(self.l3(Es))\n",
        "\n",
        "        \n",
        "        ## First Layer ##\n",
        "        Anew=self.select(self.A,Vdiz[1],Vdiz[1])\n",
        "        Anew=self.ConvertAtoCOO(Anew)\n",
        "        Es=self.GAT1(Es,Anew).T\n",
        "        Es=F.elu(Es)\n",
        "        \n",
        "        ## Second Layer ##\n",
        "        Es=self.select(Es,set(),OrDiz[2].keys()).T\n",
        "        Anew=self.select(self.A,Vdiz[2],Vdiz[2])\n",
        "        Anew=self.ConvertAtoCOO(Anew)\n",
        "        Es=self.GAT2(Es,Anew).T\n",
        "        Es=F.elu(Es)\n",
        "        Es=self.select(Es,set(),OrDiz[3])\n",
        "        \n",
        "        return Es\n",
        "    \n",
        "    def getCorrenspondancies(self,mbb):\n",
        "        OrDiz={}\n",
        "        num=int(len(self.train)/self.bs)+1\n",
        "        for j in range(len(mbb[:num])):\n",
        "          Vdiz=self.tracing(mbb[j],1)\n",
        "          OrDiz[j]={}\n",
        "          for k in Vdiz:\n",
        "              OrDiz[j][k]={}\n",
        "              OrDiz[j][k]={i: sorted(list(Vdiz[k]))[i] for i in range(len(Vdiz[k]))}\n",
        "          print(\"Processed {}-th mini-batch\".format(j+1))\n",
        "        return OrDiz\n",
        "    \n",
        "    def getCorr(self,Vdiz):\n",
        "        OrDiz={}\n",
        "        for k in Vdiz:\n",
        "            OrDiz[k]={}\n",
        "            OrDiz[k]={i: sorted(list(Vdiz[k]))[i] for i in range(len(Vdiz[k]))}\n",
        "        return OrDiz\n",
        "            \n",
        "            \n",
        "    \n",
        "    def tracing(self,V,b,eval_mode = False):\n",
        "        Vdiz={}\n",
        "        K=self.L+1\n",
        "        Vdiz[K]=sorted(list(V))\n",
        "        for k in range(K-1,0,-1):\n",
        "            d=set()\n",
        "            for idx in Vdiz[k+1]: \n",
        "                d=d.union(self.get_n(idx,b, eval_mode))\n",
        "                \n",
        "            Vdiz[k]=d\n",
        "        return Vdiz\n",
        "            \n",
        "    def get_n(self,idx,b, eval_mode): #This function is the neighbor's function. Given a batch index we get its neighborhood.\n",
        "        if b==1:\n",
        "            A=self.Atrain\n",
        "        else:\n",
        "            A=self.ATot\n",
        "        t=torch.nonzero(A[idx])\n",
        "        s=set()\n",
        "        \n",
        "        for k in t:\n",
        "            if t.shape[0]!=0 and eval_mode == False:\n",
        "              s.add(k.item())\n",
        "            \n",
        "            elif eval_mode == True:\n",
        "              if idx in self.test:\n",
        "                if k.item() not in self.test:\n",
        "                  s.add(k.item())\n",
        "              else:\n",
        "                s.add(k.item())\n",
        "            \n",
        "            else:\n",
        "              continue\n",
        "        s.add(idx)     \n",
        "        return s\n",
        "    \n",
        "    def select(self,mat,row,col):  #Given a set of indices for rows or column or both, we get the respective elements.\n",
        "        col=sorted(list(col))      #This is applied when we get the t matrix.\n",
        "       \n",
        "        c=0\n",
        "        if row==set():\n",
        "            col=torch.tensor(col,dtype=torch.int32).to(self.device)\n",
        "            ma=torch.index_select(mat,1,col)\n",
        "            return ma\n",
        "        else:\n",
        "            row=torch.tensor(sorted(list(row))).to(self.device)\n",
        "            col=torch.tensor(col).to(self.device)\n",
        "            ma=torch.index_select(mat,0,row)\n",
        "            ma=torch.index_select(ma,1,col)\n",
        "            return ma\n",
        "    \n",
        "   \n",
        "    def getDiz(self):\n",
        "        diz={}\n",
        "        for k in range(self.COO.shape[1]):\n",
        "            cn=int(self.COO[0][k].item())\n",
        "            # if cn>self.train[-1]:\n",
        "            #     break\n",
        "            \n",
        "            if cn not in diz:\n",
        "                diz[cn]=[[int(self.COO[1][k])]]\n",
        "                r=randrange(len(self.train))\n",
        "                while self.A[int(cn)][r]!=0:\n",
        "                    r=randrange(len(self.train))\n",
        "                diz[cn].append([r])\n",
        "            elif cn in diz:\n",
        "                diz[cn][0].append(int(self.COO[1][k]))\n",
        "                r=randrange(len(self.train))\n",
        "                while self.A[int(cn)][r]!=0:\n",
        "                    r=randrange(len(self.train))\n",
        "                diz[cn][1].append(r)\n",
        "                \n",
        "        return diz\n",
        "    def ConvertAtoCOO(self,SA):\n",
        "        Anew=torch.nonzero(SA).T.type(torch.LongTensor)\n",
        "        return Anew.to(self.device)\n",
        "\n",
        "    def getHardP_N(self,currentB,tensor):\n",
        "      samples=self.mbbPosNeg[currentB]\n",
        "      positives=torch.zeros((tensor.shape[0],tensor.shape[1]))\n",
        "      negatives=torch.zeros((tensor.shape[0],tensor.shape[1]))\n",
        "      mbbList=sorted(list(self.mb[currentB]))\n",
        "      for k in samples:\n",
        "        pos=samples[k][0]\n",
        "        neg=samples[k][1]\n",
        "        distDizP={kdist:((tensor[mbbList.index(k)]-tensor[mbbList.index(kdist)])**2).sum().item() for kdist in pos}\n",
        "        distDizN={kdist:((tensor[mbbList.index(k)]-tensor[mbbList.index(kdist)])**2).sum().item() for kdist in neg}\n",
        "        summP=sum(list(distDizP.values()))\n",
        "        summN=sum(list(distDizN.values()))\n",
        "        if len(distDizP)!=0 and summP!=0:\n",
        "          distDizP={kdist:distDizP[kdist]/summP for kdist in distDizP}\n",
        "        else:\n",
        "          distDizP[k]=0.5\n",
        "        if len(distDizN)!=0 and summN!=0:\n",
        "          distDizN={kdist:distDizN[kdist]/summN for kdist in distDizN}\n",
        "        else:\n",
        "          distDizN[k]=0.5\n",
        "        keysP=list(distDizP.keys())\n",
        "        keysN=list(distDizN.keys())\n",
        "        \n",
        "        for dist in keysP:\n",
        "          if distDizP[dist]>=self.lamb and len(distDizP)!=1:\n",
        "            distDizP.pop(dist)\n",
        "        \n",
        "        for dist in keysN:\n",
        "          if distDizN[dist]<= 1-self.lamb and len(distDizN)!=1:\n",
        "            distDizN.pop(dist)\n",
        "        \n",
        "        \n",
        "        positives[mbbList.index(k)]=tensor[mbbList.index(max(distDizP,key=distDizP.get))]\n",
        "        negatives[mbbList.index(k)]=tensor[mbbList.index(min(distDizN,key=distDizN.get))]\n",
        "      \n",
        "      return positives,negatives\n",
        "        \n",
        "        \n",
        "    \n",
        "    \n",
        "    def mini_batches(self,indices,bs=32): #This function generates a list of minibatches, of size bs\n",
        "        indexN=indices.copy()           #sets are unordered data structure, so there is no need to shuffle them. \n",
        "        indicesTot=[indexN[:len(self.train)],indexN[self.test[0]:]]\n",
        "        mbList=[]\n",
        "        self.mbbPosNeg={} \n",
        "        c=0   \n",
        "        num=int(len(self.train)/self.bs)+1     #Lists of lists of mini_batches indices \n",
        "        for indicesN in indicesTot:\n",
        "          u=0\n",
        "          if len(indicesN)==len(indexN[self.test[0]:]):\n",
        "            mb=set(indicesN)\n",
        "            mbList.append(mb)\n",
        "            self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "            update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "            self.mbbPosNeg[c].update(update)\n",
        "            return mbList\n",
        "          while len(indicesN)!=0:\n",
        "              mb=set()\n",
        "                                  #Inner list, with the indices of a particular mini_batch\n",
        "              while len(mb)<bs:\n",
        "                  if len(indicesN)==0:\n",
        "                      mbList.append(mb)\n",
        "                      self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "                      update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "                      self.mbbPosNeg[c].update(update)\n",
        "                      u=1\n",
        "                      c+=1\n",
        "                      break\n",
        "\n",
        "                  r=choice(indicesN)\n",
        "                  sample=indicesN.pop(indicesN.index(r))\n",
        "                  mb.add(sample)\n",
        "              if u!=1:\n",
        "                self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "                update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "                self.mbbPosNeg[c].update(update)\n",
        "                mbList.append(mb)\n",
        "                c+=1\n",
        "        return mbList          #obj.mini_batches(#,bs=128) #: train_,train,val,test, we get lists of list of batches from here\n",
        "    \n",
        "    \n",
        "    def getNegSample(self,key,mb):\n",
        "      l=[]\n",
        "      for j in mb:\n",
        "        if j!=key:\n",
        "          if key not in self.diz:\n",
        "            l.append(j)\n",
        "            if len(l)==4:\n",
        "              return l\n",
        "          else:\n",
        "            if j not in self.diz[key][0]:\n",
        "              l.append(j)\n",
        "              if len(l)==4:\n",
        "                return l  \n",
        "\n",
        "\n",
        "\n",
        "    def calcG(self,ID):  #This method is used for the evaluation of accuracy, in particular it computes the denominator\n",
        "        if ID>200:       # as described in the paper.\n",
        "            ID=200\n",
        "        c=1\n",
        "        somm=0\n",
        "        while c<=ID:\n",
        "            somm+=1/(math.log2(1+c))\n",
        "            c+=1\n",
        "        return somm\n",
        "\n",
        "    def evalAcc(self,S,kneigh,b):  #This function is to compute accuracy for the test and train set. \n",
        "        S = sorted(S)\n",
        "        S1 = sorted(self.train + S)\n",
        "        \n",
        "        T = self.forward(S1,b, nbs = -1, eval_mode = True)\n",
        "\n",
        "        test_embs = self.select(T,set(),S).to(torch.device('cpu')).detach().T.numpy()\n",
        "        T=T.detach().to(torch.device(\"cpu\")).numpy().transpose()\n",
        "        \n",
        "        neigh=NearestNeighbors(n_neighbors=(kneigh+1),algorithm='ball_tree').fit(test_embs) #With the K-NN we get the nearest \n",
        "        \n",
        "        dist,ind=neigh.kneighbors(test_embs)   \n",
        "        \n",
        "        acc=[]\n",
        "        A_acc=self.select(self.A,S,S)\n",
        "\n",
        "        c=0\n",
        "        for k in S:\n",
        "            summ=0\n",
        "            # ideal=len([i for i in range(self.test[0],self.test[0]+A_acc[k,:].shape[0]) if A_acc[k,i]!=0]) \n",
        "            \n",
        "            ideal = A_acc[ind[c][0]].sum().item()\n",
        "            \n",
        "            \n",
        "            \n",
        "            den=self.calcG(ideal)\n",
        "            if den==0:\n",
        "                c+=1\n",
        "                continue  \n",
        "            for j in range(len(ind[c][1:])):\n",
        "                if A_acc[ind[c][0]][ind[c][1:][j]].item()!=0:\n",
        "                    summ+= 1/(math.log2(1+(j+1)))\n",
        "                    \n",
        "                else:\n",
        "                    continue\n",
        "            c+=1    \n",
        "            summ/=den\n",
        "            acc.append(summ)\n",
        "        return acc\n",
        "            \n",
        "      \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a31428c7",
      "metadata": {
        "id": "a31428c7"
      },
      "source": [
        "## Fourth Configuration ##\n",
        "\n",
        "- Through torch_geometric we have to use the Coordinate format (COO), to represent the graph data structure.\n",
        "- Thus, in the class definition for the first configuration requested we have to convert our Adjacency matrix in a COO format.\n",
        "\n",
        "- Network design requested:\n",
        "\n",
        "1. GATConv(Input, 256)\n",
        "2. GATConv(256, 256)\n",
        "3. Linear(256, 256)\n",
        "4. Linear(256, 256)\n",
        "5. TripletLoss()\n",
        "\n",
        "* Also with this 'GAT-based' architecture we obtain good results, indeed this is similar to the third configuration, but the FCC layers are localized right after the Graph layers, similarly to the GraphSAGE's architectures.\n",
        "\n",
        "In the end of the notebook the performances over all the architectures are compared."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd8e1414",
      "metadata": {
        "id": "bd8e1414"
      },
      "outputs": [],
      "source": [
        "## All the methods for this class are the same as in the GraphSAGE class, the only changes are about the forward method and the constructor. ##  \n",
        "\n",
        "class Conf4(nn.Module):  ## lr=0.00001 weigth_decay=0.01\n",
        "    \n",
        "    def __init__(self,X,A,train_set,test_set,batch_size,device, training_mode = True):\n",
        "        super(Conf4,self).__init__()\n",
        "        self.device=device\n",
        "        self.A=A.to(self.device) #Tensors version of adjacency matrix and Instances\n",
        "        self.Atrain=self.select(self.A,train_set,train_set).to(self.device)\n",
        "        self.ATot=self.select(self.A,train_set+test_set,train_set+test_set).to(self.device)\n",
        "        self.L=2\n",
        "        self.X=torch.tensor(X.tolist(),requires_grad=True).to(self.device)   \n",
        "        self.COO=torch.load('COOA.pt')\n",
        "        self.train=train_set\n",
        "        self.test=test_set\n",
        "        self.lamb=0.8\n",
        "        if training_mode:\n",
        "          self.diz=self.getDiz()\n",
        "          self.bs=batch_size\n",
        "          self.mb=self.mini_batches(self.train+self.test,self.bs)\n",
        "          self.OrDiz=self.getCorrenspondancies(self.mb)\n",
        "        \n",
        "        self.n_input=2613\n",
        "        self.n_out=256\n",
        "        self.l1=nn.Linear(self.n_out,self.n_out)\n",
        "        self.l2=nn.Linear(self.n_out,self.n_out)\n",
        "\n",
        "        self.GAT1=GATConv(self.n_input,self.n_out)\n",
        "        self.GAT2=GATConv(self.n_out,self.n_out)\n",
        "        \n",
        "    \n",
        "    \n",
        "    def forward(self,V,b,nbs=-1,eval_mode = False):\n",
        "        Vdiz=self.tracing(V,b, eval_mode)\n",
        "        \n",
        "        if len(V)>500 and nbs!=-1:\n",
        "            OrDiz=self.OrDiz[nbs]\n",
        "        else:\n",
        "            OrDiz=self.getCorr(Vdiz)\n",
        "        \n",
        "        ## First Layer ##\n",
        "        Es=self.select(self.X,set(),Vdiz[1]).T\n",
        "        Anew=self.select(self.A,Vdiz[1],Vdiz[1])\n",
        "        Anew=self.ConvertAtoCOO(Anew)\n",
        "        Es=self.GAT1(Es,Anew).T\n",
        "        Es=F.elu(Es)\n",
        "        ## Second Layer ##\n",
        "        Es=self.select(Es,set(),OrDiz[2].keys()).T\n",
        "        Anew=self.select(self.A,Vdiz[2],Vdiz[2])\n",
        "        Anew=self.ConvertAtoCOO(Anew)\n",
        "        Es=self.GAT2(Es,Anew)\n",
        "        Es=F.elu(Es).T\n",
        "        \n",
        "        Es=self.select(Es,set(),OrDiz[3]).T\n",
        "        ## Fully Connected layers ##\n",
        "        \n",
        "        Es=F.elu(self.l1(Es))\n",
        "        \n",
        "        Es=F.elu(self.l2(Es))\n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "        return Es.T\n",
        "    \n",
        "    def getCorrenspondancies(self,mbb):\n",
        "        OrDiz={}\n",
        "        num=int(len(self.train)/self.bs)+1\n",
        "        for j in range(len(mbb[:num])):\n",
        "          Vdiz=self.tracing(mbb[j],1)\n",
        "          OrDiz[j]={}\n",
        "          for k in Vdiz:\n",
        "              OrDiz[j][k]={}\n",
        "              OrDiz[j][k]={i: sorted(list(Vdiz[k]))[i] for i in range(len(Vdiz[k]))}\n",
        "          print(\"Processed {}-th mini-batch\".format(j+1))\n",
        "        return OrDiz\n",
        "    \n",
        "    def getCorr(self,Vdiz):\n",
        "        OrDiz={}\n",
        "        for k in Vdiz:\n",
        "            OrDiz[k]={}\n",
        "            OrDiz[k]={i: sorted(list(Vdiz[k]))[i] for i in range(len(Vdiz[k]))}\n",
        "        return OrDiz\n",
        "            \n",
        "            \n",
        "    \n",
        "    def tracing(self,V,b,eval_mode = False):\n",
        "        Vdiz={}\n",
        "        K=self.L+1\n",
        "        Vdiz[K]=sorted(list(V))\n",
        "        for k in range(K-1,0,-1):\n",
        "            d=set()\n",
        "            for idx in Vdiz[k+1]: \n",
        "                d=d.union(self.get_n(idx,b, eval_mode))\n",
        "                \n",
        "            Vdiz[k]=d\n",
        "        return Vdiz\n",
        "            \n",
        "    def get_n(self,idx,b, eval_mode): #This function is the neighbor's function. Given a batch index we get its neighborhood.\n",
        "        if b==1:\n",
        "            A=self.Atrain\n",
        "        else:\n",
        "            A=self.ATot\n",
        "        t=torch.nonzero(A[idx])\n",
        "        s=set()\n",
        "        \n",
        "        for k in t:\n",
        "            if t.shape[0]!=0 and eval_mode == False:\n",
        "              s.add(k.item())\n",
        "            \n",
        "            elif eval_mode == True:\n",
        "              if idx in self.test:\n",
        "                if k.item() not in self.test:\n",
        "                  s.add(k.item())\n",
        "              else:\n",
        "                s.add(k.item())\n",
        "            \n",
        "            else:\n",
        "              continue\n",
        "        s.add(idx)     \n",
        "        return s\n",
        "    \n",
        "    def select(self,mat,row,col):  #Given a set of indices for rows or column or both, we get the respective elements.\n",
        "        col=sorted(list(col))      #This is applied when we get the t matrix.\n",
        "       \n",
        "        c=0\n",
        "        if row==set():\n",
        "            col=torch.tensor(col,dtype=torch.int32).to(self.device)\n",
        "            ma=torch.index_select(mat,1,col)\n",
        "            return ma\n",
        "        else:\n",
        "            row=torch.tensor(sorted(list(row))).to(self.device)\n",
        "            col=torch.tensor(col).to(self.device)\n",
        "            ma=torch.index_select(mat,0,row)\n",
        "            ma=torch.index_select(ma,1,col)\n",
        "            return ma\n",
        "    \n",
        "   \n",
        "    def getDiz(self):\n",
        "        diz={}\n",
        "        for k in range(self.COO.shape[1]):\n",
        "            cn=int(self.COO[0][k].item())\n",
        "            # if cn>self.train[-1]:\n",
        "            #     break\n",
        "            \n",
        "            if cn not in diz:\n",
        "                diz[cn]=[[int(self.COO[1][k])]]\n",
        "                r=randrange(len(self.train))\n",
        "                while self.A[int(cn)][r]!=0:\n",
        "                    r=randrange(len(self.train))\n",
        "                diz[cn].append([r])\n",
        "            elif cn in diz:\n",
        "                diz[cn][0].append(int(self.COO[1][k]))\n",
        "                r=randrange(len(self.train))\n",
        "                while self.A[int(cn)][r]!=0:\n",
        "                    r=randrange(len(self.train))\n",
        "                diz[cn][1].append(r)\n",
        "                \n",
        "        return diz\n",
        "    def ConvertAtoCOO(self,SA):\n",
        "        Anew=torch.nonzero(SA).T.type(torch.LongTensor)\n",
        "        return Anew.to(self.device)\n",
        "\n",
        "    def getHardP_N(self,currentB,tensor):\n",
        "      samples=self.mbbPosNeg[currentB]\n",
        "      positives=torch.zeros((tensor.shape[0],tensor.shape[1]))\n",
        "      negatives=torch.zeros((tensor.shape[0],tensor.shape[1]))\n",
        "      mbbList=sorted(list(self.mb[currentB]))\n",
        "      for k in samples:\n",
        "        pos=samples[k][0]\n",
        "        neg=samples[k][1]\n",
        "        distDizP={kdist:((tensor[mbbList.index(k)]-tensor[mbbList.index(kdist)])**2).sum().item() for kdist in pos}\n",
        "        distDizN={kdist:((tensor[mbbList.index(k)]-tensor[mbbList.index(kdist)])**2).sum().item() for kdist in neg}\n",
        "        summP=sum(list(distDizP.values()))\n",
        "        summN=sum(list(distDizN.values()))\n",
        "        if len(distDizP)!=0 and summP!=0:\n",
        "          distDizP={kdist:distDizP[kdist]/summP for kdist in distDizP}\n",
        "        else:\n",
        "          distDizP[k]=0.5\n",
        "        if len(distDizN)!=0 and summN!=0:\n",
        "          distDizN={kdist:distDizN[kdist]/summN for kdist in distDizN}\n",
        "        else:\n",
        "          distDizN[k]=0.5\n",
        "        keysP=list(distDizP.keys())\n",
        "        keysN=list(distDizN.keys())\n",
        "        \n",
        "        for dist in keysP:\n",
        "          if distDizP[dist]>=self.lamb and len(distDizP)!=1:\n",
        "            distDizP.pop(dist)\n",
        "        \n",
        "        for dist in keysN:\n",
        "          if distDizN[dist]<= 1-self.lamb and len(distDizN)!=1:\n",
        "            distDizN.pop(dist)\n",
        "        \n",
        "        \n",
        "        positives[mbbList.index(k)]=tensor[mbbList.index(max(distDizP,key=distDizP.get))]\n",
        "        negatives[mbbList.index(k)]=tensor[mbbList.index(min(distDizN,key=distDizN.get))]\n",
        "      \n",
        "      return positives,negatives\n",
        "        \n",
        "        \n",
        "    \n",
        "    \n",
        "    def mini_batches(self,indices,bs=32): #This function generates a list of minibatches, of size bs\n",
        "        indexN=indices.copy()           #sets are unordered data structure, so there is no need to shuffle them. \n",
        "        indicesTot=[indexN[:len(self.train)],indexN[self.test[0]:]]\n",
        "        mbList=[]\n",
        "        self.mbbPosNeg={} \n",
        "        c=0   \n",
        "        num=int(len(self.train)/self.bs)+1     #Lists of lists of mini_batches indices \n",
        "        for indicesN in indicesTot:\n",
        "          u=0\n",
        "          if len(indicesN)==len(indexN[self.test[0]:]):\n",
        "            mb=set(indicesN)\n",
        "            mbList.append(mb)\n",
        "            self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "            update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "            self.mbbPosNeg[c].update(update)\n",
        "            return mbList\n",
        "          while len(indicesN)!=0:\n",
        "              mb=set()\n",
        "                                  #Inner list, with the indices of a particular mini_batch\n",
        "              while len(mb)<bs:\n",
        "                  if len(indicesN)==0:\n",
        "                      mbList.append(mb)\n",
        "                      self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "                      update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "                      self.mbbPosNeg[c].update(update)\n",
        "                      u=1\n",
        "                      c+=1\n",
        "                      break\n",
        "\n",
        "                  r=choice(indicesN)\n",
        "                  sample=indicesN.pop(indicesN.index(r))\n",
        "                  mb.add(sample)\n",
        "              if u!=1:\n",
        "                self.mbbPosNeg[c]={key:[[i for i in set(self.diz[key][0]).intersection(mb)],self.getNegSample(key,mb)] for key in mb.intersection(set(self.diz.keys()))}\n",
        "                update={key:[[key],self.getNegSample(key,mb)] for key in mb.difference(set(self.diz.keys()))}\n",
        "                self.mbbPosNeg[c].update(update)\n",
        "                mbList.append(mb)\n",
        "                c+=1\n",
        "        return mbList          #obj.mini_batches(#,bs=128) #: train_,train,val,test, we get lists of list of batches from here\n",
        "    \n",
        "    \n",
        "    def getNegSample(self,key,mb):\n",
        "      l=[]\n",
        "      for j in mb:\n",
        "        if j!=key:\n",
        "          if key not in self.diz:\n",
        "            l.append(j)\n",
        "            if len(l)==4:\n",
        "              return l\n",
        "          else:\n",
        "            if j not in self.diz[key][0]:\n",
        "              l.append(j)\n",
        "              if len(l)==4:\n",
        "                return l  \n",
        "\n",
        "\n",
        "\n",
        "    def calcG(self,ID):  #This method is used for the evaluation of accuracy, in particular it computes the denominator\n",
        "        if ID>200:       # as described in the paper.\n",
        "            ID=200\n",
        "        c=1\n",
        "        somm=0\n",
        "        while c<=ID:\n",
        "            somm+=1/(math.log2(1+c))\n",
        "            c+=1\n",
        "        return somm\n",
        "\n",
        "    def evalAcc(self,S,kneigh,b):  #This function is to compute accuracy for the test and train set. \n",
        "        S = sorted(S)\n",
        "        S1 = sorted(self.train + S)\n",
        "        \n",
        "        T = self.forward(S1,b, nbs = -1, eval_mode = True)\n",
        "\n",
        "        test_embs = self.select(T,set(),S).to(torch.device('cpu')).detach().T.numpy()\n",
        "        T=T.detach().to(torch.device(\"cpu\")).numpy().transpose()\n",
        "        \n",
        "        neigh=NearestNeighbors(n_neighbors=(kneigh+1),algorithm='ball_tree').fit(test_embs) #With the K-NN we get the nearest \n",
        "        \n",
        "        dist,ind=neigh.kneighbors(test_embs)   \n",
        "        \n",
        "        acc=[]\n",
        "        A_acc=self.select(self.A,S,S)\n",
        "\n",
        "        c=0\n",
        "        for k in S:\n",
        "            summ=0\n",
        "            # ideal=len([i for i in range(self.test[0],self.test[0]+A_acc[k,:].shape[0]) if A_acc[k,i]!=0]) \n",
        "            \n",
        "            ideal = A_acc[ind[c][0]].sum().item()\n",
        "            \n",
        "            \n",
        "            \n",
        "            den=self.calcG(ideal)\n",
        "            if den==0:\n",
        "                c+=1\n",
        "                continue  \n",
        "            for j in range(len(ind[c][1:])):\n",
        "                if A_acc[ind[c][0]][ind[c][1:][j]].item()!=0:\n",
        "                    summ+= 1/(math.log2(1+(j+1)))\n",
        "                    \n",
        "                else:\n",
        "                    continue\n",
        "            c+=1    \n",
        "            summ/=den\n",
        "            acc.append(summ)\n",
        "        return acc\n",
        "            \n",
        "      \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb895db8",
      "metadata": {
        "id": "bb895db8"
      },
      "source": [
        "# Training step\n",
        "- In the following cell is possible to choose different hyperparameters to train the network.\n",
        "- In the hyperparameters tuning we must take into account: the number of layer (they try from 0 to 3 graph layers), the batch size, and the dimension of the projection matrices (in the aggregation step).\n",
        "- It is also possible to try previously described configurations.\n",
        "- There are also other hyperparameters of course, but they already are  deeply described in the paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06328f36",
      "metadata": {
        "id": "06328f36"
      },
      "outputs": [],
      "source": [
        "#### Possible partition of the dataset ####\n",
        "train_=list(range(0,9021+1)) #Train set, without val\n",
        "train=list(range(0,10189+1)) #Train set, with val\n",
        "val=list(range(9022,10189+1))\n",
        "test=list(range(10190,11260+1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ff785ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ff785ed",
        "outputId": "018833c2-241f-4ace-8ab1-8d335f02ef39",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "## train_/val stands for the splitting for the model selection/ validation, whereas the splitting train/test is for the comparison of the results.\n",
        "training=train\n",
        "testing=test\n",
        "\n",
        "n_layer=3      #n_of graph conv.layer, if we are using the GraphSAGE configuration.\n",
        "batch_size=512 #This is the batch size used in the paper which inspired artist similarity, since it was not specified in the Artist similarity paper.\n",
        "\n",
        "device=torch.device(\"cuda\")\n",
        "XX = torch.randn((2613,11261))\n",
        "model= GraphSAGE(XX,A1,training,testing,n_layer,batch_size,device).to(device) #Conf3(X1,A1,training,testing,batch_size,device).to(device)\n",
        "num_epochs=1 #According to the paper there will be 50 epochs for each experiment \n",
        "\n",
        "triplet_loss = nn.TripletMarginLoss(margin=0.2, p=2)\n",
        "KNN=200\n",
        "#### Tune the learning rate and the weight decay regularization term ####\n",
        "lr=1e-10                         #[1e-6,1e-7,1e-8,1e-9,1-10]\n",
        "weight_d=0.01\n",
        "#lr=min([1,((1-0.9)/2)])    #linear warm-up described in the paper, beta2 = 0.9\n",
        "\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=lr,weight_decay=weight_d)\n",
        "\n",
        "scheduler=lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min= 0, last_epoch= -1, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "751972a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "751972a1",
        "outputId": "68b71010-fc0c-4bdf-d2a1-25e4fd6a714d",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#### This line is for the training of the network ####\n",
        "mdl, optim, lossTr, accuracy, lossTe=TrainingPipeLine(model, optimizer, scheduler,triplet_loss, training, testing, num_epochs, KNN)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39165f93",
      "metadata": {
        "id": "39165f93"
      },
      "source": [
        "## Save and load a model\n",
        "\n",
        "* In the following cell is possible to save the trained model, and eventually to load it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "241a938b",
      "metadata": {
        "id": "241a938b"
      },
      "outputs": [],
      "source": [
        "path=\"models/three_layersSAGE_random.pt\" ## Change the path to save the trained model where you wish.\n",
        "\n",
        "#### This line calls the function to save the previous obtained results (from the training of the model) ####\n",
        "#Save_Model(path,mdl,optim,lossTr,accuracy,lossTe)\n",
        "device = 'cuda'\n",
        "\n",
        "#### This line can be uncommented in order to get data from one of our pre-trained model ####\n",
        "#model_check=Load_Model(\"models/conf2NEW.pt\", device)\n",
        "# print(model_check[\"Accuracy_History\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uikN7uw7q89I",
      "metadata": {
        "id": "uikN7uw7q89I"
      },
      "source": [
        "## Accuracy results\n",
        "* Choose the architecture amongst the 7, and see the results.\n",
        "* The obtained results are shown in results, and are plotted in the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Vj8o4fGyrKQM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj8o4fGyrKQM",
        "outputId": "f6032a62-3e92-497d-9344-440c3e7409d2"
      },
      "outputs": [],
      "source": [
        "models = [\"SAGE1\",\"SAGE2\", \"SAGE3\",\"conf1\",\"conf2\",\"conf3\",\"conf4\",\"random_conf3\", \"random_SAGE3\"]\n",
        "results = [0.26275006124936195,0.3189057310486129,0.4274988132047857,0.5669277224607767,0.47781317707844545,0.6927919457182362,0.6213292268763897,0.6982752015757381,0.08483794916268922]\n",
        "XX = torch.randn((2613,11261))\n",
        "\n",
        "get_accuracy(\"SAGE3\",device = 'cuda', instance = X1, model_path = 'models/three_layerSAGENEW.pt',n_layers = 3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x7mRyEYmUBdV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "x7mRyEYmUBdV",
        "outputId": "a0c85ee2-a8fa-4a87-9cf4-328330a3c280"
      },
      "outputs": [],
      "source": [
        "prefix = 'Graph'\n",
        "fig = go.Figure(data=[\n",
        "    go.Bar(name=prefix+models[0], y=[results[0]],text = round(results[0],4), textposition='auto'),\n",
        "    go.Bar(name=prefix+models[1], y=[results[1]],text = round(results[1],4), textposition='auto'),\n",
        "    go.Bar(name=prefix+models[2], y=[results[2]],text = round(results[2],4), textposition='auto'),\n",
        "    go.Bar(name=prefix+models[8], y =[results[8]],text = round(results[8],4), textposition='auto'),\n",
        "    go.Bar(name=models[3], y=[results[3]],text = round(results[3],4), textposition='auto'),\n",
        "    go.Bar(name=models[4], y=[results[4]],text = round(results[4],4), textposition='auto'),\n",
        "    go.Bar(name=models[5], y=[results[5]],text = round(results[5],4), textposition='auto'),\n",
        "    go.Bar(name=models[7], y=[results[7]],text = round(results[7],4), textposition='auto'),\n",
        "    go.Bar(name=models[6], y=[results[6]],text = round(results[6],4), textposition='auto')\n",
        "])\n",
        "fig.update_layout(\n",
        "    title='Performances over the different architectures',\n",
        "    xaxis_tickfont_size=14,\n",
        "    yaxis=dict(\n",
        "        title='Normalized Discounted Cumulative Gain',\n",
        "        titlefont_size=16,\n",
        "        tickfont_size=14,\n",
        "    ),\n",
        "    legend=dict(\n",
        "        x=0,\n",
        "        y=1.0,\n",
        "        bgcolor='rgba(255, 255, 255, 0)',\n",
        "        bordercolor='rgba(255, 255, 255, 0)'\n",
        "    ),\n",
        "    \n",
        "    bargap=0.15, # gap between bars of adjacent location coordinates.\n",
        "    bargroupgap=0.1 # gap between bars of the same location coordinate.\n",
        ")\n",
        "fig.update_layout(width = 500, height = 550)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tO9B1osddXff",
      "metadata": {
        "id": "tO9B1osddXff"
      },
      "source": [
        "As was described in the paper's authors GraphSAGE networks lose in accuracy when we are using a random low level features vector. But if we use the same random approach with the GAT-based architecture (conf3), we don't lose any performance in accuracy, we could get even better results. In fact, the adjacency matrix is based more on musicological features, instead of low level features. So we can say that GraphSage layers are not able to generalize the instance vectors as well as the GAT layers."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m11QuOt-8xqP",
      "metadata": {
        "id": "m11QuOt-8xqP"
      },
      "source": [
        "## Let's get the artists embeddings\n",
        "Now, given one of the 7 configurations we can test how much are plausible (from a musical point of view), its nearest neighbors.\n",
        "* Firstly, we need to know some artists that are from the test set, so we need to look for them. They are identified by all the indices from 10190 to 11260.\n",
        "* Then we get the points in the embedding space of all the dataset.\n",
        "* Then we compute for a certain arbitrary artist its K-nearest neighbors.\n",
        "* To compute the nearest neighbors we use the same function that was used to compute the accuracy. \n",
        "* Remember that the Graph of artists is obtained through the opinion of experts and the attributes of the nodes represents the low level features. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vuc2r0eWr6X0",
      "metadata": {
        "id": "vuc2r0eWr6X0"
      },
      "outputs": [],
      "source": [
        "test_list = list(range(10190,11261))\n",
        "for index in test_list:\n",
        "  print(diz_of_artist[str(index)])   #Ringo Starr, Giacomo Puccini, Michael Jackson, Gigi D'Agostino, Snoop Dogg, Alex Britti, Nancy Sinatra, Rod Stewart."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "filDDR1eDYyf",
      "metadata": {
        "id": "filDDR1eDYyf"
      },
      "source": [
        "* If you want to look for embedding by yourself you can change the setting of the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HV-NWMbkDgPq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV-NWMbkDgPq",
        "outputId": "ae9c1a57-2de0-4efd-fb0c-c91c238f3683"
      },
      "outputs": [],
      "source": [
        "K = 20 # Number of neighbors of that we are going to look for #\n",
        "device = 'cuda'\n",
        "model_name = 'conf3' ## Choose the model ##\n",
        "random = False\n",
        "\n",
        "if random:\n",
        "  instance = XX\n",
        "else:\n",
        "  instance = X1\n",
        "\n",
        "## Compute the embeddings based on the architecture ##\n",
        "embs = get_embeddings(model_name, instance, device, model_path = \"models/conf3NEW.pt\") #, n_layers = 3)\n",
        "\n",
        "## Choose the embedding ##\n",
        "embedding = embs\n",
        "\n",
        "artist_name = 'Roger Waters'\n",
        "print(\"\\nThe {} nearest artist in the embedded space for {} are:\\n\".format(K,artist_name))\n",
        "ind = get_nearest_artists(embedding,artist_name,K,art_to_code,diz_of_artist)\n",
        "print(ind)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5v1_X2dT-DVY",
      "metadata": {
        "id": "5v1_X2dT-DVY"
      },
      "source": [
        "According to this list and based on our musicological knowledge we have chosen to consider the following artists: Ringo Starr, Giacomo Puccini, Michael Jackson, Gigi D'Agostino, Snoop Dogg, Alex Britti, Nancy Sinatra, Rod Stewart.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd2972f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd2972f7",
        "outputId": "57fbe8eb-56a6-402a-dcf3-ccb452da5b42"
      },
      "outputs": [],
      "source": [
        "K = 20 # Number of neighbors of that we are going to look for #\n",
        "artist_list = ['Ringo Starr', 'Giacomo Puccini', 'Michael Jackson', \"Gigi D’Agostino\", 'Snoop Dogg','Alex Britti','Nancy Sinatra','Rod Stewart']\n",
        "device = 'cuda'\n",
        "model_name = 'conf3' ## Choose the model ##\n",
        "XX = torch.randn((2613,11261))\n",
        "## Compute the embeddings based on the architecture ##\n",
        "embs = get_embeddings(model_name,X1, device, model_path = \"models/conf3NEW.pt\")#, n_layers = 3)\n",
        "\n",
        "\n",
        "\n",
        "## Choose the embedding ##\n",
        "embedding = embs\n",
        "\n",
        "\n",
        "\n",
        "for artist_name in artist_list:\n",
        "  print(\"\\nThe {} nearest artist in the embedded space for {} are:\\n\".format(K,artist_name))\n",
        "  ind = get_nearest_artists(embedding,artist_name,K,art_to_code,diz_of_artist)\n",
        "  print(ind)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
